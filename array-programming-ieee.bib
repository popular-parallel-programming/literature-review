@INPROCEEDINGS{6332160,
  author =	 {Rosas-Ham, D. and Herath, I. and Yiapanis, P. and
                  Lujan, M. and Watson, I.},
  booktitle =	 {High Performance Computing and Communication 2012
                  IEEE 9th International Conference on Embedded
                  Software and Systems (HPCC-ICESS), 2012 IEEE 14th
                  International Conference on},
  title =	 {Architectural Support for Exploiting Fine Grain
                  Parallelism},
  year =	 2012,
  pages =	 {61-70},
  abstract =	 {The advent of multi-core processors, particularly
                  with projections that numbers of cores will continue
                  to increase, has focused attention on parallel
                  programming. It is widely recognized that current
                  programming techniques, including those that are
                  used for scientific parallel programming, will not
                  allow the easy formulation of general purpose
                  applications. An area which is receiving interest is
                  the use of programming styles which are side-effect
                  free. Previous work on parallel functional
                  programming demonstrated the potential of this to
                  permit the easy exploitation of parallelism. Recent
                  systems like Cilk use conventional languages such as
                  C but encourage the use of a largely functional
                  style (side-effect free) when writing programs. An
                  important part of the Cilk runtime is a system to
                  balance the usage of cores. In this paper we present
                  SLAM (Spreading Load with Active Messages), a
                  dynamic load balancing system based on functional
                  language evaluation techniques. We show that SLAM,
                  provided with appropriate hardware support,
                  significantly outperforms the Cilk system. We
                  evaluated our system using tiled CMPs with private
                  and shared L2 caches separately. Our results show
                  that, for the benchmarks evaluated, SLAM outperforms
                  Cilk by 28% on average when using 32-core CMPs with
                  private L2 caches. For the case of the CMPs with
                  shared L2 caches, SLAM was on average 21% faster
                  than Cilk when using 32 cores and 62% faster when
                  using 64 cores.},
  keywords =	 {C language;cache storage;microprocessor
                  chips;multiprocessing systems;parallel
                  programming;resource allocation;shared memory
                  systems;32-core CMP;C languages;Cilk runtime;Cilk
                  system;SLAM;dynamic load balancing system;exploiting
                  fine grain parallelism;functional language
                  evaluation techniques;multicore processors;parallel
                  functional programming;private L2 caches;scientific
                  parallel programming;shared L2 caches;side-effect
                  free;spreading load with active messages;writing
                  programs;Arrays;Hardware;Load management;Parallel
                  processing;Program processors;Registers;Simultaneous
                  localization and mapping;chip
                  multiprocessors;dynamic load balancing;parallel
                  programming;work stealing},
  doi =		 {10.1109/HPCC.2012.19},
  month =	 {June},
  review = 	 {fbie: rejected <2016-01-12 15:00:01>},
}

@INPROCEEDINGS{47507,
  author =	 {O'Donnell, J.T.},
  booktitle =	 {Frontiers of Massively Parallel Computation,
                  1988. Proceedings., 2nd Symposium on the Frontiers
                  of},
  title =	 {MPP implementation of abstract data parallel
                  architectures for declarative programming languages},
  year =	 1988,
  pages =	 {629-636},
  abstract =	 {A method of implementing declarative data structures
                  efficiently on a data parallel architecture is
                  illustrated by the implementation of a data parallel
                  algorithm for functional arrays on the massively
                  parallel processor (MPP). Functional arrays are
                  defined, and it is shown why the basic operations on
                  them are slow when implemented on a sequential
                  machine. Functional arrays cannot be implemented
                  efficiently on conventional architectures without
                  severely restricting the way a program can access
                  the array. Conventional unrestricted algorithms
                  typically require O(log n) time to update an array
                  and access an element. The MPP algorithm performs
                  these operations in a constant time of about 100 Î¼s},
  keywords =	 {data structures;parallel architectures;MPP
                  implementation;abstract data parallel
                  architectures;declarative programming
                  languages;functional arrays;sequential
                  machine;Computer architecture;Computer
                  languages;Computer science;Concurrent computing;Data
                  structures;Functional programming;Indexing;Logic
                  programming;Parallel architectures;Parallel
                  processing},
  doi =		 {10.1109/FMPC.1988.47507},
  month =	 {Oct},
  review = 	 {fbie: accepted <2016-01-12 15:01:13>},
}

@INPROCEEDINGS{5489406,
  author =	 {Diab, H. and Damaj, I. and Haffar-Habbal, W.},
  booktitle =	 {Computer Research and Development, 2010 Second
                  International Conference on},
  title =	 {CGLT: An Effective Computer-Based Learning Tool},
  year =	 2010,
  pages =	 {61-64},
  abstract =	 {Behavioral high-level hardware design tools are
                  currently considered powerful and can largely
                  facilitate the hardware development cycle as a
                  whole. Modern hardware design tools can target
                  high-density programmable logic devices, such as,
                  Field Programmable Gate Arrays. Currently,
                  hardware/software co-design is witnessing a growing
                  focus on finding alternative methods that could
                  further improve the design process. In this paper,
                  we explore the effectiveness and extend a formal
                  methodology for hardware design. The method adopts a
                  a step-wise refinement approach that starts
                  development from formal specifications. A functional
                  programming notation is used for specifying
                  algorithms and for reasoning about them. The method
                  is aided by off-the-shelf refinements based on the
                  operators of Communicating Sequential Processes that
                  map easily to programs written in
                  Handel-C. Handel-Cdescriptions are directly compiled
                  into reconfigurable hardware. The practical
                  realization of this methodology is evidenced by a
                  case studying data-parallel implementations of a
                  matrix multiplication algorithm. The developed
                  designs are compiled and tested under Agility's
                  RC-1000 reconfigurable computer with its 2 million
                  gates Virtex-E FPGA. Performance analysis and
                  evaluation of the presented implementations are
                  included.},
  keywords =	 {Visual BASIC;computer aided instruction;computer
                  graphics;educational
                  courses;microcomputers;CGLT;Toolbook;Visual
                  Basic;computer based learning tool;computer graphics
                  courses;expository instructional approach;modern
                  personal computers;multilevel teaching
                  tool;multimedia based teaching package;software
                  design tools;Design methodology;Field programmable
                  gate arrays;Formal specifications;Functional
                  programming;Hardware;Performance analysis;Process
                  design;Programmable logic arrays;Programmable logic
                  devices;Testing;animation;computer
                  graphics;computer-based instruction;simulation},
  doi =		 {10.1109/ICCRD.2010.66},
  month =	 {May},
  review = 	 {fbie: rejected <2016-01-12 15:01:54>},
}

@INPROCEEDINGS{6337524,
  author =	 {Jia-Jhe Li and Chi-Bang Kuan and Tung-Yu Wu and Jenq
                  Kuen Lee},
  booktitle =	 {Parallel Processing Workshops (ICPPW), 2012 41st
                  International Conference on},
  title =	 {Enabling an OpenCL Compiler for Embedded Multicore
                  DSP Systems},
  year =	 2012,
  pages =	 {545-552},
  abstract =	 {OpenCL is an industry's attempt to unify
                  heterogeneous multicore programming. With its
                  programming model defining SPMD kernels, vector
                  types, and address space qualifiers, OpenCL allows
                  programmers to exploit data parallelism with
                  multicore processors and SIMD instructions as well
                  as data locality with memory hierarchy. Recently,
                  OpenCL has gained success on many architectures,
                  including multicore CPUs, GPUs, vector processors,
                  embedded systems with application-specific
                  processors, and even FPGAs. However, how to support
                  OpenCL for embedded multicore DSP systems remains
                  unaddressed. In this paper, we illustrate our OpenCL
                  support for embedded multicore DSP systems. Our
                  target platform consists of one MPU and a DSP
                  subsystem with multiple DSPs. The DSPs we address
                  are VLIW processors with clustered functional units
                  and distributed register files. To generate
                  efficient code for such DSPs, compilers are required
                  to consider irregular register file access in many
                  optimization phases. To utilize the DSPs with
                  distributed register files, we propose a
                  cluster-aware work-item dispatching scheme to
                  vectorize OpenCL kernels and assign independent
                  workload to clusters of a DSP. In addition, we also
                  incorporate several optimizations to enable
                  efficient DSP code generation. In our experiments,
                  we employ a set of OpenCL benchmark programs to
                  evaluate the effectiveness of our OpenCL
                  support. The experiments are conducted on a DSP
                  cycle-accurate simulator and a multicore evaluation
                  board. We report average 29% performance improvement
                  with our vectorization scheme and a near 2-fold
                  speedup with two DSPs compared with a single-MPU
                  setup.},
  keywords =	 {digital signal processing chips;electronic
                  engineering computing;embedded systems;field
                  programmable gate arrays;graphics processing
                  units;multiprocessing systems;operating system
                  kernels;optimising compilers;parallel
                  processing;program compilers;software performance
                  evaluation;DSP code generation;DSP cycle-accurate
                  simulator;DSP subsystem;FPGA;GPU;MPU
                  subsystem;OpenCL benchmark programs;OpenCL
                  compiler;OpenCL kernels;OpenCL support;SIMD
                  instructions;SPMD kernels;VLIW processors;address
                  space qualifiers;application-specific
                  processors;cluster-aware work-item dispatching
                  scheme;clustered functional units;compilers;data
                  locality;data parallelism;distributed register
                  files;embedded multicore DSP systems;embedded
                  systems;heterogeneous multicore
                  programming;independent workload;irregular register
                  file access;memory hierarchy;multicore CPU;multicore
                  evaluation board;multicore processors;optimization
                  phases;performance improvement;programming
                  model;single-MPU setup;vector processors;vector
                  types;vectorization scheme;Digital signal
                  processing;Kernel;Multicore processing;Program
                  processors;Registers;VLIW;Vectors},
  doi =		 {10.1109/ICPPW.2012.74},
  ISSN =	 {1530-2016},
  month =	 {Sept},
  review = 	 {fbie: rejected <2016-01-12 15:02:39>},
}

@INPROCEEDINGS{4228136,
  author =	 {Grelck, C. and Scholz, S.-B. and Shafarenko, A.},
  booktitle =	 {Parallel and Distributed Processing Symposium,
                  2007. IPDPS 2007. IEEE International},
  title =	 {Coordinating Data Parallel SAC Programs with S-Net},
  year =	 2007,
  pages =	 {1-8},
  abstract =	 {We propose a two-layered approach for exploiting
                  different forms of concurrency in complex systems:
                  we specify computational components in our
                  functional array language SAC, which exploits data
                  parallel properties of array processing code. The
                  declarative stream processing language S-Net is used
                  to orchestrate the collaborative behaviour of these
                  components in a streaming network. We illustrate our
                  approach by a hybrid implementation of a sudoku
                  puzzle solver as a representative for more complex
                  search problems.},
  keywords =	 {parallel languages;parallel programming;S-Net;array
                  processing code;data parallel SAC program;functional
                  array language;sudoku puzzle solver;Array signal
                  processing;Collaboration;Concurrent computing;Data
                  structures;Debugging;Parallel languages;Parallel
                  processing;Search problems;Shape;System recovery},
  doi =		 {10.1109/IPDPS.2007.370408},
  month =	 {March},
  review = 	 {fbie: accepted <2016-01-12 15:03:42>},
}

@INPROCEEDINGS{5489391,
  author =	 {Damaj, I.},
  booktitle =	 {Computer Research and Development, 2010 Second
                  International Conference on},
  title =	 {Synthesis of Data-Parallel Algorithms for
                  Programmable Logic Devices},
  year =	 2010,
  pages =	 {98-104},
  abstract =	 {Most of the classifiers suffer from curse of
                  dimensionality during classification of high
                  dimensional image data. In this paper, we introduce
                  a new supervised nonlinear dimensionality reduction
                  (S-NLDR) algorithm called evolutionary strategy
                  based supervised dimensionality reduction
                  (ESSDR). The ESSDR method uses population based
                  evolutionary strategy (ES) algorithm to find low
                  dimensional embedded values of labeled
                  data. Simulation studies on some well-known
                  benchmark image data sets demonstrate that ESSDR
                  produces better results in dimensionality reduction
                  of labeled data as compare to other famous S-NDLR
                  methods such as Weighted so, supervised locally
                  linear embedding (SLLE), enhanced supervised locally
                  linear embedding (ESLLE) and supervised local
                  tangent space alignment (SLTSA).},
  keywords =	 {evolutionary computation;parallel
                  algorithms;programmable logic devices;ESSDR
                  method;S-NDLR methods;S-NLDR algorithm;data parallel
                  algorithm synthesis;enhanced supervised locally
                  linear embedding;evolutionary strategy based
                  supervised dimensionality reduction;high dimensional
                  image data;population based evolutionary
                  strategy;programmable logic devices;supervised local
                  tangent space alignment;supervised locally linear
                  embedding;supervised nonlinear dimensionality
                  reduction;Design methodology;Field programmable gate
                  arrays;Functional programming;Hardware;Parallel
                  processing;Performance analysis;Power engineering
                  computing;Process design;Programmable logic
                  arrays;Programmable logic devices;Data
                  Encryption;Formal Models;Gate Array;Hardware
                  Design;Parallel computing;Software Engineering},
  doi =		 {10.1109/ICCRD.2010.65},
  month =	 {May},
  review = 	 {fbie: rejected <2016-01-12 15:04:13>},
}

@INPROCEEDINGS{6412155,
  author =	 {Hee-Seok Kim and Minwook Ahn and Stratton, J.A. and
                  Hwu, W.W.},
  booktitle =	 {Field-Programmable Technology (FPT), 2012
                  International Conference on},
  title =	 {Design evaluation of OpenCL compiler framework for
                  Coarse-Grained Reconfigurable Arrays},
  year =	 2012,
  pages =	 {313-320},
  abstract =	 {OpenCL is undoubtedly becoming one of the most
                  popular parallel programming languages as it
                  provides a standardized and portable programming
                  model. However, adopting OpenCL for Coarse-Grained
                  Reconfigurable Arrays (CGRA) is challenging due to
                  divergent architecture capability compared to
                  GPUs. In particular, CGRAs are designed to
                  accelerate loop execution by software pipelining on
                  a grid of functional units exploiting
                  instruction-level parallelism. This is vastly
                  different from a GPU in that it executes data
                  parallel kernels using a large number of parallel
                  threads. Therefore, an OpenCL compiler and runtime
                  for CGRAs must map the threaded parallel programming
                  model to a loop-parallel execution model so that the
                  architecture can best utilize its resources. In this
                  paper, we propose and evaluate a design for an
                  OpenCL compiler framework for CGRAs. The proposed
                  design is composed of a serializer and post
                  optimizer. The serializer transforms parallel
                  execution of work-items to an equivalent loop-based
                  iterative execution in order to avoid expensive
                  multithreading on CGRAs. The resulting code is
                  further optimized by the post optimizer to maximize
                  the coverage of software-pipelinable innermost
                  loops. In order to achieve the goal, various
                  loop-level optimizations can take place in the post
                  optimizer using the loops introduced by the
                  serializer for iterative execution of OpenCL
                  kernels. We provide an analysis of the propose
                  framework from a set of well-studied standard OpenCL
                  kernels by comparing performance of various
                  implementations of benchmarks.},
  keywords =	 {multi-threading;optimising compilers;parallel
                  languages;pipeline processing;reconfigurable
                  architectures;software performance
                  evaluation;CGRA;OpenCL compiler
                  framework;coarse-grained reconfigurable arrays;data
                  execution;design evaluation;functional unit
                  grid;innermost loop coverage
                  maximization;instruction-level parallelism;iterative
                  OpenCL kernel execution;loop-based iterative
                  execution;loop-level optimizations;loop-parallel
                  execution model;multithreading;parallel
                  kernels;parallel programming languages;parallel
                  threads;portable programming model;post
                  optimizer;serializer;software
                  pipelining;standardized programming model;threaded
                  parallel programming model;Computer
                  architecture;Graphics processing
                  units;Hardware;Kernel;Optimization;Programming;CGRA;Coarse-Grained
                  Reconfigurable Arrays;GPU;OpenCL;RP;SRP;Samsung
                  Reconfigurable Processor},
  doi =		 {10.1109/FPT.2012.6412155},
  month =	 {Dec},
  review = 	 {fbie: rejected <2016-01-12 15:05:55>},
}

@INPROCEEDINGS{367042,
  author =	 {Shafarenko, A.V.},
  booktitle =	 {Massively Parallel Computing Systems, 1994.,
                  Proceedings of the First International Conference
                  on},
  title =	 {RETRAN: a recurrent paradigm for massively parallel
                  array computing},
  year =	 1994,
  pages =	 {478-487},
  abstract =	 {An applicative paradigm of parallel array processing
                  based on recurrence relations and a data-parallel
                  overloading of constants is presented. It is shown
                  that the suggested principle of anti-currying
                  together with introduction of function-based, eager
                  arrays result in a denotational system superior to
                  array extensions of pragmatic languages in that it
                  can exploit spatial symmetries of arrays to unify
                  the notation. The main novelty here is completely
                  asynchronous treatment of arrays of arrow types
                  (arrays of possibly array-valued functions) which
                  lends itself nicely to a massively parallel
                  data-flow implementation with yet static scheduling
                  due to the imposed strictness of the array
                  constructor. The evolution of data is defined in the
                  tradition form of stream transformation},
  keywords =	 {data flow computing;parallel processing;parallel
                  programming;RETRAN;anti-currying;array-valued
                  functions;arrays;massively parallel array
                  computing;massively parallel data-flow;pragmatic
                  languages;recurrent paradigm;stream
                  transformation;Algebra;Concurrent
                  computing;Functional programming;Genetic
                  programming;Hardware;Parallel processing;Parallel
                  programming;Processor scheduling;Programming
                  profession;Skeleton},
  doi =		 {10.1109/MPCS.1994.367042},
  month =	 {May},
  review = 	 {fbie: accepted <2016-01-12 15:07:18>},
}
