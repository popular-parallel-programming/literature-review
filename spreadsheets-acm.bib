@inproceedings{Karlsson:2008:UTH:1370847.1370857,
  author =	 {Karlsson, Fredrik},
  title =	 {Using Two Heads in Practice},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {43--47},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370857},
  doi =		 {10.1145/1370847.1370857},
  acmid =	 1370857,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user computing, end user development, error
                  rates, pair programming},
  abstract = 	 {Group development has been proposed as a way of improving quality in end user development. Earlier experiments have shown promising results on error rates. However, these studies have been carried out on students, often, in laboratory settings. This study reports on a field experiment on group development during spreadsheeting. Experienced business managers have been working alone (monads) and in groups of two (dyads), solving a context specific problem. The results show that dyads made 36\% fewer errors than monads. Hence, the results verify earlier findings and that group development can be recommended as a technique to include in end user development processes to improve quality.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370857&ftid=498654&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 12:52:37>},
}

@inproceedings{Singer:2010:TCP:1944999.1945011,
  author =	 {Singer, Leif},
  title =	 {Towards Communities of Practice for Mashups},
  booktitle =	 {Proceedings of the 3rd and 4th International
                  Workshop on Web APIs and Services Mashups},
  series =	 {Mashups '09/'10},
  year =	 2010,
  isbn =	 {978-1-4503-0418-4},
  location =	 {Ayia Napa, Cyprus},
  pages =	 {12:1--12:4},
  articleno =	 12,
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1944999.1945011},
  doi =		 {10.1145/1944999.1945011},
  acmid =	 1945011,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user development, integration, mashups,
                  services, social software},
  abstract = 	 {Many integration projects in enterprises are too small to warrant their own implementation by IT. This leaves a "long tail of enterprise integration" unaccounted for. To exploit this potential, this position paper proposes a Community of Practice for end user development whose members will be able to solve their integration needs on their own. In particular, we want to combine a spreadsheet-oriented, browser-based mashup tool with a social network site designed as a company-internal collaboration platform. This should permit many small local integration projects to be performed by end users. Employee needs that were too expensive to consider before would then be satisfiable.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1945011&ftid=913851&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:02:35>},
}

@inproceedings{Singer:2011:SCE:1984701.1984704,
  author =	 {Singer, Leif and Schneider, Kurt},
  title =	 {Supporting the Cooperation of End-user Programmers
                  Through Social Development Environments},
  booktitle =	 {Proceedings of the 2Nd International Workshop on Web
                  2.0 for Software Engineering},
  series =	 {Web2SE '11},
  year =	 2011,
  isbn =	 {978-1-4503-0595-2},
  location =	 {Waikiki, Honolulu, HI, USA},
  pages =	 {13--18},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1984701.1984704},
  doi =		 {10.1145/1984701.1984704},
  acmid =	 1984704,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {community of practice, end-user development,
                  mashups, services, social software},
  abstract = 	 {Many programs are being created by end-users without formal training in programming. Spreadsheets are the most popular environment for this, but mashups which combine public services into new, albeit small applications are also becoming more and more popular. Research shows that end-user programmers make potentially costly mistakes. Yet initiatives that aim at bringing software engineering principles to end-users are still rudimentary. In particular, we see much unused potential in approaches that foster and support the cooperation among end-user programmers. Whereas the application of mechanisms from social software to software engineering problems is gaining traction, this has not yet been investigated sufficiently for end-user software engineering. This paper discusses how insights from Communities of Practice research may be implemented using mechanisms from recent developments in social software. From the implementation of the presented social mechanisms, we expect an improvement in cooperation and mutual help in communities of end-user programmers. We plan to combine this approach with lightweight variations of software engineering methods targeted at end-user programmers. This should lead to higher quality in the programs developed by these end-users, as good practices are more likely to spread.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1984704&ftid=969690&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:02:50>},
}

@inproceedings{Repenning:2008:AWE:1385569.1385614,
  author =	 {Repenning, Alexander and Ioannidou, Andri},
  title =	 {Agent Warp Engine: Formula Based Shape Warping for
                  Networked Applications},
  booktitle =	 {Proceedings of the Working Conference on Advanced
                  Visual Interfaces},
  series =	 {AVI '08},
  year =	 2008,
  isbn =	 {978-1-60558-141-5},
  location =	 {Napoli, Italy},
  pages =	 {279--286},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1385569.1385614},
  doi =		 {10.1145/1385569.1385614},
  acmid =	 1385614,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {3D graphics, collective simulations, end-user
                  development, end-user programming, real-time image
                  warping, spreadsheets},
  abstract = 	 {Computer visualization and networking have advanced dramatically. 3D hardware acceleration has reached the point where even low-power handheld computers can render and animate complex 3D graphics efficiently. Unfortunately, end-user computing does not yet provide the necessary tools and conceptual frameworks to let end-users access these technologies and build their own networked interactive 2D and 3D applications such as rich visualizations, animations and simulations. The Agent Warp Engine (AWE) is a formula-based shape-warping framework that combines end-user visualization and end-user networking. AWE is a spreadsheet-inspired framework based on Web sharable variables. To build visualizations, users define these variables, relate them through equations and connect them to 2D and 3D shapes. In addition to basic shape control such as rotation, size, and location, AWE enables the creation of rich shape warping visualizations. We motivate the AWE approach with the Mr. Vetro human physiology simulation supporting collaborative learning through networked handheld computers.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1385614&ftid=544775&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:04:35>},
}

@inproceedings{Kissinger:2006:SED:1133265.1133293,
  author =	 {Kissinger, Cory and Burnett, Margaret and Stumpf,
                  Simone and Subrahmaniyan, Neeraja and Beckwith,
                  Laura and Yang, Sherry and Rosson, Mary Beth},
  title =	 {Supporting End-user Debugging: What Do Users Want to
                  Know?},
  booktitle =	 {Proceedings of the Working Conference on Advanced
                  Visual Interfaces},
  series =	 {AVI '06},
  year =	 2006,
  isbn =	 {1-59593-353-0},
  location =	 {Venezia, Italy},
  pages =	 {135--142},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1133265.1133293},
  doi =		 {10.1145/1133265.1133293},
  acmid =	 1133293,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user debugging, end-user development, end-user
                  programming, end-user software engineering, online
                  help},
  abstract = 	 {Although researchers have begun to explicitly support end-user programmers' debugging by providing information to help them find bugs, there is little research addressing the right content to communicate to these users. The specific semantic content of these debugging communications matters because, if the users are not actually seeking the information the system is providing, they are not likely to attend to it. This paper reports a formative empirical study that sheds light on what end users actually want to know in the course of debugging a spreadsheet, given the availability of a set of interactive visual testing and debugging features. Our results provide in sights into end-user debuggers' information gaps, and further suggest opportunities to improve end-user debugging systems' support for the things end-user debuggers actually want to know.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1133293&ftid=354868&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:04:44>},
}

@article{Ko:2011:SAE:1922649.1922658,
  author =	 {Ko, Andrew J. and Abraham, Robin and Beckwith, Laura
                  and Blackwell, Alan and Burnett, Margaret and Erwig,
                  Martin and Scaffidi, Chris and Lawrance, Joseph and
                  Lieberman, Henry and Myers, Brad and Rosson, Mary
                  Beth and Rothermel, Gregg and Shaw, Mary and
                  Wiedenbeck, Susan},
  title =	 {The State of the Art in End-user Software
                  Engineering},
  journal =	 {ACM Comput. Surv.},
  issue_date =	 {April 2011},
  volume =	 43,
  number =	 3,
  month =	 apr,
  year =	 2011,
  issn =	 {0360-0300},
  pages =	 {21:1--21:44},
  articleno =	 21,
  numpages =	 44,
  url =		 {http://doi.acm.org/10.1145/1922649.1922658},
  doi =		 {10.1145/1922649.1922658},
  acmid =	 1922658,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {End-user software engineering, end-user development,
                  end-user programming, human-computer interaction,
                  visual programming},
  abstract = 	 {Most programs today are written not by professional software developers, but by people with expertise in other domains working towards goals for which they need computational support. For example, a teacher might write a grading spreadsheet to save time grading, or an interaction designer might use an interface builder to test some user interface design ideas. Although these end-user programmers may not have the same goals as professional developers, they do face many of the same software engineering challenges, including understanding their requirements, as well as making decisions about design, reuse, integration, testing, and debugging. This article summarizes and classifies research on these activities, defining the area of End-User Software Engineering (EUSE) and related terminology. The article then discusses empirical research about end-user software engineering activities and the technologies designed to support them. The article also addresses several crosscutting issues in the design of EUSE tools, including the roles of risk, reward, and domain complexity, and self-efficacy in the design of EUSE tools and the potential of educating users about software engineering principles.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1922658&ftid=926505&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:04:52>},
}

@article{Fischer:2004:MME:1015864.1015884,
  author =	 {Fischer, G. and Giaccardi, E. and Ye, Y. and
                  Sutcliffe, A. G. and Mehandjiev, N.},
  title =	 {Meta-design: A Manifesto for End-user Development},
  journal =	 {Commun. ACM},
  issue_date =	 {September 2004},
  volume =	 47,
  number =	 9,
  month =	 sep,
  year =	 2004,
  issn =	 {0001-0782},
  pages =	 {33--37},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1015864.1015884},
  doi =		 {10.1145/1015864.1015884},
  acmid =	 1015884,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {End-user development (EUD) activities range from customization to component configuration and programming. Office software, such as the ubiquitous spreadsheet, provides customization facilities, while the growth of the Web has added impetus to end-user scripting for interactive functions in Web sites. In scientific and engineering domains, end users frequently develop complex systems with standard programming languages such as C++ and Java. However, only a minority of users adapt commercial off-the-shelf (COTS) software products. Indeed, composing systems from reusable components, such as enterprise resource planing (ERP) systems, defeats most end users who resort to expensive and scarce expert developers for implementation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1015884&ftid=273972&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:04:56>},
}

@inproceedings{Costabile:2010:EDS:1842993.1843078,
  author =	 {Costabile, Maria Francesca and De Ruyter, Boris and
                  Mehandjiev, Nikolay and Mussio, Piero},
  title =	 {End-user Development of Software Services and
                  Applications},
  booktitle =	 {Proceedings of the International Conference on
                  Advanced Visual Interfaces},
  series =	 {AVI '10},
  year =	 2010,
  isbn =	 {978-1-4503-0076-6},
  location =	 {Roma, Italy},
  pages =	 {403--407},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1842993.1843078},
  doi =		 {10.1145/1842993.1843078},
  acmid =	 1843078,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ambient intelligence, annotations, component-based
                  systems, design pattern, end-user composition,
                  end-user development, household appliance,
                  meta-design, process modeling, service composition
                  approaches, service-oriented architectures, web
                  services},
  abstract = 	 {End-User Development (EUD) has traditionally been focusing on non-programmers tailoring or even creating software artifacts, often in organizational context. Some examples of successful EUD concepts include spreadsheet and word processing macros and the specification of e-mail filters by means of rules. Recent developments, such as Web 2.0 and Semantic Web, which enable end users to be contributors rather than just consumers of information on the WWW, have renewed interest in EUD research and applications. This trend is now moving from content and personalization to functionality in the direction of user-generated web services. Various on-going projects are already considering this new trend, but primarily from a technology perspective. The workshop aims at establishing a new forum for discussion and fruitful cross-fertilization of ideas among all the communities that can contribute to and benefit from allowing end users to generate web services: human-computer interaction, software engineering, artificial intelligence, computer-supported cooperative work and innovation management.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1843078&ftid=829047&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:05:00>},
}

@inproceedings{Ruhi:2014:PPE:2656450.2656490,
  author =	 {Ruhi, Umar},
  title =	 {Prospects \&\#38; Practices for End-user Development
                  Activities in Business Computing Education},
  booktitle =	 {Proceedings of the 15th Annual Conference on
                  Information Technology Education},
  series =	 {SIGITE '14},
  year =	 2014,
  isbn =	 {978-1-4503-2686-5},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {1--2},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2656450.2656490},
  doi =		 {10.1145/2656450.2656490},
  acmid =	 2656490,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {EUD, education, end-user development, information
                  literacy, information science, information systems,
                  pedagogy},
  abstract = 	 {Many academic courses geared towards improving computer and information literacy (CIL) among non-IT specialists draw upon end-user development (EUD) activities where the end-user assumes a central role in creating or modifying software artefacts. Traditional examples of EUD in educational contexts include exploring and manipulating features and functions in software packages such as spreadsheets &#38; databases, working with simulations, developing websites, utilizing content feeds from a variety of information sources, and creating mashups and widgets with diverse functionality. Although the benefits of improving computing education with EUD practices has been acknowledged in the extant literature, guidelines for the inclusion of EUD-based tasks and tools in academic programs have not been documented in as much detail. The objective of this workshop is to discuss and demonstrate use-cases for EUD based pedagogical components in business computing education, especially so as to meet the objectives set out in model curricula by ACM and AIS.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2656490&ftid=1505388&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:05:08>},
}

@article{Burnett:2004:ESE:1015864.1015889,
  author =	 {Burnett, Margaret and Cook, Curtis and Rothermel,
                  Gregg},
  title =	 {End-user Software Engineering},
  journal =	 {Commun. ACM},
  issue_date =	 {September 2004},
  volume =	 47,
  number =	 9,
  month =	 sep,
  year =	 2004,
  issn =	 {0001-0782},
  pages =	 {53--58},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1015864.1015889},
  doi =		 {10.1145/1015864.1015889},
  acmid =	 1015889,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {End-user programming has become the most common form of programming in use today [2], but there has been little investigation into the dependability of the programs end users create. This is problematic because the dependability of these programs can be very important; in some cases, errors in end-user programs, such as formula errors in spreadsheets, have cost millions of dollars. (For example, see www.theregister.co.uk/content/67/31298.html or panko.cba.hawaii.edu/ssr/Mypapers/whatknow.htm.) We have been investigating ways to address this problem by developing a software engineering paradigm viable for end-user programming, an approach we call end-user software engineering.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1015889&ftid=273977&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:05:25>},
}

@inproceedings{Myers:2010:EUS:1753846.1753953,
  author =	 {Myers, Brad A. and Burnett, Margaret M. and Ko,
                  Andrew J. and Rosson, Mary Beth and Scaffidi,
                  Christopher and Wiedenbeck, Susan},
  title =	 {End User Software Engineering: CHI 2010 Special
                  Interest Group Meeting},
  booktitle =	 {CHI '10 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '10},
  year =	 2010,
  isbn =	 {978-1-60558-930-5},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {3189--3192},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1753846.1753953},
  doi =		 {10.1145/1753846.1753953},
  acmid =	 1753953,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programmers (esp), end users
                  shaping effective software (euses), end-user
                  development (eud), end-user software engineering
                  (euse), natural programming, psychology of
                  programming, web authoring},
  abstract = 	 {End users create software whenever they create, for instance, interactive web pages, games, educational simulations, or spreadsheets. Researchers are working to bring the benefits of rigorous software engineering methodologies to these end users to try to make their software more reliable. Unfortunately, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. This special interest group meeting will bring together the community of researchers who are addressing this topic with the companies that are creating and using end-user programming tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1753953&ftid=773747&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:05:36>},
}

@inproceedings{Myers:2009:EUS:1520340.1520393,
  author =	 {Myers, Brad A. and Burnett, Margaret M. and
                  Wiedenbeck, Susan and Ko, Andrew J. and Rosson, Mary
                  Beth},
  title =	 {End User Software Engineering: CHI: 2009 Special
                  Interest Group Meeting},
  booktitle =	 {CHI '09 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '09},
  year =	 2009,
  isbn =	 {978-1-60558-247-4},
  location =	 {Boston, MA, USA},
  pages =	 {2731--2734},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1520340.1520393},
  doi =		 {10.1145/1520340.1520393},
  acmid =	 1520393,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programmers (ESP), end users
                  shaping effective software (EUSES), end-user
                  development (EUD), end-user software engineering
                  (EUSE), natural programming, psychology of
                  programming},
  abstract = 	 {End users create software whenever they write, for instance, educational simulations, spreadsheets, or dynamic e-business web applications. Researchers are working to bring the benefits of rigorous software engineering methodologies to these end users to try to make their software more reliable. Unfortunately, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. This special interest group meeting will bring together the community of researchers who are addressing this topic with the companies that are creating and using end-user programming tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1520393&ftid=642556&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:05:40>},
}

@inproceedings{Sestoft:2008:IFS:1370847.1370867,
  author =	 {Sestoft, Peter},
  title =	 {Implementing Function Spreadsheets},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {91--94},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1370847.1370867},
  doi =		 {10.1145/1370847.1370867},
  acmid =	 1370867,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {function spreadsheet},
  abstract = 	 {A large amount of end-user development is done with spreadsheets. The spreadsheet metaphor is attractive because it is visual and accommodates interactive experimentation, but as observed by Peyton Jones, Blackwell and Burnett, the spreadsheet metaphor does not admit even the most basic abstraction: that of turning an expression into a named function. Hence they proposed a way to define a function in terms of a worksheet with designated input and output cells; we shall call it a function sheet. The goal of our work is to develop implementations of function sheets and study their application to realistic examples. Therefore, we are also developing a simple yet comprehensive spreadsheet core implementation for experimentation with this technology. Here we report briefly on our experiments with function sheets as well as other uses of our spreadsheet core implementation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370867&ftid=498664&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:05:45>},
}

@inproceedings{Bishop:2008:SDB:1370847.1370860,
  author =	 {Bishop, Brian and McDaid, Kevin},
  title =	 {Spreadsheet Debugging Behaviour of Expert and Novice
                  End-users},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {56--60},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370860},
  doi =		 {10.1145/1370847.1370860},
  acmid =	 1370860,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, spreadsheet debugging},
  abstract = 	 {In recent years the reliability of end-user developed spreadsheet programs has been shown to be very poor. Surprisingly, relatively little research has been carried out in the areas of spreadsheet testing and debugging. With the aim of recording and analysing end-user behaviour and performance in spreadsheet error detection and correction, an experiment was conducted with 13 industry-based professionals and 34 accounting & finance students. The work utilised a novel approach for acquiring experimental data through the unobtrusive recording of participants debugging actions using a custom built VBA tool. Based on the findings from analysis of debugging behaviour, a simple debugging tool was developed by the authors, and its effects on debugging performance were investigated by means of a controlled experiment.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370860&ftid=498657&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:06:47>},
}

@inproceedings{Ayalew:2009:VAI:1527033.1527038,
  author =	 {Ayalew, Yirsaw},
  title =	 {A Visualization-based Approach for Improving
                  Spreadsheet Quality},
  booktitle =	 {Proceedings of the Warm Up Workshop for ACM/IEEE
                  ICSE 2010},
  series =	 {WUP '09},
  year =	 2009,
  isbn =	 {978-1-60558-565-9},
  location =	 {Cape Town, South Africa},
  pages =	 {13--16},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1527033.1527038},
  doi =		 {10.1145/1527033.1527038},
  acmid =	 1527038,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {spreadsheet, spreadsheet quality, spreadsheet
                  understanding, visualization},
  abstract = 	 {Spreadsheet programs, artefacts developed by end-user programmers, are used for a variety of important tasks and decisions. However, as the literature indicates, a significant proportion of spreadsheet programs contain faults. One of the contributing factors to the quality issue is the invisibility of cell dependencies (which define the dataflow structure of a spreadsheet) up on which computations are performed. In an attempt to provide a guide in understanding spreadsheets, this paper presents an approach to visualize a spreadsheet in terms of logical areas using the MCL (Markov Clustering) algorithm. Instead of focusing their attention on the whole spreadsheet, spreadsheet users may narrow their focus to one logical area at a time. To evaluate our approach, a prototype tool has been developed and integrated into Microsoft Excel.},
  review = 	 {fbie: accepted <2016-01-15 13:07:05>},
}

@inproceedings{McDaid:2008:TDW:1370847.1370853,
  author =	 {McDaid, Kevin and Rust, Alan and Bishop, Brian},
  title =	 {Test-driven Development: Can It Work for
                  Spreadsheets?},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {25--29},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370853},
  doi =		 {10.1145/1370847.1370853},
  acmid =	 1370853,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {spreadsheet development., test-driven development},
  abstract = 	 {It is widely documented that the absence of a structured approach to spreadsheet engineering is a key factor in the high level of spreadsheet errors. In this paper we propose and investigate the application of Test-Driven Development to the creation of spreadsheets. Test-Driven Development is an emerging development technique in software engineering that has been shown to result in better quality software code. It has also been shown that this code requires less testing and is easier to maintain. Through a set of case studies we demonstrate that Test-Driven Development can be applied to the development of spreadsheets. We present the detail of these studies preceded by a clear explanation of the technique and its application to spreadsheet engineering. A supporting tool under development by the authors is also documented along with proposed research to determine the effectiveness of the methodology and the associated tool.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370853&ftid=498650&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:08:12>},
}

@inproceedings{Ruthruff:2005:ESF:1062455.1062523,
  author =	 {Ruthruff, Joseph R. and Burnett, Margaret and
                  Rothermel, Gregg},
  title =	 {An Empirical Study of Fault Localization for
                  End-user Programmers},
  booktitle =	 {Proceedings of the 27th International Conference on
                  Software Engineering},
  series =	 {ICSE '05},
  year =	 2005,
  isbn =	 {1-58113-963-2},
  location =	 {St. Louis, MO, USA},
  pages =	 {352--361},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1062455.1062523},
  doi =		 {10.1145/1062455.1062523},
  acmid =	 1062523,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, end-user programming, end-user software
                  engineering, fault localization},
  abstract = 	 {End users develop more software than any other group of programmers, using software authoring devices such as e-mail filtering editors, by-demonstration macro builders, and spreadsheet environments. Despite this, there has been little research on finding ways to help these programmers with the dependability of their software. We have been addressing this problem in several ways, one of which includes supporting end-user debugging activities through fault localization techniques. This paper presents the results of an empirical study conducted in an end-user programming environment to examine the impact of two separate factors in fault localization techniques that affect technique effectiveness. Our results shed new insights into fault localization techniques for end-user programmers and the factors that affect them, with significant implications for the evaluation of those techniques.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1062523&ftid=315708&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:07:27>},
}

@inproceedings{Baglietto:2010:ADS:1944999.1945007,
  author =	 {Baglietto, Pierpaolo and Cosso, Fabrizio and
                  Fornasa, Martino and Mangiante, Simone and Maresca,
                  Massimo and Parodi, Andrea and Stecca, Michele},
  title =	 {Always-on Distributed Spreadsheet Mashups},
  booktitle =	 {Proceedings of the 3rd and 4th International
                  Workshop on Web APIs and Services Mashups},
  series =	 {Mashups '09/'10},
  year =	 2010,
  isbn =	 {978-1-4503-0418-4},
  location =	 {Ayia Napa, Cyprus},
  pages =	 {8:1--8:8},
  articleno =	 8,
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1944999.1945007},
  doi =		 {10.1145/1944999.1945007},
  acmid =	 1945007,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user programming, spreadsheet mashups},
  abstract = 	 {We present a platform that supports the creation of distributed data Mashups, implemented through the composition of multiple spreadsheets. The basic idea is to link cell ranges belonging to different spreadsheets in such a way to come up with a distributed spreadsheet. While such a behavior is already supported in private file spaces, our platform extends the operating principle and the functionality to the Internet in a secure way, using a SOA infrastructure as a communication bus. The platform consists of a client component, installed as a Plug-in in spreadsheet applications, and of a server component, accessible as a Web Service, that orchestrates the data exchanges among the client spreadsheets. One of the most original functionalities provided by the platform and described in the paper is that of guaranteeing the propagation of values along chains of linked spreadsheets even when some of the component spreadsheets are off-line. In addition to the description of the platform the paper also includes the description of a Spreadsheet Mashup framework specifically suited to hierarchical organizations such as those of enterprises. The architecture of the framework is presented in the light of a real-life example.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1945007&ftid=913847&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:07:33>},
}

@article{Johnson:1993:ABI:255950.153576,
  author =	 {Johnson, Jeff A. and Nardi, Bonnie A. and Zarmer,
                  Craig L. and Miller, James R.},
  title =	 {ACE: Building Interactive Graphical Applications},
  journal =	 {Commun. ACM},
  issue_date =	 {April 1993},
  volume =	 36,
  number =	 4,
  month =	 apr,
  year =	 1993,
  issn =	 {0001-0782},
  pages =	 {40--55},
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/255950.153576},
  doi =		 {10.1145/255950.153576},
  acmid =	 153576,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {UI, UIMS, spreadsheet, toolkit},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=153576&ftid=32043&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:07:38>},
}

@article{Gupta:1994:SCQ:181840.181843,
  author =	 {Gupta, Surendra M. and Karaesmen, Fikri},
  title =	 {Solution to Complex Queueing Systems: A Spreadsheet
                  Approach},
  journal =	 {SIGMETRICS Perform. Eval. Rev.},
  issue_date =	 {April 1994},
  volume =	 21,
  number =	 {3-4},
  month =	 apr,
  year =	 1994,
  issn =	 {0163-5999},
  pages =	 {33--46},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/181840.181843},
  doi =		 {10.1145/181840.181843},
  acmid =	 181843,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {queueing systems, spreadsheets},
  abstract = 	 {In this paper, some very useful and applicable ideas are presented to facilitate solving complex problems in Queueing Theory. It is demonstrated how a spreadsheet can be used to solve problems which many practitioners find very intimidating. To this end an algorithm is presented which is particularly designed for easy implementation in a spreadsheet. A template is provided illustrating the implementation of the algorithm. The use of the template is demonstrated in various queueing applications.},
  review = 	 {fbie: rejected <2016-01-15 13:07:47>},
}

@inproceedings{Hermans:2014:BRE:2635868.2661673,
  author =	 {Hermans, Felienne and Dig, Danny},
  title =	 {BumbleBee: A Refactoring Environment for Spreadsheet
                  Formulas},
  booktitle =	 {Proceedings of the 22Nd ACM SIGSOFT International
                  Symposium on Foundations of Software Engineering},
  series =	 {FSE 2014},
  year =	 2014,
  isbn =	 {978-1-4503-3056-5},
  location =	 {Hong Kong, China},
  pages =	 {747--750},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2635868.2661673},
  doi =		 {10.1145/2635868.2661673},
  acmid =	 2661673,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, spreadsheets, transformation},
  abstract = 	 {Spreadsheets are widely used in industry. It is estimated that end-user programmers outnumber regular programmers by a factor of 5. However, spreadsheets are error-prone: several reports exist of companies that have lost big sums of money due to spreadsheet errors. In previous work, spreadsheet smells have proven to be the cause of some of these errors. To that end, we have developed a tool that can apply refactorings to spreadsheet formulas, implementing our previous work on spreadsheet refactoring, which showed that spreadsheet formula smells are very common and that refactorings for them are widely applicable and that refactoring them with a tool is both quicker and less error-prone. Our new tool Bumblebee is able to execute refactorings originating from both these papers, by means of an extensible syntax, and can furthermore apply refactorings on entire groups of formulas, thus improving upon the existing tool RefBook. Finally, BumbleBee can also execute transformations other than refactorings.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2661673&ftid=1510907&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:07:59>},
}

@article{Rothermel:2001:MTS:366378.366385,
  author =	 {Rothermel, Gregg and Burnett, Margaret and Li, Lixin
                  and Dupuis, Christopher and Sheretov, Andrei},
  title =	 {A Methodology for Testing Spreadsheets},
  journal =	 {ACM Trans. Softw. Eng. Methodol.},
  issue_date =	 {Jan. 2001},
  volume =	 10,
  number =	 1,
  month =	 jan,
  year =	 2001,
  issn =	 {1049-331X},
  pages =	 {110--147},
  numpages =	 38,
  url =		 {http://doi.acm.org/10.1145/366378.366385},
  doi =		 {10.1145/366378.366385},
  acmid =	 366385,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {software testing, spreadsheets},
  abstract = 	 {Spreadsheet languages, which include commercial spreadsheets and various research systems, have had a substantial impact on end-user computing. Research shows, however, that spreadsheets often contain faults; thus, we would like to provide at least some of the benefits of formal testing methodologies to the creators of spreadsheets. This article presents a testing methodology that adapts data flow adequacy criteria and coverage monitoring to the task of testing spreadsheets. To accommodate the evaluation model used with spreadsheets, and the interactive process by which they are created, our methodology is incremental. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing theory. We have  implemented our testing methodology in the context of the Forms/3 visual spreadsheet language. We report  on the methodology, its time and space costs, and the mapping from the testing strategy to the user interface. In an empirical study, we found that test suites created according to our methodology detected, on average, 81\% of the faults in a set of faulty spreadsheets, significantly outperforming randomly generated test suites.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=366385&ftid=51506&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:08:17>},
}

@inproceedings{Cunha:2012:RCU:2245276.2231957,
  author =	 {Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and
                  Saraiva, Jo\~{a}o},
  title =	 {From Relational ClassSheets to UML+OCL},
  booktitle =	 {Proceedings of the 27th Annual ACM Symposium on
                  Applied Computing},
  series =	 {SAC '12},
  year =	 2012,
  isbn =	 {978-1-4503-0857-1},
  location =	 {Trento, Italy},
  pages =	 {1151--1158},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2245276.2231957},
  doi =		 {10.1145/2245276.2231957},
  acmid =	 2231957,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ClassSheets, OCL, UML, spreadsheets},
  abstract = 	 {Spreadsheets are among the most popular programming languages in the world. Unfortunately, spreadsheet systems were not tailored from scratch with modern programming language features that guarantee, as much as possible, program correctness. As a consequence, spreadsheets are populated with unacceptable amounts of errors. In other programming language settings, model-based approaches have been proposed to increase productivity and program effectiveness. Within spreadsheets, this approach has also been followed, namely by ClassSheets. In this paper, we propose an extension to ClassSheets to allow the specification of spreadsheets that can be viewed as relational databases. Moreover, we present a transformation from ClassSheet models to UML class diagrams enriched with OCL constraints. This brings to the spreadsheet realm the entire paraphernalia of model validation techniques that are available for UML.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2231957&ftid=1224068&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:08:37>},
}

@inproceedings{Hung:2011:SCD:2063576.2063829,
  author =	 {Hung, Vu and Benatallah, Boualem and Saint-Paul,
                  Regis},
  title =	 {Spreadsheet-based Complex Data Transformation},
  booktitle =	 {Proceedings of the 20th ACM International Conference
                  on Information and Knowledge Management},
  series =	 {CIKM '11},
  year =	 2011,
  isbn =	 {978-1-4503-0717-8},
  location =	 {Glasgow, Scotland, UK},
  pages =	 {1749--1754},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2063576.2063829},
  doi =		 {10.1145/2063576.2063829},
  acmid =	 2063829,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data transformation, spreadsheets},
  abstract = 	 {Spreadsheets are used by millions of users as a routine all-purpose data management tool. It is now increasingly necessary for external applications and services to consume spreadsheet data. In this paper, we investigate the problem of transforming spreadsheet data to structured formats required by these applications and services. Unlike prior methods, we propose a novel approach in which transformation logic is embedded into a familiar and expressive spreadsheet-like formula mapping language. Popular transformation patterns provided by transformation languages and mapping tools, that are relevant to spreadsheet-based data transformation, are supported in the language via formulas. Consequently, the language avoids cluttering the source spreadsheets with transformations and turns out to be helpful when multiple schemas are targeted. We implemented a prototype and evaluated the benefits of our approach via experiments in a real application. The experimental results confirmed the benefits of our approach.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2063829&ftid=1054760&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:09:21>},
}

@inproceedings{Joharizadeh:2015:FBS:2814189.2815373,
  author =	 {Joharizadeh, Nima},
  title =	 {Finding Bugs in Spreadsheets Using Reference
                  Counting},
  booktitle =	 {Companion Proceedings of the 2015 ACM SIGPLAN
                  International Conference on Systems, Programming,
                  Languages and Applications: Software for Humanity},
  series =	 {SPLASH Companion 2015},
  year =	 2015,
  isbn =	 {978-1-4503-3722-9},
  location =	 {Pittsburgh, PA, USA},
  pages =	 {73--74},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2814189.2815373},
  doi =		 {10.1145/2814189.2815373},
  acmid =	 2815373,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Automated Testing, Spreadsheet testing},
  abstract = 	 {Spreadsheets are considered one of the most widely used end-user programming environments. Just as it is important for software to be free of bugs, spreadsheets need to be free of errors. This is important because in some cases, errors in spreadsheets can cost a financial entity thousands of dollars. In this work, we formulate a class of commonplace errors based on our manual inspection of real life spreadsheets, and further provide an analysis algorithm to detect these errors. We introduce ``reference counting&#039;&#039; as a simple yet effective algorithm to detect range errors. We finally demonstrate how reference counting can effectively point out erroneous cells in faulty spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2815373&ftid=1636919&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:09:31>},
}

@inproceedings{Wang:2009:MEM:1526709.1526825,
  author =	 {Wang, Guiling and Yang, Shaohua and Han, Yanbo},
  title =	 {Mashroom: End-user Mashup Programming Using Nested
                  Tables},
  booktitle =	 {Proceedings of the 18th International Conference on
                  World Wide Web},
  series =	 {WWW '09},
  year =	 2009,
  isbn =	 {978-1-60558-487-4},
  location =	 {Madrid, Spain},
  pages =	 {861--870},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1526709.1526825},
  doi =		 {10.1145/1526709.1526825},
  acmid =	 1526825,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, mashup, nested table,
                  spreadsheet},
  abstract = 	 {This paper presents an end-user-oriented programming environment called Mashroom. Major contributions herein include an end-user programming model with an expressive data structure as well as a set of formally-defined mashup operators. The data structure takes advantage of nested table, and maintains the intuitiveness while allowing users to express complex data objects. The mashup operators are visualized with contextual menu and formula bar and can be directly applied on the data. Experiments and case studies reveal that end users have little difficulty in effectively and efficiently using Mashroom to build mashup applications.},
  review = 	 {fbie: rejected <2016-01-15 13:09:34>},
}

@inproceedings{Wong:2007:MMM:1240624.1240842,
  author =	 {Wong, Jeffrey and Hong, Jason I.},
  title =	 {Making Mashups with Marmite: Towards End-user
                  Programming for the Web},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '07},
  year =	 2007,
  isbn =	 {978-1-59593-593-9},
  location =	 {San Jose, California, USA},
  pages =	 {1435--1444},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1240624.1240842},
  doi =		 {10.1145/1240624.1240842},
  acmid =	 1240842,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, mashup, spreadsheet, web
                  services},
  abstract = 	 {There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1240842&ftid=416481&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:09:39>},
}

@inproceedings{Kohlhase:2009:MTE:1621995.1622021,
  author =	 {Kohlhase, Andrea E. and Kohlhase, Michael},
  title =	 {Modeling Task Experience in User Assistance Systems},
  booktitle =	 {Proceedings of the 27th ACM International Conference
                  on Design of Communication},
  series =	 {SIGDOC '09},
  year =	 2009,
  isbn =	 {978-1-60558-559-8},
  location =	 {Bloomington, Indiana, USA},
  pages =	 {135--142},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1621995.1622021},
  doi =		 {10.1145/1621995.1622021},
  acmid =	 1622021,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {spreadsheets, task experience, user assitance},
  abstract = 	 {One of the major issues for user assistance systems consists of "providing help at an appropriate level". In this paper we analyze the problem of modeling task experience - a prerequisite for provisioning adequate help. In contrast to level-based approaches we propose an ontology-based model, which allows fine-grained modeling of task experience using the concepts of the task domain as granules. The model is semantic in the sense that it allows to take advantage of the relations between concepts to provide novel semantic services and interactions. We present the SACHS (Semantic Annotations for a Controlling Help System, a semantic help system for a spreadsheet-based financial controlling system) software as an exemplary application of the proposed task experience model.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1622021&ftid=689882&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:09:47>},
}

@inproceedings{Doush:2010:DRT:1815330.1815391,
  author =	 {Doush, Iyad Abu and Pontelli, Enrico},
  title =	 {Detecting and Recognizing Tables in Spreadsheets},
  booktitle =	 {Proceedings of the 9th IAPR International Workshop
                  on Document Analysis Systems},
  series =	 {DAS '10},
  year =	 2010,
  isbn =	 {978-1-60558-773-8},
  location =	 {Boston, Massachusetts, USA},
  pages =	 {471--478},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1815330.1815391},
  doi =		 {10.1145/1815330.1815391},
  acmid =	 1815391,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {spreadsheet analysis, spreadsheets, table
                  navigation, table recognition, visual impairments},
  abstract = 	 {Detecting tables in a spreadsheet is the first step needed to make spreadsheet documents accessible to individuals with visual disabilities. Techniques to enable aural presentation and navigation of tables have been proposed, but they assume a thorough knowledge of the structure of the table; on the other hand, boundaries and structure of tables in a spreadsheet are not evident without a visual exploration. This paper presents an algorithm for table recognition in spreadsheets. The algorithm uses three types of cells as its basis: title cell, header cell, and data cell. Different attributes of the cells are used to identify the cell type within a spreadsheet. Hierarchical clustering is used to aggregate cells to compose the functional components of a table. The algorithm has been evaluated on a diverse set of benchmarks with very encouraging results.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1815391&ftid=822012&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:09:54>},
}

@inproceedings{Scaffidi:2008:TEE:1358628.1358884,
  author =	 {Scaffidi, Christopher and Myers, Brad and Shaw,
                  Mary},
  title =	 {Toped: Enabling End-user Programmers to Validate
                  Data},
  booktitle =	 {CHI '08 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '08},
  year =	 2008,
  isbn =	 {978-1-60558-012-8},
  location =	 {Florence, Italy},
  pages =	 {3519--3524},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1358628.1358884},
  doi =		 {10.1145/1358628.1358884},
  acmid =	 1358884,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, spreadsheets, web
                  applications},
  abstract = 	 {Inputs to spreadsheets and web forms often contain typos or other errors. However, existing tools require end-user programmers (EUPs) to write regular expressions or even scripts to validate data, which is slow and error-prone. We present a new technique enabling EUPs to describe data as a series of constrained parts. We incorporate our technique in a prototype tool called Toped, which generates validation code for Excel and web forms. Our technique enables EUPs to validate data more quickly and accurately than with existing techniques, finding 90\% of invalid inputs in a lab study.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1358884&ftid=507498&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:10:01>},
}

@inproceedings{Hermans:2009:GDK:1595782.1595798,
  author =	 {Hermans, Felienne},
  title =	 {Gathering Domain Knowledge from Spreadsheets},
  booktitle =	 {Proceedings of the Doctoral Symposium for ESEC/FSE
                  on Doctoral Symposium},
  series =	 {ESEC/FSE Doctoral Symposium '09},
  year =	 2009,
  isbn =	 {978-1-60558-731-8},
  location =	 {Amsterdam, The Netherlands},
  pages =	 {37--38},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1595782.1595798},
  doi =		 {10.1145/1595782.1595798},
  acmid =	 1595798,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data mining, reverse engineering, spreadsheets},
  abstract = 	 {Many companies use an ad hoc notation to describe the domain they work in. We consider this notation, that often occurs in the form of spreadsheets, as an unexplored source of domain knowledge. With this research we will investigate how software engineering techniques, like reverse engineering and data mining, can be applied to spreadsheets. Our first goal is to develop means to formalize spreadsheets. Formalization can be used in different ways, such as the validation of existing spreadsheets, documentation, and also for the transformation of spreadsheets into applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1595798&ftid=673552&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:10:31>},
}

@inproceedings{Chen:2014:ISD:2623330.2623617,
  author =	 {Chen, Zhe and Cafarella, Michael},
  title =	 {Integrating Spreadsheet Data via Accurate and
                  Low-effort Extraction},
  booktitle =	 {Proceedings of the 20th ACM SIGKDD International
                  Conference on Knowledge Discovery and Data Mining},
  series =	 {KDD '14},
  year =	 2014,
  isbn =	 {978-1-4503-2956-9},
  location =	 {New York, New York, USA},
  pages =	 {1126--1135},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2623330.2623617},
  doi =		 {10.1145/2623330.2623617},
  acmid =	 2623617,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {graphical model, information extraction,
                  spreadsheets},
  abstract = 	 {Spreadsheets contain valuable data on many topics. However, spreadsheets are difficult to integrate with other data sources. Converting spreadsheet data to the relational model would allow data analysts to use relational integration tools. We propose a two-phase semiautomatic system that extracts accurate relational metadata while minimizing user effort. Based on an undirected graphical model, our system enables downstream spreadsheet integration applications. First, the automatic extractor uses hints from spreadsheets' graphical style and recovered metadata to extract the spreadsheet data as accurately as possible. Second, the interactive repair identifies similar regions in distinct spreadsheets scattered across large spreadsheet corpora, allowing a user's single manual repair to be amortized over many possible extraction errors. Our experiments show that a human can obtain the accurate extraction with just 31\% of the manual operations required by a standard classification based technique on two real-world datasets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2623617&ftid=1495108&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:10:47>},
}

@inproceedings{Scaffidi:2009:ICR:1502650.1502692,
  author =	 {Scaffidi, Christopher and Myers, Brad and Shaw,
                  Mary},
  title =	 {Intelligently Creating and Recommending Reusable
                  Reformatting Rules},
  booktitle =	 {Proceedings of the 14th International Conference on
                  Intelligent User Interfaces},
  series =	 {IUI '09},
  year =	 2009,
  isbn =	 {978-1-60558-168-2},
  location =	 {Sanibel Island, Florida, USA},
  pages =	 {297--306},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1502650.1502692},
  doi =		 {10.1145/1502650.1502692},
  acmid =	 1502692,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {consistent data format, end-user programming,
                  spreadsheets},
  abstract = 	 {When users combine data from multiple sources into a spreadsheet or dataset, the result is often a mishmash of different formats, since phone numbers, dates, course numbers and other string-like kinds of data can each be written in many different formats. Although spreadsheets provide features for reformatting numbers and a few specific kinds of string data, they do not provide any support for the wide range of other kinds of string data encountered by users. We describe a user interface where a user can describe the formats of each kind of data. We provide an algorithm that uses these formats to automatically generate reformatting rules that transform strings from one format to another. In effect, our system enables users to create a small expert system called a "tope" that can recognize and reformat instances of one kind of data. Later, as the user is working with a spreadsheet, our system recommends appropriate topes for validating and reformatting the data. With a recall of over 80\% for a query time of under 1 second, this algorithm is accurate enough and fast enough to make useful recommendations in an interactive setting. A laboratory experiment shows that compared to manual typing, users can reformat sample spreadsheet data more than twice as fast by creating and using topes.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1502692&ftid=609414&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:10:56>},
}

@article{Witkowski:2005:ASM:1061318.1061321,
  author =	 {Witkowski, Andrew and Bellamkonda, Srikanth and
                  Bozkaya, Tolga and Folkert, Nathan and Gupta,
                  Abhinav and Haydu, John and Sheng, Lei and
                  Subramanian, Sankar},
  title =	 {Advanced SQL Modeling in RDBMS},
  journal =	 {ACM Trans. Database Syst.},
  issue_date =	 {March 2005},
  volume =	 30,
  number =	 1,
  month =	 mar,
  year =	 2005,
  issn =	 {0362-5915},
  pages =	 {83--121},
  numpages =	 39,
  url =		 {http://doi.acm.org/10.1145/1061318.1061321},
  doi =		 {10.1145/1061318.1061321},
  acmid =	 1061321,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Excel, OLAP, analytic computations, spreadsheet},
  abstract = 	 {Commercial relational database systems lack support for complex business modeling. ANSI SQL cannot treat relations as multidimensional arrays and define multiple, interrelated formulas over them, operations which are needed for business modeling. Relational OLAP (ROLAP) applications have to perform such tasks using joins, SQL Window Functions, complex CASE expressions, and the GROUP BY operator simulating the pivot operation. The designated place in SQL for calculations is the SELECT clause, which is extremely limiting and forces the user to generate queries with nested views, subqueries and complex joins. Furthermore, SQL query optimizers are preoccupied with determining efficient join orders and choosing optimal access methods and largely disregard optimization of multiple, interrelated formulas. Research into execution methods has thus far concentrated on efficient computation of data cubes and cube compression rather than on access structures for random, interrow calculations. This has created a gap that has been filled by spreadsheets and specialized MOLAP engines, which are good at specification of formulas for modeling but lack the formalism of the relational model, are difficult to coordinate across large user groups, exhibit scalability problems, and require replication of data between the tool and RDBMS. This article presents an SQL extension called SQL Spreadsheet, to provide array calculations over relations for complex modeling. We present optimizations, access structures, and execution models for processing them efficiently. Special attention is paid to compile time optimization for expensive operations like aggregation. Furthermore, ANSI SQL does not provide a good separation between data and computation and hence cannot support parameterization for SQL Spreadsheets models. We propose two parameterization methods for SQL. One parameterizes ANSI SQL view using subqueries and scalars, which allows passing data to SQL Spreadsheet. Another method presents parameterization of the SQL Spreadsheet formulas. This supports building stand-alone SQL Spreadsheet libraries. These models are then subject to the SQL Spreadsheet optimizations during model invocation time.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1061321&ftid=329919&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:11:00>},
}

@inproceedings{Kongdenfha:2009:RDS:1526709.1526824,
  author =	 {Kongdenfha, Woralak and Benatallah, Boualem and
                  Vayssi\`{e}re, Julien and Saint-Paul, R{\'e}gis and
                  Casati, Fabio},
  title =	 {Rapid Development of Spreadsheet-based Web Mashups},
  booktitle =	 {Proceedings of the 18th International Conference on
                  World Wide Web},
  series =	 {WWW '09},
  year =	 2009,
  isbn =	 {978-1-60558-487-4},
  location =	 {Madrid, Spain},
  pages =	 {851--860},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1526709.1526824},
  doi =		 {10.1145/1526709.1526824},
  acmid =	 1526824,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {component model, spreadsheet-based mashup patterns,
                  spreadsheets, web data mashups},
  abstract = 	 {The rapid growth of social networking sites and web communities have motivated web sites to expose their APIs to external developers who create mashups by assembling existing functionalities. Current APIs, however, aim toward developers with programming expertise; they are not directly usable by wider class of users who do not have programming background, but would nevertheless like to build their own mashups. To address this need, we propose a spreadsheet-based Web mashups development framework, which enables users to develop mashups in the popular spreadsheet environment. First, we provide a mechanism that makes structured data first class values of spreadsheet cells. Second, we propose a new component model that can be used to develop fairly sophisticated mashups, involving joining data sources and keeping spreadsheet data up to date. Third, to simplify mashup development, we provide a collection of spreadsheet-based mashup patterns that captures common Web data access and spreadsheet presentation functionalities. Users can reuse and customize these patterns to build spreadsheet-based Web mashups instead of developing them from scratch. Fourth, we enable users to manipulate structured data presented on spreadsheet in a drag-and-drop fashion. Finally, we have developed and tested a proof-of-concept prototype to demonstrate the utility of the proposed framework.},
  review = 	 {fbie: rejected <2016-01-15 13:11:04>},
}

@inproceedings{Kapros:2014:UDS:2607023.2607027,
  author =	 {Kapros, Evangelos and McGinnes, Simon},
  title =	 {Updating Database Schemas Without Breaking the UI:
                  Modeling Using Cognitive Semantic Categories},
  booktitle =	 {Proceedings of the 2014 ACM SIGCHI Symposium on
                  Engineering Interactive Computing Systems},
  series =	 {EICS '14},
  year =	 2014,
  isbn =	 {978-1-4503-2725-1},
  location =	 {Rome, Italy},
  pages =	 {23--31},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/2607023.2607027},
  doi =		 {10.1145/2607023.2607027},
  acmid =	 2607027,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {adaptive information systems, databases,
                  spreadsheets},
  abstract = 	 {Data management user interfaces are ubiquitous in information systems and web-based applications. From the oldest spreadsheet to the most modern database, end users and administrators alike have interacted with tabular data. Usually, each concept is represented by a table and columns. Change to the structure of each concept requires structural change to the tables and columns, which is costly. Tailor-made database and web applications may overcome this obstacle by designing UIs on top of the data layer, providing some degree of data independence. However, changes in their schemas do not automatically propagate into the user interface, and so their maintenance is expensive. In this paper we present a user interface that lets the end user alter the schema without the need for programming skills, eliminating the need for expensive software maintenance. To this end we propose an automatically generated user interface to include schema and data management functions. We built and evaluated an Adaptive Information System user interface (AIS UI), incorporating schema evolution functionality. In usability testing, first-time users were able to perform various data management tasks equally fast or faster than users using Microsoft Access, and on average ~43\% faster than users using Microsoft Excel. Task completion rates using the AIS significantly exceeded those using Microsoft Access and were comparable (>95\%) with those using Microsoft Excel.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2607027&ftid=1473196&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:11:10>},
}

@inproceedings{Corser:2012:TTC:2390317.2390320,
  author =	 {Corser, George},
  title =	 {A Tale of Two CTs: IP Packets Rejected by a
                  Firewall},
  booktitle =	 {Proceedings of the 2012 Information Security
                  Curriculum Development Conference},
  series =	 {InfoSecCD '12},
  year =	 2012,
  isbn =	 {978-1-4503-1538-8},
  location =	 {Kennesaw, Georgia},
  pages =	 {16--20},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/2390317.2390320},
  doi =		 {10.1145/2390317.2390320},
  acmid =	 2390320,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {firewall log analysis, spreadsheets, visualization},
  abstract = 	 {Two distinct curve tendencies (CTs) characterize the flow of IP packets rejected by a firewall from specific source IP addresses. One flow model appears relatively flat and steady over time. The other manifests as a single sharp spike. This study examines a recent real-world firewall log which exhibits these two patterns.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2390320&ftid=1304085&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:11:15>},
}

@article{Dybdahl:1998:AFE:290320.283034,
  author =	 {Dybdahl, Arne and Sutinen, Erkki and Tarhio, Jorma},
  title =	 {On Animation Features of Excel},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Sept. 1998},
  volume =	 30,
  number =	 3,
  month =	 aug,
  year =	 1998,
  issn =	 {0097-8418},
  pages =	 {77--80},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/290320.283034},
  doi =		 {10.1145/290320.283034},
  acmid =	 283034,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Excel, animation, educational visualisation,
                  spreadsheet},
  abstract = 	 {We consider how to create animations with Microsoft Excel. We present the capabilities of the drawing and auditing tools, dynamic graphs, and special effects of cells. Combining these features with the integrated Visual Basic programming language provides the user with an easy-to-use platform for versatile educational visualisations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=283034&ftid=29397&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:11:42>},
}

@inproceedings{Dybdahl:1998:AFE:282991.283034,
  author =	 {Dybdahl, Arne and Sutinen, Erkki and Tarhio, Jorma},
  title =	 {On Animation Features of Excel},
  booktitle =	 {Proceedings of the 6th Annual Conference on the
                  Teaching of Computing and the 3rd Annual Conference
                  on Integrating Technology into Computer Science
                  Education: Changing the Delivery of Computer Science
                  Education},
  series =	 {ITiCSE '98},
  year =	 1998,
  isbn =	 {1-58113-000-7},
  location =	 {Dublin City Univ., Ireland},
  pages =	 {77--80},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/282991.283034},
  doi =		 {10.1145/282991.283034},
  acmid =	 283034,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Excel, animation, educational visualisation,
                  spreadsheet},
  abstract = 	 {We consider how to create animations with Microsoft Excel. We present the capabilities of the drawing and auditing tools, dynamic graphs, and special effects of cells. Combining these features with the integrated Visual Basic programming language provides the user with an easy-to-use platform for versatile educational visualisations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=283034&ftid=29397&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:11:45>},
}

@inproceedings{Dou:2014:SAH:2568225.2568316,
  author =	 {Dou, Wensheng and Cheung, Shing-Chi and Wei, Jun},
  title =	 {Is Spreadsheet Ambiguity Harmful? Detecting and
                  Repairing Spreadsheet Smells Due to Ambiguous
                  Computation},
  booktitle =	 {Proceedings of the 36th International Conference on
                  Software Engineering},
  series =	 {ICSE 2014},
  year =	 2014,
  isbn =	 {978-1-4503-2756-5},
  location =	 {Hyderabad, India},
  pages =	 {848--858},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2568225.2568316},
  doi =		 {10.1145/2568225.2568316},
  acmid =	 2568316,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Spreadsheet, ambiguous computation, repair, smell},
  abstract = 	 {Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column. When a spreadsheet evolves, these cell clusters can degenerate due to ad hoc modifications or undisciplined copy-and-pastes. Such degenerated clusters no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. Our empirical study finds that such smells are common and likely harmful. We propose AmCheck, a novel technique that automatically detects and repairs ambiguous computation smells by recovering their intended computational semantics. A case study using AmCheck suggests that it is useful for discovering and repairing real spreadsheet problems.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2568316&ftid=1467949&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:11:55>},
}

@inproceedings{Engels:2005:CAG:1101908.1101929,
  author =	 {Engels, Gregor and Erwig, Martin},
  title =	 {ClassSheets: Automatic Generation of Spreadsheet
                  Applications from Object-oriented Specifications},
  booktitle =	 {Proceedings of the 20th IEEE/ACM International
                  Conference on Automated Software Engineering},
  series =	 {ASE '05},
  year =	 2005,
  isbn =	 {1-58113-993-4},
  location =	 {Long Beach, CA, USA},
  pages =	 {124--133},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1101908.1101929},
  doi =		 {10.1145/1101908.1101929},
  acmid =	 1101929,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {UML, end-user software engineering, spreadsheet},
  abstract = 	 {Spreadsheets are widely used in all kinds of business applications. Numerous studies have shown that they contain many errors that sometimes have dramatic impacts. One reason for this situation is the low-level, cell-oriented development process of spreadsheets.We improve this process by introducing and formalizing a higher-level object-oriented model termed ClassSheet. While still following the tabular look-and feel of spreadsheets, ClassSheets allow the developer to express explicitly business object structures within a spreadsheet, which is achieved by integrating concepts from the UML (Unified Modeling Language). A stepwise automatic transformation process generates a spreadsheet application that is consistent with the ClassSheet model. Thus, by deploying the formal underpinning of ClassSheets, a large variety of errors can be prevented that occur in many existing spreadsheet applications today.The presented ClassSheet approach links spreadsheet applications to the object-oriented modeling world and advocates an automatic model-driven development process for spreadsheet applications of high quality.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1101929&ftid=337916&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:12:03>},
}

@inproceedings{Gulwani:2014:NIP:2588555.2612177,
  author =	 {Gulwani, Sumit and Marron, Mark},
  title =	 {NLyze: Interactive Programming by Natural Language
                  for Spreadsheet Data Analysis and Manipulation},
  booktitle =	 {Proceedings of the 2014 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '14},
  year =	 2014,
  isbn =	 {978-1-4503-2376-5},
  location =	 {Snowbird, Utah, USA},
  pages =	 {803--814},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2588555.2612177},
  doi =		 {10.1145/2588555.2612177},
  acmid =	 2612177,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, program synthesis, spreadsheet
                  programming, user intent},
  abstract = 	 {Millions of computer end users need to perform tasks over tabular spreadsheet data, yet lack the programming knowledge to do such tasks automatically. This paper describes the design and implementation of a robust natural language based interface to spreadsheet programming. Our methodology involves designing a typed domain-specific language (DSL) that supports an expressive algebra of map, filter, reduce, join, and formatting capabilities at a level of abstraction appropriate for non-expert users. The key algorithmic component of our methodology is a translation algorithm for converting a natural language specification in the context of a given spreadsheet to a ranked set of likely programs in the DSL. The translation algorithm leverages the spreadsheet spatial and temporal context to assign interpretations to specifications with implicit references, and is thus robust to a variety of ways in which end users can express the same task. The translation algorithm builds over ideas from keyword programming and semantic parsing to achieve both high precision and high recall. We implemented the system as an Excel add-in called NLyze that supports a rich user interaction model including annotating the user's natural language specification and explaining the synthesized DSL programs by paraphrasing them into structured English. We collected a total of 3570 English descriptions for 40 spreadsheet tasks and our system was able to generate the intended interpretation as the top candidate for 94\% (97 for the top 3) of those instances.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2612177&ftid=1474645&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:12:23>},
}

@inproceedings{Fisher:2005:ESC:1083231.1083242,
  author =	 {Fisher, Marc and Rothermel, Gregg},
  title =	 {The EUSES Spreadsheet Corpus: A Shared Resource for
                  Supporting Experimentation with Spreadsheet
                  Dependability Mechanisms},
  booktitle =	 {Proceedings of the First Workshop on End-user
                  Software Engineering},
  series =	 {WEUSE I},
  year =	 2005,
  isbn =	 {1-59593-131-7},
  location =	 {St. Louis, Missouri},
  pages =	 {1--5},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1082983.1083242},
  doi =		 {10.1145/1082983.1083242},
  acmid =	 1083242,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, end-user software engineering},
  abstract = 	 {In recent years several tools and methodologies have been developed to improve the dependability of spreadsheets. However, there has been little evaluation of these dependability devices on spreadsheets in actual use by end users. To assist in the process of evaluating these methodologies, we have assembled a corpus of spreadsheets from a variety of sources. We have ensured that these spreadsheets are suitable for evaluating dependability devices in Microsoft Excel (the most commonly used commercial spreadsheet environment) and have measured a variety of feature of these spreadsheets to aid researchers in selecting subsets of the corpus appropriate to their needs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1083242&ftid=328659&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:12:28>},
}

@article{Fisher:2005:ESC:1082983.1083242,
  author =	 {Fisher, Marc and Rothermel, Gregg},
  title =	 {The EUSES Spreadsheet Corpus: A Shared Resource for
                  Supporting Experimentation with Spreadsheet
                  Dependability Mechanisms},
  journal =	 {SIGSOFT Softw. Eng. Notes},
  issue_date =	 {July 2005},
  volume =	 30,
  number =	 4,
  month =	 may,
  year =	 2005,
  issn =	 {0163-5948},
  pages =	 {1--5},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1082983.1083242},
  doi =		 {10.1145/1082983.1083242},
  acmid =	 1083242,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, end-user software engineering},
  abstract = 	 {In recent years several tools and methodologies have been developed to improve the dependability of spreadsheets. However, there has been little evaluation of these dependability devices on spreadsheets in actual use by end users. To assist in the process of evaluating these methodologies, we have assembled a corpus of spreadsheets from a variety of sources. We have ensured that these spreadsheets are suitable for evaluating dependability devices in Microsoft Excel (the most commonly used commercial spreadsheet environment) and have measured a variety of feature of these spreadsheets to aid researchers in selecting subsets of the corpus appropriate to their needs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1083242&ftid=328659&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:12:31>},
}

@inproceedings{Pesce:2012:SSF:2667062.2667075,
  author =	 {Pesce, Marcia Lucas and Breitman, Karin K. and
                  Casanova, Marco Antonio},
  title =	 {Surfacing Scientific and Financial Data with the
                  Xcel2RDF Plug-in},
  booktitle =	 {Proceedings of the Second International Workshop on
                  Developing Tools As Plug-Ins},
  series =	 {TOPI '12},
  year =	 2012,
  isbn =	 {978-1-4673-1820-4},
  location =	 {Zurich, Switzerland},
  pages =	 {73--78},
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=2667062.2667075},
  acmid =	 2667075,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  keywords =	 {Excel, RDF, linked open data, spreadsheet},
  abstract = 	 {Given the astounding amount of data stored in spreadsheets and relational databases, a critical requirement for the evolution of the Semantic Web (SW) is the ability to convert data to SW compatible formats, such as RDF and OWL. The process by which data is transformed into RDF is known as triplification. This paper introduces Xcel2RDF, an MS Excel plug-in to support the triplification of spreadsheets, which minimizes the learning curve, as it is integrated into a widely used spreadsheet software tool. The plug-in is user-friendly, does not depend on the installation of additional software and does not require the user to leave his familiar environment, thereby avoiding problems reported as the major drawbacks of existing spreadsheet to RDF conversion tools. Finally, as a proof of concept, the paper illustrates how to use the tool to triplify statistical data.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2667075&ftid=1497996&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:12:44>},
}

@inproceedings{Kandogan:2005:AEP:1095034.1095070,
  author =	 {Kandogan, Eser and Haber, Eben and Barrett, Rob and
                  Cypher, Allen and Maglio, Paul and Zhao, Haixia},
  title =	 {A1: End-user Programming for Web-based System
                  Administration},
  booktitle =	 {Proceedings of the 18th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '05},
  year =	 2005,
  isbn =	 {1-59593-271-2},
  location =	 {Seattle, WA, USA},
  pages =	 {211--220},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1095034.1095070},
  doi =		 {10.1145/1095034.1095070},
  acmid =	 1095070,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, spreadsheets, system
                  management, web-portal user interfaces},
  abstract = 	 {System administrators work with many different tools to manage and fix complex hardware and software infrastructure in a rapidly paced work environment. Through extensive field studies, we observed that they often build and share custom tools for specific tasks that are not supported by vendor tools. Recent trends toward web-based management consoles offer many advantages but put an extra burden on system administrators, as customization requires web programming, which is beyond the skills of many system administrators. To meet their needs, we developed A1, a spreadsheet-based environment with a task-specific system-administration language for quickly creating small tools or migrating existing scripts to run as web portlets. Using A1, system administrators can build spreadsheets to access remote and heterogeneous systems, gather and integrate status data, and orchestrate control of disparate systems in a uniform way. A preliminary user study showed that in just a few hours, system administrators can learn to use A1 to build relatively complex tools from scratch.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1095070&ftid=332614&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:12:48>},
}

@inproceedings{Subrahmaniyan:2008:SVE:1409720.1409742,
  author =	 {Subrahmaniyan, Neeraja and Burnett, Margaret and
                  Bogart, Christopher},
  title =	 {Software Visualization for End-user Programmers:
                  Trial Period Obstacles},
  booktitle =	 {Proceedings of the 4th ACM Symposium on Software
                  Visualization},
  series =	 {SoftVis '08},
  year =	 2008,
  isbn =	 {978-1-60558-112-5},
  location =	 {Ammersee, Germany},
  pages =	 {135--144},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1409720.1409742},
  doi =		 {10.1145/1409720.1409742},
  acmid =	 1409742,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user software engineering, software adoption,
                  software visualization, spreadsheets},
  abstract = 	 {Software visualization for end-user programmers is a relatively unexplored opportunity area. There are advances in software visualization research pertinent to this, but the adoption stage has been entirely ignored. In this paper, we focus on a popular facilitator of adoption decisions: the free trial period. We conducted a case study of an end-user programmer (an accountant) in this situation, as she tried out a commercial spreadsheet visualization tool to make an adoption decision. The results have implications for both theory and design, revealing open questions, design opportunities, and strengths and weaknesses of theoretical foundations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1409742&ftid=552885&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:13:09>},
}

@inproceedings{Hermans:2011:SPS:1985793.1985855,
  author =	 {Hermans, Felienne and Pinzger, Martin and van
                  Deursen, Arie},
  title =	 {Supporting Professional Spreadsheet Users by
                  Generating Leveled Dataflow Diagrams},
  booktitle =	 {Proceedings of the 33rd International Conference on
                  Software Engineering},
  series =	 {ICSE '11},
  year =	 2011,
  isbn =	 {978-1-4503-0445-0},
  location =	 {Waikiki, Honolulu, HI, USA},
  pages =	 {451--460},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1985793.1985855},
  doi =		 {10.1145/1985793.1985855},
  acmid =	 1985855,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data flow diagrams, end-user programming,
                  spreadsheets, visualization},
  abstract = 	 {Thanks to their flexibility and intuitive programming model, spreadsheets are widely used in industry, often for businesscritical applications. Similar to software developers, professional spreadsheet users demand support for maintaining and transferring their spreadsheets. In this paper, we first study the problems and information needs of professional spreadsheet users by means of a survey conducted at a large financial company. Based on these needs, we then present an approach that extracts this information from spreadsheets and presents it in a compact and easy to understand way, with leveled dataflow diagrams. Our approach comes with three different views on the dataflow that allow the user to analyze the dataflow diagrams in a top-down fashion. To evaluate the usefulness of the proposed approach, we conducted a series of interviews as well as nine case studies in an industrial setting. The results of the evaluation clearly indicate the demand for and usefulness of our approach in ease the understanding of spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1985855&ftid=969519&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:13:18>},
}

@inproceedings{Abraham:2006:ITS:1134285.1134312,
  author =	 {Abraham, Robin and Erwig, Martin},
  title =	 {Inferring Templates from Spreadsheets},
  booktitle =	 {Proceedings of the 28th International Conference on
                  Software Engineering},
  series =	 {ICSE '06},
  year =	 2006,
  isbn =	 {1-59593-375-1},
  location =	 {Shanghai, China},
  pages =	 {182--191},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1134285.1134312},
  doi =		 {10.1145/1134285.1134312},
  acmid =	 1134312,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user software engineering, spreadsheet
                  specification, template inference},
  abstract = 	 {We present a study investigating the performance of a system for automatically inferring spreadsheet templates. These templates allow users to safely edit spreadsheets, that is, certain kinds of errors such as range, reference, and type errors can be provably prevented. Since the inference of templates is inherently ambiguous, such a study is required to demonstrate the effectiveness of any such automatic system. The study results show that the system considered performs significantly better than subjects with intermediate to expert level programming expertise. These results are important because the translation of the huge body of existing spreadsheets into a system based on safety-guaranteeing templates cannot be performed without automatic support. We also carried out post-hoc analyses of the video recordings of the subjects' interactions with the spreadsheets and found that although expert-level subjects needed less time and developed more accurate templates than less experienced subjects, they did not inspect fewer cells in the spreadsheet. \%and found that expert-level subjects spend less time and inspect fewer cells in the spreadsheet and develop more accurate templates than subjects with less experience.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1134312&ftid=355341&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:13:30>},
}

@inproceedings{Capovilla:2013:TSV:2462476.2462477,
  author =	 {Capovilla, Dino and Hubwieser, Peter},
  title =	 {Teaching Spreadsheets to Visually-impaired Students
                  in an Environment Similar to a Mainstream Class},
  booktitle =	 {Proceedings of the 18th ACM Conference on Innovation
                  and Technology in Computer Science Education},
  series =	 {ITiCSE '13},
  year =	 2013,
  isbn =	 {978-1-4503-2078-8},
  location =	 {Canterbury, England, UK},
  pages =	 {99--104},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2462476.2462477},
  doi =		 {10.1145/2462476.2462477},
  acmid =	 2462477,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {blind, inclusive education, spreadsheets,
                  visually-impaired},
  abstract = 	 {Inclusive education at all levels, as required by the UN General Assembly, will increase the heterogeneity of classes noticeably. Computer science education has to change in order to ensure equal access and equal opportunities for all. In contrast to previous research, we developed and tested teaching methods suitable for both normal and visually-impaired / blind students using standard handicap-specific equipment (e.g. laptop and screen reader). Our results show that no additional software and hardware is necessary to reach a fair level of handling spreadsheets when the proposed teaching methods are used.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2462477&ftid=1379680&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:13:40>},
}

@inproceedings{Tyszkiewicz:2010:SRD:1807167.1807191,
  author =	 {Tyszkiewicz, Jerzy},
  title =	 {Spreadsheet As a Relational Database Engine},
  booktitle =	 {Proceedings of the 2010 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '10},
  year =	 2010,
  isbn =	 {978-1-4503-0032-2},
  location =	 {Indianapolis, Indiana, USA},
  pages =	 {195--206},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1807167.1807191},
  doi =		 {10.1145/1807167.1807191},
  acmid =	 1807191,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {performance, relational algebra, relational
                  databases, spreadsheets, sql},
  abstract = 	 {Spreadsheets are among the most commonly used applications for data management and analysis. Perhaps they are even among the most widely used computer applications of all kinds. However, the spreadsheet paradigm of computation still lacks sufficient analysis. In this paper we demonstrate that a spreadsheet can play the role of a relational database engine, without any use of macros or built-in programming languages, merely by utilizing spreadsheet formulas. We achieve that by implementing all operators of relational algebra by means of spreadsheet functions. Given a definition of a database in SQL, it is therefore possible to construct a spreadsheet workbook with empty worksheets for data tables and worksheets filled with formulas for queries. From then on, when the user enters, alters or deletes data in the data worksheets, the formulas in query worksheets automatically compute the actual results of the queries. Thus, the spreadsheet serves as data storage and executes SQL queries, and therefore acts as a relational database engine. The paper is based on Microsoft Excel (TM), but our constructions work in other spreadsheet systems, too. We present a number of performance tests conducted in the beta version of Excel 2010. Their conclusion is that the performance is sufficient for a desktop database with a couple thousand rows.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1807191&ftid=803616&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:13:54>},
}

@inproceedings{Chi:1997:SAI:263407.263513,
  author =	 {Chi, Ed Huai-hsin and Konstan, Joseph and Barry,
                  Phillip and Riedl, John},
  title =	 {A Spreadsheet Approach to Information Visualization},
  booktitle =	 {Proceedings of the 10th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '97},
  year =	 1997,
  isbn =	 {0-89791-881-9},
  location =	 {Banff, Alberta, Canada},
  pages =	 {79--80},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/263407.263513},
  doi =		 {10.1145/263407.263513},
  acmid =	 263513,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {information visualization, interactive graphics,
                  spreadsheet, visualization},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=263513&ftid=42002&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:14:09>},
}

@inproceedings{Kandogan:2011:FSI:1978942.1979079,
  author =	 {Kandogan, Eser and Kim, Juho and Moran, Thomas
                  P. and Pedemonte, Pablo},
  title =	 {How a Freeform Spatial Interface Supports Simple
                  Problem Solving Tasks},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '11},
  year =	 2011,
  isbn =	 {978-1-4503-0228-9},
  location =	 {Vancouver, BC, Canada},
  pages =	 {925--934},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1978942.1979079},
  doi =		 {10.1145/1978942.1979079},
  acmid =	 1979079,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {freeform interaction, problem solving, spatial
                  interfaces, spreadsheets},
  abstract = 	 {We developed DataBoard, a freeform spatial interface, to support users in simple problem solving tasks. To develop a deeper understanding of the role of space and the tradeoffs between freeform and structured interaction styles in problem solving tasks, we conducted a controlled user study comparing the DataBoard with a spreadsheet and analyzed video data in detail. Beyond improvements in task performance and memory recall, our observations reveal that freeform interfaces can support users in a variety of ways: representing problems flexibly, developing strategies, executing strategies incrementally, tracking problem state easily, reducing mental computation, and verifying solutions perceptually. The spreadsheet also had advantages, and we discuss the tradeoffs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1979079&ftid=963790&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:14:20>},
}

@inproceedings{Kankuzi:2008:EOG:1370847.1370866,
  author =	 {Kankuzi, Bennett and Ayalew, Yirsaw},
  title =	 {An End-user Oriented Graph-based Visualization for
                  Spreadsheets},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {86--90},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370866},
  doi =		 {10.1145/1370847.1370866},
  acmid =	 1370866,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user software engineering, mcl algorithm,
                  spreadsheets, visual programming, visualization},
  abstract = 	 {One of the difficulties in understanding and debugging spreadsheets is due to the invisibility of the data flow structure which is associated with cell formulas. In this paper, we present a spreadsheet visualization approach that is mainly based on the Markov Clustering (MCL) algorithm in an attempt to help spreadsheet users understand and debug their spreadsheets. The MCL algorithm helps in visualizing large graphs by generating clusters of cells. In our visualization approach, we also use compound fisheye views and treemaps to help in the navigation of the generated clusters. Compound fish eye views help to view members of a particular cluster while showing their linkages with other clusters. Treemaps help to visualize the depth we are at while navigating a cluster tree. Our initial experiments show that graph-based spreadsheet visualization using the MCL algorithm generates clusters which match with the corresponding logical areas of a given spreadsheet. Our experiments also show that analysis of the clusters helps us to identify some errors in the spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370866&ftid=498663&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:14:29>},
}

@inproceedings{Gibbs:2015:ISM:2808047.2808048,
  author =	 {Gibbs, Shirley and Cromie, Kate and Pellow, Ron},
  title =	 {An Interactive Spreadsheet Model for Visualizing
                  Dairy Farm Data},
  booktitle =	 {Proceedings of the 15th New Zealand Conference on
                  Human-Computer Interaction},
  series =	 {CHINZ 2015},
  year =	 2015,
  isbn =	 {978-1-4503-3670-3},
  location =	 {Hamilton, New Zealand},
  pages =	 {51--55},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/2808047.2808048},
  doi =		 {10.1145/2808047.2808048},
  acmid =	 2808048,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Data visualization, spreadsheet visualization, user
                  interaction},
  abstract = 	 {This paper describes the development of an interactive spreadsheet model (INT-VIS) developed to give users quick access to bespoke visualization representations of data from a dairy demonstration farm. Dairy farming has a long history in New Zealand with the country exporting ninety-five percent of the annual milk production. Demonstration Farms, such as the one which is the focus of this paper, have been established by educational institutes and industry groups as a way of promoting best practice dairying for this fast growing industry. One of the aims of such farms is to produce and share data so that other farmers will benefit from the information sourced. Typically, the information from the South Island Dairy Development Centre (SIDDC) demonstration farm at Lincoln University is collected weekly, entered into a spreadsheet, graphs and charts produced on an adhoc basis and shared with stakeholders by way of pdf documents on the organisation website. This paper describes the first steps in developing an interactive spreadsheet model to allow users to create their own bespoke visualizations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2808048&ftid=1619319&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:14:35>},
}

@article{Kolster:2000:CPM:570440.570491,
  author =	 {Kolster, Nils and Nagel, Christian},
  title =	 {Communication Between PC and Mainframe via TCP/IP
                  Using APL},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {June 2000},
  volume =	 30,
  number =	 4,
  month =	 jun,
  year =	 2000,
  issn =	 {0163-6006},
  pages =	 {121--130},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/570440.570491},
  doi =		 {10.1145/570440.570491},
  acmid =	 570491,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {APL, PC, TCP/IP, client, mainframe, server,
                  spreadsheet},
  abstract = 	 {There is a growing demand to be able to process data, maintained within large mainframe databases, using Windows based workstations, thus making communication between workstation and mainframe necessary. The availability of the APL language on both platforms simplifies this problem tremendously, and offers the potential to use almost identical code on both systems. The workspaces (for APL+WIN 3.0 and APL2 Mainframe) written by the authors, allow the user to run a stateless server on one platform, which can then process incoming requests from any platform using TCP/IP. (A host-to-host communication facility is not yet provided.) Several specific server commands let multiple users interact individually with the server, e.g. to combine GUI and mainframe data or to plot mainframe data directly using standard software products such as MS-EXCEL.},
  review = 	 {fbie: rejected <2016-01-15 13:14:39>},
}

@inproceedings{Kolster:2000:CPM:570475.570491,
  author =	 {Kolster, Nils and Nagel, Christian},
  title =	 {Communication Between PC and Mainframe via TCP/IP
                  Using APL},
  booktitle =	 {Proceedings of the International Conference on
                  APL-Berlin-2000 Conference},
  series =	 {APL '00},
  year =	 2000,
  isbn =	 {1-58113-182-8},
  location =	 {Berlin, Germany},
  pages =	 {121--130},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/570475.570491},
  doi =		 {10.1145/570475.570491},
  acmid =	 570491,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {APL, PC, TCP/IP, client, mainframe, server,
                  spreadsheet},
  abstract = 	 {There is a growing demand to be able to process data, maintained within large mainframe databases, using Windows based workstations, thus making communication between workstation and mainframe necessary. The availability of the APL language on both platforms simplifies this problem tremendously, and offers the potential to use almost identical code on both systems. The workspaces (for APL+WIN 3.0 and APL2 Mainframe) written by the authors, allow the user to run a stateless server on one platform, which can then process incoming requests from any platform using TCP/IP. (A host-to-host communication facility is not yet provided.) Several specific server commands let multiple users interact individually with the server, e.g. to combine GUI and mainframe data or to plot mainframe data directly using standard software products such as MS-EXCEL.},
  review = 	 {fbie: rejected <2016-01-15 13:14:43>},
}

@article{Barowy:2015:FER:2813885.2737952,
  author =	 {Barowy, Daniel W. and Gulwani, Sumit and Hart, Ted
                  and Zorn, Benjamin},
  title =	 {FlashRelate: Extracting Relational Data from
                  Semi-structured Spreadsheets Using Examples},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {June 2015},
  volume =	 50,
  number =	 6,
  month =	 jun,
  year =	 2015,
  issn =	 {0362-1340},
  pages =	 {218--228},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2813885.2737952},
  doi =		 {10.1145/2813885.2737952},
  acmid =	 2737952,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data extraction, program synthesis, relational data,
                  spreadsheets},
  abstract = 	 {With hundreds of millions of users, spreadsheets are one of the most important end-user applications. Spreadsheets are easy to use and allow users great flexibility in storing data. This flexibility comes at a price: users often treat spreadsheets as a poor man&#039;s database, leading to creative solutions for storing high-dimensional data. The trouble arises when users need to answer queries with their data. Data manipulation tools make strong assumptions about data layouts and cannot read these ad-hoc databases. Converting data into the appropriate layout requires programming skills or a major investment in manual reformatting. The effect is that a vast amount of real-world data is "locked-in" to a proliferation of one-off formats. We introduce FlashRelate, a synthesis engine that lets ordinary users extract structured relational data from spreadsheets without programming. Instead, users extract data by supplying examples of output relational tuples. FlashRelate uses these examples to synthesize a program in Flare. Flare is a novel extraction language that extends regular expressions with geometric constructs. An interactive user interface on top of FlashRelate lets end users extract data by point-and-click. We demonstrate that correct Flare programs can be synthesized in seconds from a small set of examples for 43 real-world scenarios. Finally, our case study demonstrates FlashRelate&#039;s usefulness addressing the widespread problem of data trapped in corporate and government formats.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2737952&ftid=1588447&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:14:53>},
}

@inproceedings{Barowy:2015:FER:2737924.2737952,
  author =	 {Barowy, Daniel W. and Gulwani, Sumit and Hart, Ted
                  and Zorn, Benjamin},
  title =	 {FlashRelate: Extracting Relational Data from
                  Semi-structured Spreadsheets Using Examples},
  booktitle =	 {Proceedings of the 36th ACM SIGPLAN Conference on
                  Programming Language Design and Implementation},
  series =	 {PLDI 2015},
  year =	 2015,
  isbn =	 {978-1-4503-3468-6},
  location =	 {Portland, OR, USA},
  pages =	 {218--228},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2737924.2737952},
  doi =		 {10.1145/2737924.2737952},
  acmid =	 2737952,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data extraction, program synthesis, relational data,
                  spreadsheets},
  abstract = 	 {With hundreds of millions of users, spreadsheets are one of the most important end-user applications. Spreadsheets are easy to use and allow users great flexibility in storing data. This flexibility comes at a price: users often treat spreadsheets as a poor man&#039;s database, leading to creative solutions for storing high-dimensional data. The trouble arises when users need to answer queries with their data. Data manipulation tools make strong assumptions about data layouts and cannot read these ad-hoc databases. Converting data into the appropriate layout requires programming skills or a major investment in manual reformatting. The effect is that a vast amount of real-world data is "locked-in" to a proliferation of one-off formats. We introduce FlashRelate, a synthesis engine that lets ordinary users extract structured relational data from spreadsheets without programming. Instead, users extract data by supplying examples of output relational tuples. FlashRelate uses these examples to synthesize a program in Flare. Flare is a novel extraction language that extends regular expressions with geometric constructs. An interactive user interface on top of FlashRelate lets end users extract data by point-and-click. We demonstrate that correct Flare programs can be synthesized in seconds from a small set of examples for 43 real-world scenarios. Finally, our case study demonstrates FlashRelate&#039;s usefulness addressing the widespread problem of data trapped in corporate and government formats.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2737952&ftid=1588447&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:14:57>},
}

@inproceedings{Wolber:2002:DDW:502716.502770,
  author =	 {Wolber, David and Su, Yingfeng and Chiang, Yih
                  Tsung},
  title =	 {Designing Dynamic Web Pages and Persistence in the
                  WYSIWYG Interface},
  booktitle =	 {Proceedings of the 7th International Conference on
                  Intelligent User Interfaces},
  series =	 {IUI '02},
  year =	 2002,
  isbn =	 {1-58113-459-2},
  location =	 {San Francisco, California, USA},
  pages =	 {228--229},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/502716.502770},
  doi =		 {10.1145/502716.502770},
  acmid =	 502770,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {HTML, PBE, QBE, dynamic web pages, spreadsheets},
  abstract = 	 {WebSheets is a programming in the WYSIWYG interface tool for building dynamic web pages that access and modify databases. Without programming, designers can specify not only the presentation of a page, but the dynamic content as well. This capability is facilitated through a novel application of Programming by Example (PBE), Query by Example (QBE), and spreadsheet formulas within the WYSIWYG HTML editor environment.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=502770&ftid=63934&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:15:03>},
}

@inproceedings{Psallidas:2015:STS:2723372.2749452,
  author =	 {Psallidas, Fotis and Ding, Bolin and Chakrabarti,
                  Kaushik and Chaudhuri, Surajit},
  title =	 {S4: Top-k Spreadsheet-Style Search for Query
                  Discovery},
  booktitle =	 {Proceedings of the 2015 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '15},
  year =	 2015,
  isbn =	 {978-1-4503-2758-9},
  location =	 {Melbourne, Victoria, Australia},
  pages =	 {2001--2016},
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/2723372.2749452},
  doi =		 {10.1145/2723372.2749452},
  acmid =	 2749452,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {example spreadsheet, relevance ranking, sql query
                  discovery},
  abstract = 	 {An enterprise information worker is often aware of a few example tuples that should be present in the output of the query. Query discovery systems have been developed to discover project-join queries that contain the given example tuples in their output. However, they require the output to exactly contain all the example tuples and do not perform any ranking. To address this limitation, we study the problem of efficiently discovering top-k project join queries which approximately contain the given example tuples in their output. We extend our algorithms to incrementally produce results as soon as the user finishes typing/modifying a cell. Our experiments on real-life and synthetic datasets show that our proposed solution is significantly more efficient compared with applying state-of-the-art algorithms.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2749452&ftid=1586897&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:15:25>},
}

@inproceedings{Benson:2014:SDW:2642918.2647387,
  author =	 {Benson, Edward and Zhang, Amy X. and Karger, David
                  R.},
  title =	 {Spreadsheet Driven Web Applications},
  booktitle =	 {Proceedings of the 27th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '14},
  year =	 2014,
  isbn =	 {978-1-4503-3069-5},
  location =	 {Honolulu, Hawaii, USA},
  pages =	 {97--106},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2642918.2647387},
  doi =		 {10.1145/2642918.2647387},
  acmid =	 2647387,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, information architecture,
                  spreadsheets, web design},
  abstract = 	 {Creating and publishing read-write-compute web applications requires programming skills beyond what most end users possess. But many end users know how to make spreadsheets that act as simple information management applications, some even with computation. We present a system for creating basic web applications using such spreadsheets in place of a server and using HTML to describe the client UI. Authors connect the two by placing spreadsheet references inside HTML attributes. Data computation is provided by spreadsheet formulas. The result is a reactive read-write-compute web page without a single line of Javascript code. Nearly all of the fifteen HTML novices we studied were able to connect HTML to spreadsheets using our method with minimal instruction. We draw conclusions from their experience and discuss future extensions to this programming model.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2647387&ftid=1503393&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:15:29>},
}

@inproceedings{Miller:2015:SPB:2814189.2814201,
  author =	 {Miller, Gary},
  title =	 {The Spreadsheet Paradigm: A Basis for Powerful and
                  Accessible Programming},
  booktitle =	 {Companion Proceedings of the 2015 ACM SIGPLAN
                  International Conference on Systems, Programming,
                  Languages and Applications: Software for Humanity},
  series =	 {SPLASH Companion 2015},
  year =	 2015,
  isbn =	 {978-1-4503-3722-9},
  location =	 {Pittsburgh, PA, USA},
  pages =	 {33--35},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/2814189.2814201},
  doi =		 {10.1145/2814189.2814201},
  acmid =	 2814201,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Empirical Testing, End-User Programming, Programming
                  Language Design, Spreadsheet Paradigm},
  abstract = 	 {This paper takes a cognition-centric approach for programming languages. It promotes the spreadsheet paradigm, with two concrete goals. First, it calls for the design and implementation of several language features to enhance the expressiveness of spreadsheet programming. Second, it describes a plan for rigorous empirical studies to retain the learnability of spreadsheet programming.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2814201&ftid=1636943&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:15:37>},
}

@inproceedings{Alawini:2014:HSR:2618243.2618263,
  author =	 {Alawini, Abdussalam and Maier, David and Tufte,
                  Kristin and Howe, Bill},
  title =	 {Helping Scientists Reconnect Their Datasets},
  booktitle =	 {Proceedings of the 26th International Conference on
                  Scientific and Statistical Database Management},
  series =	 {SSDBM '14},
  year =	 2014,
  isbn =	 {978-1-4503-2722-0},
  location =	 {Aalborg, Denmark},
  pages =	 {29:1--29:12},
  articleno =	 29,
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2618243.2618263},
  doi =		 {10.1145/2618243.2618263},
  acmid =	 2618263,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {relationship identification, scientific data
                  management, spreadsheets},
  abstract = 	 {It seems inevitable that the datasets associated with a research project proliferate over time: collaborators may extend datasets with new measurements and new attributes, new experimental runs result in new files with similar structures, and subsets of data are extracted for independent analysis. As these "residual" datasets begin to accrete over time, scientists can lose track of the derivation history that connects them, complicating data sharing, provenance tracking, and scientific reproducibility. In this paper, focusing on data in spreadsheets, we consider how observable relationships between two datasets can help scientists recall their original derivation connection. For instance, if dataset A is wholly contained in dataset B, B may be a more recent version of A and should be preferred when archiving or publishing. We articulate a space of relevant relationships, develop a set of algorithms for efficient discovery of these relationships, and organize these algorithms into a new system called ReConnect to assist scientists in relationship discovery. Our evaluation shows that existing approaches that rely on flagging differences between two spreadsheets are impractical for many relationship-discovery tasks, and a user study shows that ReConnect can improve scientists' ability to detect useful relationships and subsequently identify the best dataset for a given task.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2618263&ftid=1475425&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:15:48>},
}

@inproceedings{Lieberman:2009:SSG:1653771.1653860,
  author =	 {Lieberman, Michael D. and Samet, Hanan and
                  Sankaranarayanan, Jagan and Sperling, Jon},
  title =	 {Spatio-textual Spreadsheets: Geotagging via Spatial
                  Coherence},
  booktitle =	 {Proceedings of the 17th ACM SIGSPATIAL International
                  Conference on Advances in Geographic Information
                  Systems},
  series =	 {GIS '09},
  year =	 2009,
  isbn =	 {978-1-60558-649-6},
  location =	 {Seattle, Washington},
  pages =	 {524--527},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1653771.1653860},
  doi =		 {10.1145/1653771.1653860},
  acmid =	 1653860,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {geotagging, spatial coherence, spatio-textual,
                  spreadsheets},
  abstract = 	 {The spatio-textual spreadsheet is a conventional spreadsheet where spatial attribute values are specified textually. Techniques are presented to automatically find the textually-specified spatial attributes that are present in spreadsheets. Once the spatial attributes have been identified, an accurate translation of the values of the spatial attributes to their actual geographic locations is needed (known as geotagging). The key observation is that spreadsheets with spatial data exhibit spatial coherence --- that is, cells with spatial data that are nearby in the spreadsheet contain data that share spatial characteristics in the real world. These techniques also allow richer search engine results by returning actual tuples from spreadsheets instead of simply links to the spreadsheets. Moreover, when the search key is a particular location, results in proximity to the query can be provided rather than just exact matches.},
  review = 	 {fbie: rejected <2016-01-15 13:15:54>},
}

@inproceedings{Rothermel:2000:WTS:337180.337206,
  author =	 {Rothermel, Karen J. and Cook, Curtis R. and Burnett,
                  Margaret M. and Schonfeld, Justin and Green,
                  T. R. G. and Rothermel, Gregg},
  title =	 {WYSIWYT Testing in the Spreadsheet Paradigm: An
                  Empirical Evaluation},
  booktitle =	 {Proceedings of the 22Nd International Conference on
                  Software Engineering},
  series =	 {ICSE '00},
  year =	 2000,
  isbn =	 {1-58113-206-9},
  location =	 {Limerick, Ireland},
  pages =	 {230--239},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/337180.337206},
  doi =		 {10.1145/337180.337206},
  acmid =	 337206,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies, spreadsheets, testing, visual
                  programming},
  abstract = 	 {Is it possible to achieve some of the benefits of formal testing within the informal programming conventions of the spreadsheet paradigm? We have been working on an approach that attempts to do so via the development of a testing methodology for this paradigm. Our “What You See Is What You Test” (WYSIWYT) methodology supplements the convention by which spreadsheets provide automatic immediate visual feedback about values by providing automatic immediate visual feedback about “testedness”. In previous work we described this methodology; in this paper, we present empirical data about the methodology's effectiveness. Our results show that the use of the methodology was associated with significant improvement in testing effectiveness and efficiency even with no training on the theory of testing or test adequacy that the model implements. These results may be due at least in part to the fact that use of the methodology was associated with a significant reduction in overconfidence.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=337206&ftid=7032&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:16:02>},
}

@inproceedings{Nasrallah:2014:TBS:2685617.2685660,
  author =	 {Nasrallah, Walid F.},
  title =	 {Two Bare-bones Simulations of Human-controlled
                  Systems},
  booktitle =	 {Proceedings of the 2014 Summer Simulation
                  Multiconference},
  series =	 {SummerSim '14},
  year =	 2014,
  location =	 {Monterey, California},
  pages =	 {43:1--43:7},
  articleno =	 43,
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=2685617.2685660},
  acmid =	 2685660,
  publisher =	 {Society for Computer Simulation International},
  address =	 {San Diego, CA, USA},
  keywords =	 {human-controlled systems, iterative, rapid
                  prototyping, spreadsheets},
  abstract = 	 {This paper describes two simulations built upon iterative calculation of mutually referenced equations in a spreadsheet. The modeling approach enables a researcher, practitioner or student to easily see on one screen all the relationships between the different components of the simulation, and to modify any simulation variable, be it global or local, either directly or by automated computation from any other global or local variable. This is useful in developing quick prototypes, since he idiom of spreadsheet cells and arithmetic operators on the cell contents is more widely (and easily) understood than various programming paradigms and idioms (procedural, object-oriented, distributed, etc.) "Black Box" simulation platforms, whether packaged as commercial software, freeware or open-source, are simpler than programming languages, but the assumptions built into the program constrain free exploration. So when exploring a new approach to simulating a known system, simulating inside a spreadsheet (with a well-ordered structure for iterative calculation) is a natural and powerful approach. Two examples illustrate how this approach can make it easy to see how new assumptions change a known model. The first explores the effects of traffic density on car velocity, and adds the assumption that the direction in which density is measured changes the effect on velocity. The second example considers how completion time of a project with multiple linked tasks can change non-linearly when project decision makers are become more busy.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2685660&ftid=1511046&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:16:06>},
}

@inproceedings{Erwig:2005:AGM:1062455.1062494,
  author =	 {Erwig, Martin and Abraham, Robin and Cooperstein,
                  Irene and Kollmansberger, Steve},
  title =	 {Automatic Generation and Maintenance of Correct
                  Spreadsheets},
  booktitle =	 {Proceedings of the 27th International Conference on
                  Software Engineering},
  series =	 {ICSE '05},
  year =	 2005,
  isbn =	 {1-58113-963-2},
  location =	 {St. Louis, MO, USA},
  pages =	 {136--145},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1062455.1062494},
  doi =		 {10.1145/1062455.1062494},
  acmid =	 1062494,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user software engineering, error prevention,
                  program generation, spreadsheet, template, type
                  system},
  abstract = 	 {Existing spreadsheet systems allow users to change cells arbitrarily, which is a major source of spreadsheet errors. We propose a system that prevents errors in spreadsheets by restricting spreadsheet updates to only those that are logically and technically correct. The system is based on the concept of templates that describe the principal structure of the initial spreadsheet and all of its future versions. We have developed a program generator that translates a template into an initial spreadsheet together with customized update operations for changing cells and inserting/deleting rows and columns for this particular template.We have designed a type system for templates that ensures the following form of "spreadsheet maintenance safety": Update operations that are generated from a type-correct template are proved to transform the spreadsheet only according to the template and to never produce any omission, reference, or type errors.Finally, we have developed a prototype as an extension to Excel, which has been shown by a preliminary usability study to be well accepted by end users.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1062494&ftid=315686&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:16:18>},
}

@inproceedings{Ruthruff:2003:ESV:774833.774851,
  author =	 {Ruthruff, J. and Creswick, E. and Burnett, M. and
                  Cook, C. and Prabhakararao, S. and Fisher,II, M. and
                  Main, M.},
  title =	 {End-user Software Visualizations for Fault
                  Localization},
  booktitle =	 {Proceedings of the 2003 ACM Symposium on Software
                  Visualization},
  series =	 {SoftVis '03},
  year =	 2003,
  isbn =	 {1-58113-642-0},
  location =	 {San Diego, California},
  pages =	 {123--132},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/774833.774851},
  doi =		 {10.1145/774833.774851},
  acmid =	 774851,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, end-user software engineering,
                  end-user software visualization, fault localization,
                  spreadsheets},
  abstract = 	 {End-user programming has become the most common form of programming today. However, despite this growth, there has been little investigation into bringing the benefits of software visualization to end-user programmers. Evidence from the spreadsheet paradigm, probably the most widely used end-user environment, reveals that end users' programs often contain faults. We would like to integrate software visualization into these end-user environments to help end users deal with the reliability issues in their programs. Towards this end, we have devised several fault localization visualization techniques for spreadsheets. This paper describes these techniques and reports the results of a formative study---using tests created by end users---to investigate how these fault localization techniques compare. Our results reveal some strengths and weaknesses of each technique, and provide insights into the cost-effectiveness of each technique for the interactive world of end-user spreadsheet development.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=774851&ftid=155212&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:16:53>},
}

@inproceedings{Stadelmann:1993:SBC:168642.168664,
  author =	 {Stadelmann, Marc},
  title =	 {A Spreadsheet Based on Constraints},
  booktitle =	 {Proceedings of the 6th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '93},
  year =	 1993,
  isbn =	 {0-89791-628-X},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {217--224},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/168642.168664},
  doi =		 {10.1145/168642.168664},
  acmid =	 168664,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {APL, constraint satisfaction, constraints, matrices,
                  spreadsheets, user-interface, vectors},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=168664&ftid=33824&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:05>},
}

@inproceedings{Abraham:2007:GSD:1248820.1248858,
  author =	 {Abraham, Robin and Erwig, Martin},
  title =	 {GoalDebug: A Spreadsheet Debugger for End Users},
  booktitle =	 {Proceedings of the 29th International Conference on
                  Software Engineering},
  series =	 {ICSE '07},
  year =	 2007,
  isbn =	 {0-7695-2828-7},
  pages =	 {251--260},
  numpages =	 10,
  url =		 {http://dx.doi.org/10.1109/ICSE.2007.39},
  doi =		 {10.1109/ICSE.2007.39},
  acmid =	 1248858,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: accepted <2016-01-15 13:17:08>},
}

@article{Grigoreanu:2012:EDS:2147783.2147788,
  author =	 {Grigoreanu, Valentina and Burnett, Margaret and
                  Wiedenbeck, Susan and Cao, Jill and Rector, Kyle and
                  Kwan, Irwin},
  title =	 {End-user Debugging Strategies: A Sensemaking
                  Perspective},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {March 2012},
  volume =	 19,
  number =	 1,
  month =	 may,
  year =	 2012,
  issn =	 {1073-0516},
  pages =	 {5:1--5:28},
  articleno =	 5,
  numpages =	 28,
  url =		 {http://doi.acm.org/10.1145/2147783.2147788},
  doi =		 {10.1145/2147783.2147788},
  acmid =	 2147788,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {End-user programming, debugging, debugging
                  strategies, end-user software engineering, gender
                  HCI, gender differences, sensemaking, spreadsheets},
  abstract = 	 {Despite decades of research into how professional programmers debug, only recently has work emerged about how end-user programmers attempt to debug programs. Without this knowledge, we cannot build tools to adequately support their needs. This article reports the results of a detailed qualitative empirical study of end-user programmers' sensemaking about a spreadsheet's correctness. Using our study's data, we derived a sensemaking model for end-user debugging and categorized participants' activities and verbalizations according to this model, allowing us to investigate how participants went about debugging. Among the results are identification of the prevalence of information foraging during end-user debugging, two successful strategies for traversing the sensemaking model, potential ties to gender differences in the literature, sensemaking sequences leading to debugging progress, and sequences tied with troublesome points in the debugging process. The results also reveal new implications for the design of spreadsheet tools to support end-user programmers' sensemaking during debugging.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2147788&ftid=1197847&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:14>},
}

@inproceedings{Spenke:1996:FIT:237091.237097,
  author =	 {Spenke, Michael and Beilken, Christian and Berlage,
                  Thomas},
  title =	 {FOCUS: The Interactive Table for Product Comparison
                  and Selection},
  booktitle =	 {Proceedings of the 9th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '96},
  year =	 1996,
  isbn =	 {0-89791-798-7},
  location =	 {Seattle, Washington, USA},
  pages =	 {41--50},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/237091.237097},
  doi =		 {10.1145/237091.237097},
  acmid =	 237097,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {dynamic queries, focus+context technique,
                  interactive data exploration, spreadsheets, tables},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=237097&ftid=42890&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:19>},
}

@inproceedings{Levoy:1994:SI:192161.192190,
  author =	 {Levoy, Marc},
  title =	 {Spreadsheets for Images},
  booktitle =	 {Proceedings of the 21st Annual Conference on
                  Computer Graphics and Interactive Techniques},
  series =	 {SIGGRAPH '94},
  year =	 1994,
  isbn =	 {0-89791-667-0},
  pages =	 {139--146},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/192161.192190},
  doi =		 {10.1145/192161.192190},
  acmid =	 192190,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data visualization, flow charts, spreadsheets, user
                  interfaces, visual programming languages},
  abstract = 	 {We describe a data visualization system based on spreadsheets. Cells in our spreadsheet contain graphical objects such as images, volumes, or movies. Cells may also contain widgets such as buttons, sliders, or curve editors. Objects are displayed in miniature inside each cell. Formulas for cells are written in a general-purpose programming language (Tcl) augmented with operators for array manipulation, image processing, and rendering.Compared to flow chart visualization systems, spreadsheets are more expressive, morescalable, and easier to program. Compared to conventional numerical spreadsheets, spreadsheets for images pose several unique design problems: larger formulas, longer computation times, and more complicated intercelldependencies. In response to these problems, we have extended the spreadsheet paradigm in three ways: formulas can display their results anywhere in the spreadsheet, cells can be selectively disabled, and multiple cells can be edited at once. We discuss these extensions and their implications, and we also point out some unexpected uses for our spreadsheets: as a visual database browser, as a graphical user interface builder, as a smart clipboard for the desktop, and as a presentation tool.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=192190&ftid=609020&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:17:26>},
}

@article{Gulwani:2012:SDM:2240236.2240260,
  author =	 {Gulwani, Sumit and Harris, William R. and Singh,
                  Rishabh},
  title =	 {Spreadsheet Data Manipulation Using Examples},
  journal =	 {Commun. ACM},
  issue_date =	 {August 2012},
  volume =	 55,
  number =	 8,
  month =	 aug,
  year =	 2012,
  issn =	 {0001-0782},
  pages =	 {97--105},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/2240236.2240260},
  doi =		 {10.1145/2240236.2240260},
  acmid =	 2240260,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Millions of computer end users need to perform tasks over large spreadsheet data, yet lack the programming knowledge to do such tasks automatically. We present a programming by example methodology that allows end users to automate such repetitive tasks. Our methodology involves designing a domain-specific language and developing a synthesis algorithm that can learn programs in that language from user-provided examples. We present instantiations of this methodology for particular domains of tasks: (a) syntactic transformations of strings using restricted forms of regular expressions, conditionals, and loops, (b) semantic transformations of strings involving lookup in relational tables, and (c) layout transformations on spreadsheet tables. We have implemented this technology as an add-in for the Microsoft Excel Spreadsheet system and have evaluated it successfully over several benchmarks picked from various Excel help forums.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2240260&ftid=1265813&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:17:32>},
}

@article{Ronen:1989:SAD:63238.63244,
  author =	 {Ronen, Boaz and Palley, Michael A and Lucas,Jr.,
                  Henry C.},
  title =	 {Spreadsheet Analysis and Design},
  journal =	 {Commun. ACM},
  issue_date =	 {Jan. 1989},
  volume =	 32,
  number =	 1,
  month =	 jan,
  year =	 1989,
  issn =	 {0001-0782},
  pages =	 {84--93},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/63238.63244},
  doi =		 {10.1145/63238.63244},
  acmid =	 63244,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Although spreadsheet programs and microcomputers have revolutionized information processing in organizations, a significant number of serious errors have been reported through the misuse of this technology. This article discusses several different contexts for the development of spreadsheet models and presents structured design techniques for these models.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=63244&ftid=19968&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:17:37>},
}

@article{Hudson:1994:UIS:195784.195787,
  author =	 {Hudson, Scott E.},
  title =	 {User Interface Specification Using an Enhanced
                  Spreadsheet Model},
  journal =	 {ACM Trans. Graph.},
  issue_date =	 {July 1994},
  volume =	 13,
  number =	 3,
  month =	 jul,
  year =	 1994,
  issn =	 {0730-0301},
  pages =	 {209--239},
  numpages =	 31,
  url =		 {http://doi.acm.org/10.1145/195784.195787},
  doi =		 {10.1145/195784.195787},
  acmid =	 195787,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {automatic display update, constraint systems, direct
                  manipulation, end-user programming, interface
                  builders, prototype-instance-based inheritance,
                  semantic feedback, user interface management
                  systems},
  abstract = 	 {This paper describes a new interactive environment for user interface specification which is based on an enhanced spreadsheet model of computation. This environment allows sophisticated graphical user interfaces with dynamic feedback to be implemented with little or no explicit programming. Its goal is to support user interface specification by nonprogramming experts in human factors, visual design, or the application domain. In addition, the system is designed to allow sophisticated end-users to modify and customize their own interfaces. The system is based on a data flow model of computation. This model is presented to the interface designer in the form of a spreadsheet enhanced with new constructs for easier programming and reuse. These constructs include an improved interactive programming environment, a prototype-instance-based inheritance system, support for composition, abstraction, and customization using indirect references, the addition of support for graphical inputs and outputs, and support for the encapsulation of application data structures and routines within system objects.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=195787&ftid=36925&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:42>},
}

@inproceedings{Jankun-Kelly:2000:SIV:375213.375220,
  author =	 {Jankun-Kelly, T. J. and Ma, Kwan-Liu},
  title =	 {A Spreadsheet Interface for Visualization
                  Exploration},
  booktitle =	 {Proceedings of the Conference on Visualization '00},
  series =	 {VIS '00},
  year =	 2000,
  isbn =	 {1-58113-309-X},
  location =	 {Salt Lake City, Utah, USA},
  pages =	 {69--76},
  numpages =	 8,
  url =		 {http://dl.acm.org/citation.cfm?id=375213.375220},
  acmid =	 375220,
  publisher =	 {IEEE Computer Society Press},
  address =	 {Los Alamitos, CA, USA},
  keywords =	 {knowledge representation, scientific visualization,
                  spreadsheets, user interfaces, visualization
                  systems, volume rendering},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=375220&ftid=76352&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:17:48>},
}

@inproceedings{Hong:2011:OTD:1999927.1999937,
  author =	 {Hong, YoonSung and Worden, Hilary K. and Borriello,
                  Gaetano},
  title =	 {ODK Tables: Data Organization and Information
                  Services on a Smartphone},
  booktitle =	 {Proceedings of the 5th ACM Workshop on Networked
                  Systems for Developing Regions},
  series =	 {NSDR '11},
  year =	 2011,
  isbn =	 {978-1-4503-0739-0},
  location =	 {Bethesda, Maryland, USA},
  pages =	 {33--38},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1999927.1999937},
  doi =		 {10.1145/1999927.1999937},
  acmid =	 1999937,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data tables, mobile databases, mobile phones, sms,
                  spreadsheets},
  abstract = 	 {Many information services require the transfer of only small amounts of information between a client and server. Furthermore, their deployment often requires an ecosystem of cloud services rarely present in developing world contexts. ODK Tables (a component of the Open Data Kit) provides a way of organizing data into database tables hosted directly by a smartphone. Clients can make new entries into the tables (under an extensible access control model) and make queries of existing information. ODK Tables supports SMS-based interactions and allows import/export of tables to other storage whether in the cloud or on another local computing device. The objective of ODK Tables is to lower barriers experienced by entrepreneurs or other information providers in the developing world to field their own information services. This paper describes ODK Tables' capabilities, user interface, performance characteristics, and some example use cases.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1999937&ftid=991585&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:54>},
}

@inproceedings{Hartley:1990:ORS:328885.329266,
  author =	 {Hartley,III, Dean S.},
  title =	 {The Oak Ridge Spreadsheet Battle Model},
  booktitle =	 {Proceedings of the 22Nd Conference on Winter
                  Simulation},
  series =	 {WSC' 90},
  year =	 1990,
  isbn =	 {0-911801-72-3},
  location =	 {New Orleans, Louisiana, USA},
  pages =	 {863--869},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=328885.329266},
  acmid =	 329266,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=329266&ftid=46475&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:17:58>},
}

@inproceedings{Babbitt:1998:ISS:353053.353087,
  author =	 {Babbitt, Timothy G. and Galletta, Dennis F. and
                  Lopes, Alexandre B.},
  title =	 {Influencing the Success of Spreadsheet Development
                  by Novice Users},
  booktitle =	 {Proceedings of the International Conference on
                  Information Systems},
  series =	 {ICIS '98},
  year =	 1998,
  location =	 {Helsinki, Finland},
  pages =	 {319--324},
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=353053.353087},
  acmid =	 353087,
  publisher =	 {Association for Information Systems},
  address =	 {Atlanta, GA, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=353087&ftid=3821&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:18:07>},
}

@inproceedings{Marchese:1998:TCG:280953.281012,
  author =	 {Marchese, Francis T.},
  title =	 {Teaching Computer Graphics with Spreadsheets},
  booktitle =	 {ACM SIGGRAPH 98 Conference Abstracts and
                  Applications},
  series =	 {SIGGRAPH '98},
  year =	 1998,
  isbn =	 {1-58113-046-5},
  location =	 {Orlando, Florida, USA},
  pages =	 {84--87},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/280953.281012},
  doi =		 {10.1145/280953.281012},
  acmid =	 281012,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheets are a great way to introduce computer graphics
concepts to computer science students. Through direct manipulation
of numbers, students develop a more concrete understanding of the
data they compute from the formulas they derive and use. This paper
presents some experiences using spreadsheets for in-class
demonstrations and homework assignments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=281012&ftid=465692&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:18:13>},
}

@article{Fisher:2006:IAT:1131421.1131423,
  author =	 {Fisher,II, Marc and Rothermel, Gregg and Brown,
                  Darren and Cao, Mingming and Cook, Curtis and
                  Burnett, Margaret},
  title =	 {Integrating Automated Test Generation into the
                  WYSIWYT Spreadsheet Testing Methodology},
  journal =	 {ACM Trans. Softw. Eng. Methodol.},
  issue_date =	 {April 2006},
  volume =	 15,
  number =	 2,
  month =	 apr,
  year =	 2006,
  issn =	 {1049-331X},
  pages =	 {150--194},
  numpages =	 45,
  url =		 {http://doi.acm.org/10.1145/1131421.1131423},
  doi =		 {10.1145/1131421.1131423},
  acmid =	 1131423,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {End-user software engineering, end-user programming,
                  test case generation, testing},
  abstract = 	 {Spreadsheet languages, which include commercial spreadsheets and various research systems, have had a substantial impact on end-user computing. Research shows, however, that spreadsheets often contain faults. Thus, in previous work we presented a methodology that helps spreadsheet users test their spreadsheet formulas. Our empirical studies have shown that end users can use this methodology to test spreadsheets more adequately and efficiently; however, the process of generating test cases can still present a significant impediment. To address this problem, we have been investigating how to incorporate automated test case generation into our testing methodology in ways that support incremental testing and provide immediate visual feedback. We have used two techniques for generating test cases, one involving random selection and one involving a goal-oriented approach. We describe these techniques and their integration into our testing environment, and report results of an experiment examining their effectiveness and efficiency.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1131423&ftid=357704&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:18:26>},
}

@article{Harris:2011:STT:1993316.1993536,
  author =	 {Harris, William R. and Gulwani, Sumit},
  title =	 {Spreadsheet Table Transformations from Examples},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {June 2011},
  volume =	 46,
  number =	 6,
  month =	 jun,
  year =	 2011,
  issn =	 {0362-1340},
  pages =	 {317--328},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1993316.1993536},
  doi =		 {10.1145/1993316.1993536},
  acmid =	 1993536,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, program synthesis, programming
                  by example, spreadsheet programming, table
                  manipulation, user intent},
  abstract = 	 {Every day, millions of computer end-users need to perform tasks over large, tabular data, yet lack the programming knowledge to do such tasks automatically. In this work, we present an automatic technique that takes from a user an example of how the user needs to transform a table of data, and provides to the user a program that implements the transformation described by the example. In particular, we present a language of programs TableProg that can describe transformations that real users require.We then present an algorithm ProgFromEx that takes an example input and output table, and infers a program in TableProg that implements the transformation described by the example. When the program is applied to the example input, it reproduces the example output. When the program is applied to another, potentially larger, table with a 'similar' layout as the example input table, then the program produces a corresponding table with a layout that is similar to the example output table. A user can apply ProgFromEx interactively, providing multiple small examples to obtain a program that implements the transformation that the user desires. Moreover, ProgFromEx can help identify 'noisy' examples that contain errors. To evaluate the practicality of TableProg and ProgFromEx, we implemented ProgFromEx as a module for the Microsoft Excel spreadsheet program. We applied the module to automatically implement over 50 table transformations specified by endusers through examples on online Excel help forums. In seconds, ProgFromEx found programs that satisfied the examples and could be applied to larger input tables. This experience demonstrates that TableProg and ProgFromEx can significantly automate the tasks over tabular data that users need to perform.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1993536&ftid=981798&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:18:32>},
}

@inproceedings{Harris:2011:STT:1993498.1993536,
  author =	 {Harris, William R. and Gulwani, Sumit},
  title =	 {Spreadsheet Table Transformations from Examples},
  booktitle =	 {Proceedings of the 32Nd ACM SIGPLAN Conference on
                  Programming Language Design and Implementation},
  series =	 {PLDI '11},
  year =	 2011,
  isbn =	 {978-1-4503-0663-8},
  location =	 {San Jose, California, USA},
  pages =	 {317--328},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1993498.1993536},
  doi =		 {10.1145/1993498.1993536},
  acmid =	 1993536,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, program synthesis, programming
                  by example, spreadsheet programming, table
                  manipulation, user intent},
  abstract = 	 {Every day, millions of computer end-users need to perform tasks over large, tabular data, yet lack the programming knowledge to do such tasks automatically. In this work, we present an automatic technique that takes from a user an example of how the user needs to transform a table of data, and provides to the user a program that implements the transformation described by the example. In particular, we present a language of programs TableProg that can describe transformations that real users require.We then present an algorithm ProgFromEx that takes an example input and output table, and infers a program in TableProg that implements the transformation described by the example. When the program is applied to the example input, it reproduces the example output. When the program is applied to another, potentially larger, table with a 'similar' layout as the example input table, then the program produces a corresponding table with a layout that is similar to the example output table. A user can apply ProgFromEx interactively, providing multiple small examples to obtain a program that implements the transformation that the user desires. Moreover, ProgFromEx can help identify 'noisy' examples that contain errors. To evaluate the practicality of TableProg and ProgFromEx, we implemented ProgFromEx as a module for the Microsoft Excel spreadsheet program. We applied the module to automatically implement over 50 table transformations specified by endusers through examples on online Excel help forums. In seconds, ProgFromEx found programs that satisfied the examples and could be applied to larger input tables. This experience demonstrates that TableProg and ProgFromEx can significantly automate the tasks over tabular data that users need to perform.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1993536&ftid=981798&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:18:36>},
}

@article{Ballou:1987:IDQ:27544.27546,
  author =	 {Ballou, Donald P. and Pazer, Harold L. and Belardo,
                  Salvatore and Klein, Barbara},
  title =	 {Implications of Data Quality for Spreadsheet
                  Analysis},
  journal =	 {SIGMIS Database},
  issue_date =	 {March 1987},
  volume =	 18,
  number =	 3,
  month =	 mar,
  year =	 1987,
  issn =	 {0095-0033},
  pages =	 {13--19},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/27544.27546},
  doi =		 {10.1145/27544.27546},
  acmid =	 27546,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper examines the impact of deficiencies in data quality on the results generated for spreadsheet applications. The purpose is to describe a framework which can be systematically used to determine the relative importance of potential errors in operational and judgmental data. Special emphasis is placed on analyzing the implications of deficiencies in data quality on projected spreadsheet results.},
  review = 	 {fbie: rejected <2016-01-15 13:18:46>},
}

@inproceedings{Scaffidi:2008:UTV:1370847.1370850,
  author =	 {Scaffidi, Christopher and Cypher, Allen and Elbaum,
                  Sebastian and Koesnandar, Andhy and Lin, James and
                  Myers, Brad and Shaw, Mary},
  title =	 {Using Topes to Validate and Reformat Data in
                  End-user Programming Tools},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {11--15},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370850},
  doi =		 {10.1145/1370847.1370850},
  acmid =	 1370850,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {abstraction, data, end-user programming, end-user
                  software engineering, spreadsheets, validation, web
                  applications, web macros},
  abstract = 	 {End-user programming tools offer no data types except "string" for many categories of data, such as person names and street addresses. Consequently, these tools cannot automatically validate or reformat these data. To address this problem, we have developed a user-extensible model for string-like data. Each "tope" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data. Specifically, each tope implementation contains software functions for recognizing and reformatting instances of that tope's kind of data. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or invalid data can be double-checked and possibly corrected, thereby increasing the overall reliability of the data. Valid data can be automatically reformatted to any of the formats appropriate for that kind of data. To show the general applicability of topes, we describe new features that topes have enabled us to provide in four tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370850&ftid=498647&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:18:53>},
}

@inproceedings{Abraham:2006:TIS:1140335.1140346,
  author =	 {Abraham, Robin and Erwig, Martin},
  title =	 {Type Inference for Spreadsheets},
  booktitle =	 {Proceedings of the 8th ACM SIGPLAN International
                  Conference on Principles and Practice of Declarative
                  Programming},
  series =	 {PPDP '06},
  year =	 2006,
  isbn =	 {1-59593-388-3},
  location =	 {Venice, Italy},
  pages =	 {73--84},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1140335.1140346},
  doi =		 {10.1145/1140335.1140346},
  acmid =	 1140346,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user software engineering, templates, type
                  inference},
  abstract = 	 {Spreadsheets are the most popular programming systems in use today. Since spreadsheets are visual, first-order functional languages, research into the foundations of spreadsheets is therefore a highly relevant topic for the principles and, in particular, the practice, of declarative programming.Since the error rate in spreadsheets is very high and since those errors have significant impact, methods and tools that can help detect and remove errors from spreadsheets are very much needed. Type systems have traditionally played a strong role in detecting errors in programming languages, and it is therefore reasonable to ask whether type systems could not be helpful in improving the current situation of spreadsheet programming.In this paper we introduce a type system and a type inference algorithm for spreadsheets and demonstrate how this algorithm and the underlying typing concept can identify programming errors in spreadsheets. In addition, we also demonstrate how the type inference algorithm can be employed to infer models, or specifications, for spreadsheets, which can be used to prevent future errors in spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1140346&ftid=362172&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:18:57>},
}

@inproceedings{Chang:2014:CIW:2642918.2647371,
  author =	 {Chang, Kerry Shih-Ping and Myers, Brad A.},
  title =	 {Creating Interactive Web Data Applications with
                  Spreadsheets},
  booktitle =	 {Proceedings of the 27th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '14},
  year =	 2014,
  isbn =	 {978-1-4503-3069-5},
  location =	 {Honolulu, Hawaii, USA},
  pages =	 {87--96},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2642918.2647371},
  doi =		 {10.1145/2642918.2647371},
  acmid =	 2647371,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, live programming, mashups,
                  spreadsheets, web applications, web services},
  abstract = 	 {While more and more data are available through web services, it remains difficult for end-users to create web applications that make use of these data without having to write complex code. We present Gneiss, a live programming environment that extends the spreadsheet metaphor to support creating interactive web applications that dynamically use local or web data from multiple sources. Gneiss closely integrates a spreadsheet editor with a web interface builder to let users demonstrate bindings between properties of web GUI elements and cells in the spreadsheet while working with real web service data. The spreadsheet editor provides two-way connections to web services, to both visualize and retrieve different data based on the user input in the web interface. Gneiss achieves rich interactivity without the need for event-based programming by extending the 'pull model' of formulas that is familiar to the spreadsheet users. We use a series of examples to demonstrate Gneiss's ability to create a variety of interactive web data applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2647371&ftid=1503392&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:10>},
}

@inproceedings{Fuller:1993:DOC:162754.162950,
  author =	 {Fuller, David A. and Mujica, Sergio T. and Pino,
                  Jos{\'e} A.},
  title =	 {The Design of an Object-oriented Collaborative
                  Spreadsheet with Version Control and History
                  Management},
  booktitle =	 {Proceedings of the 1993 ACM/SIGAPP Symposium on
                  Applied Computing: States of the Art and Practice},
  series =	 {SAC '93},
  year =	 1993,
  isbn =	 {0-89791-567-4},
  location =	 {Indianapolis, Indiana, USA},
  pages =	 {416--423},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/162754.162950},
  doi =		 {10.1145/162754.162950},
  acmid =	 162950,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {history management, interfaces, object-oriented,
                  spreadsheet, version control},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=162950&ftid=29787&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:14>},
}

@inproceedings{Kovalenko:2013:TEC:2506182.2506190,
  author =	 {Kovalenko, Olga and Serral, Estefan\'{\i}a and
                  Biffl, Stefan},
  title =	 {Towards Evaluation and Comparison of Tools for
                  Ontology Population from Spreadsheet Data},
  booktitle =	 {Proceedings of the 9th International Conference on
                  Semantic Systems},
  series =	 {I-SEMANTICS '13},
  year =	 2013,
  isbn =	 {978-1-4503-1972-0},
  location =	 {Graz, Austria},
  pages =	 {57--64},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2506182.2506190},
  doi =		 {10.1145/2506182.2506190},
  acmid =	 2506190,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data transformation, knowledge extraction, ontology
                  engineering, ontology population, spreadsheet data},
  abstract = 	 {Semantic Web technologies and ontologies increasingly provide mission-critical capabilities for a variety of applications, not only in the Web, but also in industry projects to facilitate semantic integration and interoperability between heterogeneous systems. Due to this proliferation in the use of ontologies, technologies and tools have been developed to facilitate the ontology engineering process and ontology population, as a part of this process. As spreadsheets are widely used to store and exchange data, academia and industry have developed a range of tools and mapping techniques to support the (semi-)automated translation of spreadsheet data into OWL/RDF. Existing tools vary in many aspects, therefore it can be difficult to select tool that fits best for a specific usage context. In this paper we analyzed several types of end users, which could be interested to apply such tools in their workflow, and their specific needs. Based on this analysis we propose an evaluation framework that could facilitate tools comparison; and c) search for an appropriate tool for a specific task/problem. In order to validate the proposed evaluation framework, a qualitative analysis of a set of six tools for ontology population has been performed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2506190&ftid=1401903&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:22>},
}

@inproceedings{Wilcox:1997:CVF:258549.258721,
  author =	 {Wilcox, E. M. and Atwood, J. W. and Burnett,
                  M. M. and Cadiz, J. J. and Cook, C. R.},
  title =	 {Does Continuous Visual Feedback Aid Debugging in
                  Direct-manipulation Programming Systems?},
  booktitle =	 {Proceedings of the ACM SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '97},
  year =	 1997,
  isbn =	 {0-89791-802-9},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {258--265},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/258549.258721},
  doi =		 {10.1145/258549.258721},
  acmid =	 258721,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, direct manipulation, empirical study,
                  end-user programming, liveness, spreadsheets, visual
                  programming languages},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=258721&ftid=38889&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:30>},
}

@inproceedings{Chang:2015:SMH:2702123.2702587,
  author =	 {Chang, Kerry Shih-Ping and Myers, Brad A.},
  title =	 {A Spreadsheet Model for Handling Streaming Data},
  booktitle =	 {Proceedings of the 33rd Annual ACM Conference on
                  Human Factors in Computing Systems},
  series =	 {CHI '15},
  year =	 2015,
  isbn =	 {978-1-4503-3145-6},
  location =	 {Seoul, Republic of Korea},
  pages =	 {3399--3402},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2702123.2702587},
  doi =		 {10.1145/2702123.2702587},
  acmid =	 2702587,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user pro-gramming, live programming,
                  spreadsheets, streaming data, web services},
  abstract = 	 {We present a spreadsheet model for working with streaming data. Our prototype tool presents techniques to let the user stream data from web services and web input elements to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells record metadata about where and when the data came from, allowing the user to view and manipulate streaming data using temporal information. Starting and pausing a data stream in the spreadsheet can be controlled programmatically using values computed by spreadsheet cells, making the spreadsheet program highly dynamic and interactive. We demonstrate the range of our design with a series of examples highlighting its ability to create different kinds of applications that process real-time data from the web using simple spreadsheet formulas.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2702587&ftid=1565196&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:34>},
}

@inproceedings{Ginige:2010:URW:1842993.1843017,
  author =	 {Ginige, Athula and Paolino, Luca and Sebillo, Monica
                  and Shrodkar, Richa and Vitiello, Giuliana},
  title =	 {User Requirements for a Web Based
                  Spreadsheet-mediated Collaboration},
  booktitle =	 {Proceedings of the International Conference on
                  Advanced Visual Interfaces},
  series =	 {AVI '10},
  year =	 2010,
  isbn =	 {978-1-4503-0076-6},
  location =	 {Roma, Italy},
  pages =	 {133--136},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1842993.1843017},
  doi =		 {10.1145/1842993.1843017},
  acmid =	 1843017,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {HCI design patterns, artifact mediated
                  collaboration, scenario-based design, usability
                  principles},
  abstract = 	 {This paper reports the initial results of a research project to investigate how to develop a web based spreadsheet mediated business collaboration system that could notably enhance the business processes presently carried out by Small to Medium sized Enterprises. Using a scenario-based design approach, a set of user's requirements were extracted from an appropriate field study. These requirements were then analysed in the context of well-known usability principles, and a set of design implications were derived based on a selected set of HCI design patterns related to cooperative interaction design. Starting from that knowledge, suitable interactive collaboration scenarios have been drawn, from which a list of user interface requirements for a web based spreadsheet mediated collaboration system has been formulated.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1843017&ftid=828997&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:53>},
}

@inproceedings{Thornton:2008:DTE:1384271.1384303,
  author =	 {Thornton, Matthew and Edwards, Stephen H.},
  title =	 {A Data Type to Exploit Online Data Sources},
  booktitle =	 {Proceedings of the 13th Annual Conference on
                  Innovation and Technology in Computer Science
                  Education},
  series =	 {ITiCSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-078-4},
  location =	 {Madrid, Spain},
  pages =	 {114--118},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1384271.1384303},
  doi =		 {10.1145/1384271.1384303},
  acmid =	 1384303,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {csv, data mining, data table, objectdraw,
                  spreadsheet, web-cat},
  abstract = 	 {Recent work in developing student assignments has involved making use of online data resources to make them more interesting and to give students real world information to interact with in some manner. While definitely a practical approach, the work that has been done so far is either for "CS0" courses targeted at non-majors, often using tools like Microsoft Excel, or courses that require a level of skill at programming from the students. Additionally, existing tools are specific to a particular structure of the data (CSV, XML, and others). As a result, these constraints make on-line real-world data sets difficult to use in typical introductory programming courses for majors. Objects-first approaches to teaching introductory programming advocate the use of objects early on. Consequently, students are able to take advantage of using data types early on. We have created an interface that allows students to access real-world data sets from online (or local) sources in a uniform fashion. This abstraction allows students with minimal programming experience to load, process, and manipulate external data sets in a variety of formats. We also developed a lab assignment where students accessed an online CSV data source to demonstrate feasibility and to gain experience with classroom use of this approach.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1384303&ftid=537539&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:19:59>},
}

@article{Thornton:2008:DTE:1597849.1384303,
  author =	 {Thornton, Matthew and Edwards, Stephen H.},
  title =	 {A Data Type to Exploit Online Data Sources},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {September 2008},
  volume =	 40,
  number =	 3,
  month =	 jun,
  year =	 2008,
  issn =	 {0097-8418},
  pages =	 {114--118},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1597849.1384303},
  doi =		 {10.1145/1597849.1384303},
  acmid =	 1384303,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {csv, data mining, data table, objectdraw,
                  spreadsheet, web-cat},
  abstract = 	 {Recent work in developing student assignments has involved making use of online data resources to make them more interesting and to give students real world information to interact with in some manner. While definitely a practical approach, the work that has been done so far is either for "CS0" courses targeted at non-majors, often using tools like Microsoft Excel, or courses that require a level of skill at programming from the students. Additionally, existing tools are specific to a particular structure of the data (CSV, XML, and others). As a result, these constraints make on-line real-world data sets difficult to use in typical introductory programming courses for majors. Objects-first approaches to teaching introductory programming advocate the use of objects early on. Consequently, students are able to take advantage of using data types early on. We have created an interface that allows students to access real-world data sets from online (or local) sources in a uniform fashion. This abstraction allows students with minimal programming experience to load, process, and manipulate external data sets in a variety of formats. We also developed a lab assignment where students accessed an online CSV data source to demonstrate feasibility and to gain experience with classroom use of this approach.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1384303&ftid=537539&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:20:03>},
}

@inproceedings{Burnett:2003:ESE:776816.776828,
  author =	 {Burnett, Margaret and Cook, Curtis and Pendse, Omkar
                  and Rothermel, Gregg and Summet, Jay and Wallace,
                  Chris},
  title =	 {End-user Software Engineering with Assertions in the
                  Spreadsheet Paradigm},
  booktitle =	 {Proceedings of the 25th International Conference on
                  Software Engineering},
  series =	 {ICSE '03},
  year =	 2003,
  isbn =	 {0-7695-1877-X},
  location =	 {Portland, Oregon},
  pages =	 {93--103},
  numpages =	 11,
  url =		 {http://dl.acm.org/citation.cfm?id=776816.776828},
  acmid =	 776828,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  abstract = 	 {There has been little research on end-user program development beyond the activity of programming. Devising ways to address additional activities related to end-user program development may be critical, however, because research shows that a large proportion of the programs written by end users contain faults. Toward this end, we have been working on ways to provide formal "software engineering" methodologies to end-user programmers. This paper describes an approach we have developed for supporting assertions in end-user software, focusing on the spreadsheet paradigm. We also report the results of a controlled experiment, with 59 end-user subjects, to investigate the usefulness of this approach. Our results show that the end users were able to use the assertions to reason about their spreadsheets, and that doing so was tied to both greater correctness and greater efficiency.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=776828&ftid=148316&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:20:08>},
}

@inproceedings{Hermans:2012:DVI:2337223.2337275,
  author =	 {Hermans, Felienne and Pinzger, Martin and Deursen,
                  Arie van},
  title =	 {Detecting and Visualizing Inter-worksheet Smells in
                  Spreadsheets},
  booktitle =	 {Proceedings of the 34th International Conference on
                  Software Engineering},
  series =	 {ICSE '12},
  year =	 2012,
  isbn =	 {978-1-4673-1067-3},
  location =	 {Zurich, Switzerland},
  pages =	 {441--451},
  numpages =	 11,
  url =		 {http://dl.acm.org/citation.cfm?id=2337223.2337275},
  acmid =	 2337275,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Spreadsheets are often used in business, for simple tasks, as well as for mission critical tasks such as finance or forecasting. Similar to software, some spreadsheets are of better quality than others, for instance with respect to usability, maintainability or reliability. In contrast with software however, spreadsheets are rarely checked, tested or certified. In this paper, we aim at developing an approach for detecting smells that indicate weak points in a spreadsheet's design. To that end we first study code smells and transform these code smells to their spreadsheet counterparts. We then present an approach to detect the smells, and communicate located smells to spreadsheet users with data flow diagrams. We analyzed occurrences of these smells in the Euses corpus. Furthermore we conducted ten case studies in an industrial setting. The results of the evaluation indicate that smells can indeed reveal weaknesses in a spreadsheet's design, and that data flow diagrams are an appropriate way to show those weaknesses.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2337275&ftid=1264917&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:20:16>},
}

@article{Kokol:1991:MSS:122661.122664,
  author =	 {Kokol, Peter and Bigec, Martin and Kancler, Kurt},
  title =	 {Microcomputer Spreadsheet Software Application in
                  Body Development Determination},
  journal =	 {SIGBIO Newsl.},
  issue_date =	 {May 1991},
  volume =	 11,
  number =	 {1-2},
  month =	 apr,
  year =	 1991,
  issn =	 {0163-5697},
  pages =	 {49--59},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/122661.122664},
  doi =		 {10.1145/122661.122664},
  acmid =	 122664,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The historical analysis of great data collections is a common practice in medical research. Performing such tasks manually is not only time consuming and tedious, but also very sensitive to errors. Computers with theirs ability to store and process information can enormously ease this work. But it is very hard for non-computer specialists like doctors, nurses and other medical staff to learn and use conventional programming tools and techniques. Using spreadsheet software, which is a very user friendly and easy to learn tool, is a possible solution. In this paper we first present a mathematical model based on Rohrer's indexes which we have developed to assist us in common pupil's body-development determination. Then we briefly present the spreadsheet software, and the spreadsheet implementation of the above model.},
  review = 	 {fbie: rejected <2016-01-15 13:20:24>},
}

@inproceedings{Hermans:2013:DCD:2486788.2486827,
  author =	 {Hermans, Felienne and Sedee, Ben and Pinzger, Martin
                  and Deursen, Arie van},
  title =	 {Data Clone Detection and Visualization in
                  Spreadsheets},
  booktitle =	 {Proceedings of the 2013 International Conference on
                  Software Engineering},
  series =	 {ICSE '13},
  year =	 2013,
  isbn =	 {978-1-4673-3076-3},
  location =	 {San Francisco, CA, USA},
  pages =	 {292--301},
  numpages =	 10,
  url =		 {http://dl.acm.org/citation.cfm?id=2486788.2486827},
  acmid =	 2486827,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Spreadsheets are widely used in industry: it is estimated that end-user programmers outnumber programmers by a factor 5. However, spreadsheets are error-prone, numerous companies have lost money because of spreadsheet errors. One of the causes for spreadsheet problems is the prevalence of copy-pasting.   In this paper, we study this cloning in spreadsheets. Based on existing text-based clone detection algorithms, we have developed an algorithm to detect data clones in spreadsheets: formulas whose values are copied as plain text in a different location.   To evaluate the usefulness of the proposed approach, we conducted two evaluations. A quantitative evaluation in which we analyzed the EUSES corpus and a qualitative evaluation consisting of two case studies. The results of the evaluation clearly indicate that 1) data clones are common, 2) data clones pose threats to spreadsheet quality and 3) our approach supports users in finding and resolving data clones.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2486827&ftid=1372473&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:20:30>},
}

@inproceedings{XingliangYu:2009:EBS:1569137.1569159,
  author =	 {Xingliang Yu and Jing Li and Hua Zhong},
  title =	 {Extending the Boundary of Spreadsheet Programming:
                  Lessons Learned from Chinese Governmental Projects},
  booktitle =	 {Proceedings of the 2009 ICSE Workshop on Software
                  Engineering Foundations for End User Programming},
  series =	 {SEEUP '09},
  year =	 2009,
  isbn =	 {978-1-4244-3738-2},
  pages =	 {8--14},
  numpages =	 7,
  url =		 {http://dx.doi.org/10.1109/SEEUP.2009.5071697},
  doi =		 {10.1109/SEEUP.2009.5071697},
  acmid =	 1569159,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:20:40>},
}

@inproceedings{Pichitlamken:2008:HPS:1516744.1516869,
  author =	 {Pichitlamken, Juta and Kajkamhaeng, Supasit and
                  Uthayopas, Putchong},
  title =	 {High Performance Spreadsheet Simulation on a Desktop
                  Grid},
  booktitle =	 {Proceedings of the 40th Conference on Winter
                  Simulation},
  series =	 {WSC '08},
  year =	 2008,
  isbn =	 {978-1-4244-2708-6},
  location =	 {Miami, Florida},
  pages =	 {663--670},
  numpages =	 8,
  url =		 {http://dl.acm.org/citation.cfm?id=1516744.1516869},
  acmid =	 1516869,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {We present a proof-of-concept prototype for high performance spreadsheet simulation called S3. Our goal is to provide a user-friendly, yet computationally powerful simulation environment for end users. Our approach is to add power of parallel computing on Windows-based desktop grid into popular Excel models. We show that, by using standard Web Services and Service-Oriented Architecture (SOA), one can build a fast and efficient system on a desktop grid for simulation. The complexity of parallelism can be hidden from users through a well-defined computation template. This work also demonstrates that a massive computing power can be harvested by linking off-the-shelf office PCs into a desktop grid for simulation. The experimental results show that the prototype system is highly scalable. In the best case, the execution time can be reduced 13.6 times using 16 desktop PCs; the simulation time is dramatically reduced from 200 minutes to 14 minutes.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1516869&ftid=605034&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:20:57>},
}

@article{Isakowitz:1995:TLT:195705.195708,
  author =	 {Isakowitz, Tom\'{a}s and Schocken, Shimon and
                  Lucas,Jr., Henry C.},
  title =	 {Toward a Logical/Physical Theory of Spreadsheet
                  Modeling},
  journal =	 {ACM Trans. Inf. Syst.},
  issue_date =	 {Jan. 1995},
  volume =	 13,
  number =	 1,
  month =	 jan,
  year =	 1995,
  issn =	 {1046-8188},
  pages =	 {1--37},
  numpages =	 37,
  url =		 {http://doi.acm.org/10.1145/195705.195708},
  doi =		 {10.1145/195705.195708},
  acmid =	 195708,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {model management},
  abstract = 	 {In spite of the increasing sophistication and power of commercial spreadsheet packages, we still lack a formal theory or a methodology to support the construction and maintenance of spreadsheet models. Using a dual logical/physical perspective, we identify four principal components that characterize any spread sheet model: schema, data, editorial, and binding. We present a factoring algorithm for identifying and extracting these components from conventional spreadsheets with minimal user intervention, and a synthesis algorithm that assists users in the construction of executable spreadsheets from reusable model components. This approach opens new possibilities for applying object-oriented and model management  techniques to support the construction, sharing, and reuse of spreadsheet models in organizations. Importantly, our approach to model management and the Windows-based prototype that we have developed are designed to coexist with, rather than replace, traditional spreadsheet programs. In other words, the users are not required to learn a new modeling language; instead, their logical models and data sets are extracted from their spreadsheets transparently, as a side-effect of using standard spreadsheet programs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=195708&ftid=36921&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:21:05>},
}

@inproceedings{Reichwein:1999:SSI:331960.331968,
  author =	 {Reichwein, James and Rothermel, Gregg and Burnett,
                  Margaret},
  title =	 {Slicing Spreadsheets: An Integrated Methodology for
                  Spreadsheet Testing and Debugging},
  booktitle =	 {Proceedings of the 2Nd Conference on Domain-specific
                  Languages},
  series =	 {DSL '99},
  year =	 1999,
  isbn =	 {1-58113-255-7},
  location =	 {Austin, Texas, USA},
  pages =	 {25--38},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/331960.331968},
  doi =		 {10.1145/331960.331968},
  acmid =	 331968,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheet languages, which include commercial spreadsheets and various research systems, have proven to be flexible tools in many domain specific settings. Research shows, however, that spreadsheets often contain faults. We would like to provide at least some of the benefits of formal testing and debugging methodologies to spreadsheet developers. This paper presents an integrated testing and debugging methodology for spreadsheets. To accommodate the modeless and incremental development, testing and debugging activities that occur during spreadsheet creation, our methodology is tightly integrated into the spreadsheet environment. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing and debugging theory, and that takes advantage of the immediate visual feedback that is characteristic of the spreadsheet paradigm.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=331968&ftid=1304&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:21:12>},
}

@article{Reichwein:1999:SSI:331963.331968,
  author =	 {Reichwein, James and Rothermel, Gregg and Burnett,
                  Margaret},
  title =	 {Slicing Spreadsheets: An Integrated Methodology for
                  Spreadsheet Testing and Debugging},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {Jan. 2000},
  volume =	 35,
  number =	 1,
  month =	 dec,
  year =	 1999,
  issn =	 {0362-1340},
  pages =	 {25--38},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/331963.331968},
  doi =		 {10.1145/331963.331968},
  acmid =	 331968,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheet languages, which include commercial spreadsheets and various research systems, have proven to be flexible tools in many domain specific settings. Research shows, however, that spreadsheets often contain faults. We would like to provide at least some of the benefits of formal testing and debugging methodologies to spreadsheet developers. This paper presents an integrated testing and debugging methodology for spreadsheets. To accommodate the modeless and incremental development, testing and debugging activities that occur during spreadsheet creation, our methodology is tightly integrated into the spreadsheet environment. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing and debugging theory, and that takes advantage of the immediate visual feedback that is characteristic of the spreadsheet paradigm.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=331968&ftid=1304&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:21:15>},
}

@inproceedings{Cunha:2012:MFM:2337223.2337427,
  author =	 {Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and
                  Mendes, Jorge and Saraiva, Jo\~{a}o},
  title =	 {MDSheet: A Framework for Model-driven Spreadsheet
                  Engineering},
  booktitle =	 {Proceedings of the 34th International Conference on
                  Software Engineering},
  series =	 {ICSE '12},
  year =	 2012,
  isbn =	 {978-1-4673-1067-3},
  location =	 {Zurich, Switzerland},
  pages =	 {1395--1398},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=2337223.2337427},
  acmid =	 2337427,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {In this paper, we present MDSheet, a framework for the embedding, evolution and inference of spreadsheet models. This framework offers a model-driven software development mechanism for spreadsheet users.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2337427&ftid=1265012&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:21:24>},
}

@inproceedings{Seth:2005:STS:1098918.1098978,
  author =	 {Seth, Siddharth and Woo, Alec and Olson, Tim and
                  Liu, Jie and Zhao, Feng},
  title =	 {A Spreadsheet Toolkit for Streaming Sensor Data},
  booktitle =	 {Proceedings of the 3rd International Conference on
                  Embedded Networked Sensor Systems},
  series =	 {SenSys '05},
  year =	 2005,
  isbn =	 {1-59593-054-X},
  location =	 {San Diego, California, USA},
  pages =	 {313--313},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1098918.1098978},
  doi =		 {10.1145/1098918.1098978},
  acmid =	 1098978,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SQL server, data streams analysis and visualization,
                  excel, networked sensors},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1098978&ftid=334291&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:21:29>},
}

@article{Brown:1987:ESP:27641.28058,
  author =	 {Brown, Polly S. and Gould, John D.},
  title =	 {An Experimental Study of People Creating
                  Spreadsheets},
  journal =	 {ACM Trans. Inf. Syst.},
  issue_date =	 {July 1987},
  volume =	 5,
  number =	 3,
  month =	 jul,
  year =	 1987,
  issn =	 {1046-8188},
  pages =	 {258--272},
  numpages =	 15,
  url =		 {http://doi.acm.org/10.1145/27641.28058},
  doi =		 {10.1145/27641.28058},
  acmid =	 28058,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Nine experienced users of electronic spreadsheets each created three spreadsheets. Although participants were quite confident that their spreadsheets were accurate, 44 percent of the spreadsheets contained user-generated programming errors. With regard to the spreadsheet creation process, we found that experienced spreadsheet users spend a large percentage of their time using the cursor keys, primarily for the purpose of moving the cursor around the spreadsheet. Users did not spend a lot of time planning before launching into spreadsheet creation, nor did they spend much time in a separate, systematic debugging stage. Participants spent 21 percent of their time pausing, presumably reading and/or thinking, prior to the initial keystrokes of spreadsheet creation episodes.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=28058&ftid=39196&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:21:35>},
}

@inproceedings{Fisher:2002:ATC:581339.581359,
  author =	 {Fisher, Marc and Cao, Mingming and Rothermel, Gregg
                  and Cook, Curtis R. and Burnett, Margaret M.},
  title =	 {Automated Test Case Generation for Spreadsheets},
  booktitle =	 {Proceedings of the 24th International Conference on
                  Software Engineering},
  series =	 {ICSE '02},
  year =	 2002,
  isbn =	 {1-58113-472-X},
  location =	 {Orlando, Florida},
  pages =	 {141--153},
  numpages =	 13,
  url =		 {http://doi.acm.org/10.1145/581339.581359},
  doi =		 {10.1145/581339.581359},
  acmid =	 581359,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheet languages, which include commercial spreadsheets and various research systems, have had a substantial impact on end-user computing. Research shows, however, that spreadsheets often contain faults. Thus, in previous work, we presented a methodology that assists spreadsheet users in testing their spreadsheet formulas. Our empirical studies have shown that this methodology can help end-users test spreadsheets more adequately and efficiently; however, the process of generating test cases can still represent a significant impediment. To address this problem, we have been investigating how to automate test case generation for spreadsheets in ways that support incremental testing and provide immediate visual feedback. We have utilized two techniques for generating test cases, one involving random selection and one involving a goal-oriented approach. We describe these techniques, and report results of an experiment examining their relative costs and benefits.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=581359&ftid=79344&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:21:51>},
}

@inproceedings{Lutz:2010:CSC:1836049.1836068,
  author =	 {Lutz, Rainer and Diehl, Stephan},
  title =	 {ChartFlight: From Spreadsheets to Computer-animated
                  Data Flights},
  booktitle =	 {Proceedings of the 15th International Conference on
                  Web 3D Technology},
  series =	 {Web3D '10},
  year =	 2010,
  isbn =	 {978-1-4503-0209-8},
  location =	 {Los Angeles, California},
  pages =	 {127--136},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1836049.1836068},
  doi =		 {10.1145/1836049.1836068},
  acmid =	 1836068,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {animation, video, web},
  abstract = 	 {In business as well as science a clear and professional presentation of quantitative information is often required and helps to efficiently communicate new insights. The predominant approach is to integrate charts into slide shows created with standard presentation programs. In this paper, we introduce the chart flight metaphor for visualizing spatially distributed statistical data as a computer-generated three-dimensional camera flight over a map with animated charts. Our web application leverages the Blender 3D modeling and animation tool to allow end users to submit their data sets, and easily generate chart flight videos without profound knowledge of computer graphics methods and systems. The generated videos can be included into slide show presentations, put on web pages or shared via file hosting sites, and even displayed on low-performance hardware devices like mobile phones or netbooks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1836068&ftid=798595&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:21:52>},
}

@article{Lai:1988:OLL:58566.59298,
  author =	 {Lai, Kum-Yew and Malone, Thomas W. and Yu,
                  Keh-Chiang},
  title =	 {Object Lens: A \&Ldquo;Spreadsheet\&Rdquo; for
                  Cooperative Work},
  journal =	 {ACM Trans. Inf. Syst.},
  issue_date =	 {Oct. 1988},
  volume =	 6,
  number =	 4,
  month =	 oct,
  year =	 1988,
  issn =	 {1046-8188},
  pages =	 {332--353},
  numpages =	 22,
  url =		 {http://doi.acm.org/10.1145/58566.59298},
  doi =		 {10.1145/58566.59298},
  acmid =	 59298,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times.
The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=59298&ftid=20427&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:21:59>},
}

@inproceedings{Lai:1988:OLL:62266.62276,
  author =	 {Lai, Kum-Yew and Malone, Thomas W.},
  title =	 {Object Lens: A \&Ldquo;Spreadsheet\&Rdquo; for
                  Cooperative Work},
  booktitle =	 {Proceedings of the 1988 ACM Conference on
                  Computer-supported Cooperative Work},
  series =	 {CSCW '88},
  year =	 1988,
  isbn =	 {0-89791-282-9},
  location =	 {Portland, Oregon, USA},
  pages =	 {115--124},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/62266.62276},
  doi =		 {10.1145/62266.62276},
  acmid =	 62276,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users represent many different kinds of information. By creating semiautonomous agents, users specify rules for automatically processing this information in different situations.
The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=62276&ftid=6050&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:22:11>},
}

@inproceedings{Miyashita:2014:CME:2568225.2568231,
  author =	 {Miyashita, Hisashi and Tai, Hideki and Amano,
                  Shunichi},
  title =	 {Controlled Modeling Environment Using
                  Flexibly-formatted Spreadsheets},
  booktitle =	 {Proceedings of the 36th International Conference on
                  Software Engineering},
  series =	 {ICSE 2014},
  year =	 2014,
  isbn =	 {978-1-4503-2756-5},
  location =	 {Hyderabad, India},
  pages =	 {978--988},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2568225.2568231},
  doi =		 {10.1145/2568225.2568231},
  acmid =	 2568231,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Model Transformation, Model-driven Software and
                  Systems Engineering, Spreadsheets, SysML, UML},
  abstract = 	 {As modeling in software and system development becomes increasingly prevalent, many engineers need to collaboratively develop models spanning many disciplines such as requirements management, system design, software, etc. However, integrating modeling languages for various disciplines is challenging, because UML and SysML are too complex for many engineers to understand. Therefore, in complicated engineering processes, engineers with different areas of expertise often find it difficult to access the same information in different domain-specific modeling environments.   Our approach to address this problem is to share and edit the models as task-oriented spreadsheets, using a unified model (in UML or SysML) and a unified user interface (in the spreadsheet program). The formats of the spreadsheets are optimized for various tasks while the target models remain in a unified modeling language. Since the transformation between the spreadsheets and the models is automated and transparent, users do not have to be skilled with the modeling languages to edit the spreadsheets.   Using our novel approach, we were able to reduce the errors and time, and also the difficulty for each task without providing specialized training for the engineers. A preliminary user study showed that, by applying the spreadsheet-based approach, we could reduce the number of errors with less time for typical systems engineering tasks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2568231&ftid=1467960&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:22:18>},
}

@inproceedings{Cox:1994:UVP:192309.192343,
  author =	 {Cox, Philip T. and Smedley, Trevor J.},
  title =	 {Using Visual Programming to Extend the Power of
                  Spreadsheet},
  booktitle =	 {Proceedings of the Workshop on Advanced Visual
                  Interfaces},
  series =	 {AVI '94},
  year =	 1994,
  isbn =	 {0-89791-733-2},
  location =	 {Bari, Italy},
  pages =	 {153--161},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/192309.192343},
  doi =		 {10.1145/192309.192343},
  acmid =	 192343,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We describe a new means for representing computations in spreadsheets based on the visual, object-oriented data-flow language, Prograph, rather than textual arithmetic formulae. This mechanism is illustrated using various examples to show how common spreadsheet operation such as copying and extending formulae is more naturally represented. A formal syntax and semantics is presented. Suggestions are made for how this mechanism may be used to extend the range of applications of spreadsheets from the standard numerical calculations to areas such as symbolic computations and multimedia.},
  review = 	 {fbie: accepted <2016-01-15 13:22:26>},
}

@article{LaLomia:1991:GCT:126729.1056015,
  author =	 {LaLomia, Mary J. and Cohen, Karen C.},
  title =	 {GESTURE CONSISTENCY FOR TEXT, SPREADSHEET, GRAPHIC
                  AND FORM FILL EDITING},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {Oct. 1991},
  volume =	 23,
  number =	 4,
  month =	 oct,
  year =	 1991,
  issn =	 {0736-6906},
  pages =	 {40--41},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/126729.1056015},
  doi =		 {10.1145/126729.1056015},
  acmid =	 1056015,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Computer systems that simulate a paper and pen environment have been the focus of considerable development activity. One concern generated from this activity is whether a default set of hand-drawn gestures should be provided to the users. This paper examined whether individuals produced similar gestures for 32 editing functions across four application domains; text, spreadsheet, graphic, and form fill. The individuals (half computer novices and half computer-experienced) indicated gestures for each of the editing functions using each application domain. The results indicated that the consistency of hand-drawn gestures was not affected by the participant's computer experience, by the size and shape of the information to be modified or the application domain.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1056015&ftid=310084&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:22:34>},
}

@article{Napier:1992:KCU:134347.134353,
  author =	 {Napier, H. Albert and Batsell, Richard R. and Lane,
                  David M. and Guadagno, Norman S.},
  title =	 {Knowledge of Command Usage in a Spreadsheet Program},
  journal =	 {SIGMIS Database},
  issue_date =	 {Winter 1992},
  volume =	 23,
  number =	 1,
  month =	 mar,
  year =	 1992,
  issn =	 {0095-0033},
  pages =	 {13--21},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/134347.134353},
  doi =		 {10.1145/134347.134353},
  acmid =	 134353,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Knowledge of how software is actually used by people can assist software developers and internal MIS application development personnel to improve the user-interface of existing software, in creating new user interface styles for existing software packages, and to improve the training for personnel using software packages. This article reports results from a study that examined the use of a popular spreadsheet software by 40 experienced users in their work environment. Of the 505 commands that could be used, 18 (3.6\%) accounted for over 80\% of the usage. More than 50\% of the available commands were never used. Most of the command usage was related to creating, maintaining, and printing spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=134353&ftid=274500&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:22:46>},
}

@article{LeBlanc:2007:DLS:1278201.1278207,
  author =	 {LeBlanc, Larry J. and Galbreth, Michael R.},
  title =	 {Designing Large-scale Supply Chain Linear Programs
                  in Spreadsheets},
  journal =	 {Commun. ACM},
  issue_date =	 {August 2007},
  volume =	 50,
  number =	 8,
  month =	 aug,
  year =	 2007,
  issn =	 {0001-0782},
  pages =	 {59--64},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1278201.1278207},
  doi =		 {10.1145/1278201.1278207},
  acmid =	 1278207,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Developing techniques to create a complete supply chain model across an entire product line.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1278207&ftid=432072&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:08>},
}

@inproceedings{Singh:2007:SPA:1314436.1314443,
  author =	 {Singh, Anu and Ramakrishnan, C. R. and Ramakrishnan,
                  I. V. and Stoller, Scott D. and Warren, David S.},
  title =	 {Security Policy Analysis Using Deductive
                  Spreadsheets},
  booktitle =	 {Proceedings of the 2007 ACM Workshop on Formal
                  Methods in Security Engineering},
  series =	 {FMSE '07},
  year =	 2007,
  isbn =	 {978-1-59593-887-9},
  location =	 {Fairfax, Virginia, USA},
  pages =	 {42--50},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/1314436.1314443},
  doi =		 {10.1145/1314436.1314443},
  acmid =	 1314443,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SELinux policy, security policy analysis,
                  vulnerability analysis},
  abstract = 	 {As security policies get larger and more complex, analysis tools that help users understand and validate security policies are becoming more important.This paper explores the use of deductive spreadsheets for security policy analysis.Deductive spreadsheets combine the power ofdeductive rules (for specifying policies and analyses) with the usability of spreadsheets.This approach is introduced with a simple example of analyzing information flow allowed by RBAC policies and then applied in two case studies: analysis of computer system configurations and analysisof Security-Enhanced Linux access control policies.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1314443&ftid=487091&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:14>},
}

@inproceedings{Vemuri:1992:DDD:503720.503808,
  author =	 {Vemuri, Sarat and Sengupta, Shankar and Davis,
                  J. Steve},
  title =	 {Data Dependency Diagrams for Spreadsheet
                  Applications},
  booktitle =	 {Proceedings of the 30th Annual Southeast Regional
                  Conference},
  series =	 {ACM-SE 30},
  year =	 1992,
  isbn =	 {0-89791-506-2},
  location =	 {Raleigh, North Carolina},
  pages =	 {467--470},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/503720.503808},
  doi =		 {10.1145/503720.503808},
  acmid =	 503808,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We conducted experiments to evaluate on-line data dependency diagrams for spreadsheets. Results were consistent those of earlier experiments with written data dependency diagrams. Although users had no trouble browsing the on-line diagrams, the diagrams did not seem to improve the performance of a maintenance task on a small spreadsheet. The diagrams may be helpful for larger spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=503808&ftid=69381&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:23:18>},
}

@article{Kokol:1989:USS:66068.66069,
  author =	 {Kokol, P.},
  title =	 {Using Spreadsheet Software to Support Metric's Life
                  Cycle Activities},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {May 1989},
  volume =	 24,
  number =	 5,
  month =	 may,
  year =	 1989,
  issn =	 {0362-1340},
  pages =	 {27--37},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/66068.66069},
  doi =		 {10.1145/66068.66069},
  acmid =	 66069,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The application of the spreadsheet software in the field of software measurement technology is disccussed. A model of metric's life cycle is defined and used together with the spreadsheet software to develop a new class of complexity metrics, called Hybrid metrics. Theirs evaluation has shown that they are supperior to most other complexity metrics in estimating development times and allocating testing resources. Finally, the spreadsheet and conventional programming are compared, and it is not unreasonable to state that spreadsheet better supports activities performd during metric's life cycle then conventional programming.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=66069&ftid=226456&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:24>},
}

@article{ReitmanOlson:1989:ACI:67880.1046597,
  author =	 {Reitman Olson, Judith and Nilsen, Erik},
  title =	 {Analysis of the Cognition Involved in Spreadsheet
                  Software Interaction (Abstract Only)},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {July 1989},
  volume =	 21,
  number =	 1,
  month =	 aug,
  year =	 1989,
  issn =	 {0736-6906},
  pages =	 {123--},
  url =		 {http://doi.acm.org/10.1145/67880.1046597},
  doi =		 {10.1145/67880.1046597},
  acmid =	 1046597,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper analyzes details of the cognition involved when people use spreadsheet software, a task that is both a major microcomputer application and a cognitively intense task. This task is analyzed in terms of the GOMS model (Card, Moran, and Newell, 1983), both to test the generality of the model and to extend its set of parameters. We found that people using two seemingly similar spreadsheet applications, Lotus 1-2-3 and Multiplan, require very different amounts of time to accomplish the same tasks. Experienced users of Lotus 1-2-3 took far longer to complete the same four tasks than experienced Multiplan users did. Some of that additional time was found to be caused by the fact that Lotus 1-2-3 offers a choice to users of two general methods to use to enter formulas. Lotus requires that the user decide which to use. This decision takes time. And, when the users type in the values of the formula instead of using the cursor to point to the cell in which the values reside, they pause a long time before each such typing entry. Presumably they are scanning the screen and calculating the coordinates to type in during the pause. Again, these cognitive processes take time. In an analysis of a second task, that of adjusting the column width, there was substantial evidence that the performance changes when a method is repeated in close succession. This repetition affects the parameters that reflect the time it takes to retrieve command parts from memory. When the parameters for scanning decision and repetition were added to the keystroke analysis of our task, we found remarkable correspondence with the basic parameters from Card, Moran, and Newell's original work: the keystroke times and mental preparation times from their original experiments were very close to the estimates of those same parameters in our tasks. However, in our analysis of the spreadsheet task, we expanded the parameter set in the keystroke model to account for performance in tasks that require substantial planning, scanning, and repetition.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1046597&ftid=302472&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:29>},
}

@inproceedings{Jankun-Kelly:2002:VRR:1242073.1242337,
  author =	 {Jankun-Kelly, T. J. and Ma, Kwan-Liu},
  title =	 {VisSheet Redux: Redesigning a Visualization
                  Exploration Spreadsheet for the Web},
  booktitle =	 {ACM SIGGRAPH 2002 Conference Abstracts and
                  Applications},
  series =	 {SIGGRAPH '02},
  year =	 2002,
  isbn =	 {1-58113-525-4},
  location =	 {San Antonio, Texas},
  pages =	 {329--329},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1242073.1242337},
  doi =		 {10.1145/1242073.1242337},
  acmid =	 1242337,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The exploration of complex data sets requires interfaces to present and navigate through the visualization of the data. In recent work [Jankun-Kelly and Ma 2001], we produced a visualization exploration spreadsheet to address this issue. The developed application, however, was implemented for off-line use only. For data sets on remote sites, this approach is not appropriate. Thus, a web-based version of the visualization exploration spreadsheet is needed. This abstract discusses the process of transforming the interface from an off-line to an on-line design.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1242337&ftid=412143&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:37>},
}

@inproceedings{Witkowski:2003:SRO:872757.872767,
  author =	 {Witkowski, Andrew and Bellamkonda, Srikanth and
                  Bozkaya, Tolga and Dorman, Gregory and Folkert,
                  Nathan and Gupta, Abhinav and Shen, Lei and
                  Subramanian, Sankar},
  title =	 {Spreadsheets in RDBMS for OLAP},
  booktitle =	 {Proceedings of the 2003 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '03},
  year =	 2003,
  isbn =	 {1-58113-634-X},
  location =	 {San Diego, California},
  pages =	 {52--63},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/872757.872767},
  doi =		 {10.1145/872757.872767},
  acmid =	 872767,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {One of the critical deficiencies of SQL is lack of support for n-dimensional array-based computations which are frequent in OLAP environments. Relational OLAP (ROLAP) applications have to emulate them using joins, recently introduced SQL Window Functions [18] and complex and inefficient CASE expressions. The designated place in SQL for specifying calculations is the SELECT clause, which is extremely limiting and forces the user to generate queries using nested views, subqueries and complex joins. Furthermore, SQL-query optimizer is pre-occupied with determining efficient join orders and choosing optimal access methods and largely disregards optimization of complex numerical formulas. Execution methods concentrated on efficient computation of a cube [11], [16] rather than on random access structures for inter-row calculations. This has created a gap that has been filled by spreadsheets and specialized MOLAP engines, which are good at formulas for mathematical modeling but lack the formalism of the relational model, are difficult to manage, and exhibit scalability problems. This paper presents SQL extensions involving array based calculations for complex modeling. In addition, we present optimizations, access structures and execution models for processing them efficiently.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=872767&ftid=210394&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:23:55>},
}

@inproceedings{Cunha:2012:BMS:2337223.2337443,
  author =	 {Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and
                  Mendes, Jorge and Saraiva, Jo\~{a}o},
  title =	 {A Bidirectional Model-driven Spreadsheet
                  Environment},
  booktitle =	 {Proceedings of the 34th International Conference on
                  Software Engineering},
  series =	 {ICSE '12},
  year =	 2012,
  isbn =	 {978-1-4673-1067-3},
  location =	 {Zurich, Switzerland},
  pages =	 {1443--1444},
  numpages =	 2,
  url =		 {http://dl.acm.org/citation.cfm?id=2337223.2337443},
  acmid =	 2337443,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {In this extended abstract we present a bidirectional model-driven framework to develop spreadsheets. By being model driven, our approach allows to evolve a spreadsheet model and automatically have the data co-evolved. The bidirectional component achieves precisely the inverse, that is, to evolve the data and automatically obtain a new model to which the data conforms.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2337443&ftid=1265026&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:11>},
}

@inproceedings{Chen:2013:AWS:2509908.2509909,
  author =	 {Chen, Zhe and Cafarella, Michael},
  title =	 {Automatic Web Spreadsheet Data Extraction},
  booktitle =	 {Proceedings of the 3rd International Workshop on
                  Semantic Search Over the Web},
  series =	 {SS@ '13},
  year =	 2013,
  isbn =	 {978-1-4503-2483-0},
  location =	 {Riva del Garda, Italy},
  pages =	 {1:1--1:8},
  articleno =	 1,
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2509908.2509909},
  doi =		 {10.1145/2509908.2509909},
  acmid =	 2509909,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheets contain a huge amount of high-value data but do not observe a standard data model and thus are difficult to integrate. A large number of data integration tools exist, but they generally can only work on relational data. Existing systems for extracting relational data from spreadsheets are too labor intensive to support ad-hoc integration tasks, in which the correct extraction target is only learned during the course of user interaction. This paper introduces a system that automatically extracts relational data from spreadsheets, thereby enabling relational spreadsheet integration. The resulting integrated relational data can be queried directly or can be translated into RDF triples. When compared to standard techniques for spreadsheet data extraction on a set of 100 random Web spreadsheets, the system reduces the amount of human labor by 72\% to 92\%. In addition to the system design, we present the results of a general survey of more than 400,000 spreadsheets we downloaded from the Web, giving a novel view of how users organize their data in spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2509909&ftid=1432191&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:24:17>},
}

@inproceedings{Mendes:2012:CEM:2337223.2337500,
  author =	 {Mendes, Jorge},
  title =	 {Coupled Evolution of Model-driven Spreadsheets},
  booktitle =	 {Proceedings of the 34th International Conference on
                  Software Engineering},
  series =	 {ICSE '12},
  year =	 2012,
  isbn =	 {978-1-4673-1067-3},
  location =	 {Zurich, Switzerland},
  pages =	 {1616--1618},
  numpages =	 3,
  url =		 {http://dl.acm.org/citation.cfm?id=2337223.2337500},
  acmid =	 2337500,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Spreadsheets are increasingly used as programming languages, in the construction of large and complex systems. The fact is that spreadsheets, being a highly flexible framework, lack important programming language features such as abstraction or encapsulation. This flexibility, however, comes with a price: spreadsheets are populated with significant amounts of errors. One of the approaches that try to overcome this problem advocates the use of model-driven spreadsheet development: a spreadsheet model is defined, from which a concrete spreadsheet is generated. Although this approach has been proved effective in other contexts, still it needs to accommodate for future evolution of both the model and its instance, so that they remain synchronized at all moments. In this paper, we propose a pair of transformation sets, one working at the model level and the other at the instance level, such that each transformation in one set is related to a transformation in the other set. With our approach, we ensure model/data compliance while allowing for model and data evolution.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2337500&ftid=1265077&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:22>},
}

@inproceedings{Cunha:2012:TEB:2667089.2667096,
  author =	 {Cunha, J\'{a}come and Fernandes, Jo\~{a}o Paulo and
                  Mendes, Jorge and Saraiva, Jo\~{a}o},
  title =	 {Towards an Evaluation of Bidirectional Model-driven
                  Spreadsheets},
  booktitle =	 {Proceedings of the First International Workshop on
                  User Evaluation for Software Engineering
                  Researchers},
  series =	 {USER '12},
  year =	 2012,
  isbn =	 {978-1-4673-1859-4},
  location =	 {Zurich, Switzerland},
  pages =	 {25--28},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=2667089.2667096},
  acmid =	 2667096,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  keywords =	 {bidirectional transformations, embedded DSLS, model
                  inference, model-driven engineering, software
                  evolution, spreadsheets},
  abstract = 	 {Spreadsheets are widely recognized as popular programming systems with a huge number of spreadsheets being created every day. Also, spreadsheets are often used in the decision processes of profit-oriented companies. While this illustrates their practical importance, studies have shown that up to 90\% of real-world spreadsheets contain errors. In order to improve the productivity of spreadsheet end-users, the software engineering community has proposed to employ model-driven approaches to spreadsheet development. In this paper we describe the evaluation of a bidirectional model-driven spreadsheet environment. In this environment, models and data instances are kept in conformity, even after an update on any of these artifacts. We describe the issues of an empirical study we plan to conduct, based on our previous experience with end-user studies. Our goal is to assess if this model-driven spreadsheet development framework does in fact contribute to improve the productivity of spreadsheet users.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2667096&ftid=1498015&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:26>},
}

@inproceedings{Brunette:2013:OTB:2442882.2442898,
  author =	 {Brunette, Waylon and Sudar, Samuel and Worden,
                  Nicholas and Price, Dylan and Anderson, Richard and
                  Borriello, Gaetano},
  title =	 {ODK Tables: Building Easily Customizable Information
                  Applications on Android Devices},
  booktitle =	 {Proceedings of the 3rd ACM Symposium on Computing
                  for Development},
  series =	 {ACM DEV '13},
  year =	 2013,
  isbn =	 {978-1-4503-1856-3},
  location =	 {Bangalore, India},
  pages =	 {12:1--12:10},
  articleno =	 12,
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2442882.2442898},
  doi =		 {10.1145/2442882.2442898},
  acmid =	 2442898,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SMS, data tables, mobile database, mobile phones,
                  open data kit, remote synchronization, spreadsheets},
  abstract = 	 {ODK Tables is an Android app that allows users to enter and curate tabular data. Users can explore the data through a variety of built-in views or build custom views using HTML/JavaScript. It also supports the linking of multiple data tables. Data values can be updated in a variety of ways, including using mobile data collection tools such as ODK Collect, that support rich data types including multi-media, or by communicating with low-cost phones over SMS. Additionally, ODK Tables supports a simple synchronization scheme appropriate for a distributed workforce and backed up on cloud servers. The goal of ODK Tables is to lower barriers to developing customized information applications by making it easy to customize data views using standard web technologie&sacute; that do not require recompilation. Our experience in working with many organizations in the developing world led us to make feature choices based on their input (through an on-line survey) with particular consideration to the potential pool of developers available. In this paper, we report on our implementation of ODK Tables and some of its performance parameters. We have designed it to be a flexible solution for a variety of use cases, including logistics management, public health, and environment monitoring where previously collected data is often revisited and updated.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2442898&ftid=1348354&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:24:30>},
}

@article{Gulwani:2011:ASP:1925844.1926423,
  author =	 {Gulwani, Sumit},
  title =	 {Automating String Processing in Spreadsheets Using
                  Input-output Examples},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {January 2011},
  volume =	 46,
  number =	 1,
  month =	 jan,
  year =	 2011,
  issn =	 {0362-1340},
  pages =	 {317--330},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/1925844.1926423},
  doi =		 {10.1145/1925844.1926423},
  acmid =	 1926423,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {program synthesis, programming by example (pbe),
                  spreadsheet programming, string manipulation, user
                  intent, version space algebra},
  abstract = 	 {We describe the design of a string programming/expression language that supports restricted forms of regular expressions, conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations. The algorithm has been implemented as an interactive add-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test - it has synthesized part of itself, and has been used to solve problems beyond author's imagination.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1926423&ftid=907639&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:39>},
}

@inproceedings{Gulwani:2011:ASP:1926385.1926423,
  author =	 {Gulwani, Sumit},
  title =	 {Automating String Processing in Spreadsheets Using
                  Input-output Examples},
  booktitle =	 {Proceedings of the 38th Annual ACM SIGPLAN-SIGACT
                  Symposium on Principles of Programming Languages},
  series =	 {POPL '11},
  year =	 2011,
  isbn =	 {978-1-4503-0490-0},
  location =	 {Austin, Texas, USA},
  pages =	 {317--330},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/1926385.1926423},
  doi =		 {10.1145/1926385.1926423},
  acmid =	 1926423,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {program synthesis, programming by example (pbe),
                  spreadsheet programming, string manipulation, user
                  intent, version space algebra},
  abstract = 	 {We describe the design of a string programming/expression language that supports restricted forms of regular expressions, conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations. The algorithm has been implemented as an interactive add-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test - it has synthesized part of itself, and has been used to solve problems beyond author's imagination.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1926423&ftid=907639&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:43>},
}

@inproceedings{Singh:2016:TSD:2837614.2837668,
  author =	 {Singh, Rishabh and Gulwani, Sumit},
  title =	 {Transforming Spreadsheet Data Types Using Examples},
  booktitle =	 {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT
                  Symposium on Principles of Programming Languages},
  series =	 {POPL 2016},
  year =	 2016,
  isbn =	 {978-1-4503-3549-2},
  location =	 {St. Petersburg, FL, USA},
  pages =	 {343--356},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/2837614.2837668},
  doi =		 {10.1145/2837614.2837668},
  acmid =	 2837668,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Noisy Examples, Probabilistic Synthesis, Program
                  Synthesis, Programming By Examples, Spreadsheet
                  Programming},
  abstract = 	 {Cleaning spreadsheet data types is a common problem faced by millions of spreadsheet users. Data types such as date, time, name, and units are ubiquitous in spreadsheets, and cleaning transformations on these data types involve parsing and pretty printing their string representations. This presents many challenges to users because cleaning such data requires some background knowledge about the data itself and moreover this data is typically non-uniform, unstructured, and ambiguous. Spreadsheet systems and Programming Languages provide some UI-based and programmatic solutions for this problem but they are either insufficient for the user&#039;s needs or are beyond their expertise. In this paper, we present a programming by example methodology of cleaning data types that learns the desired transformation from a few input-output examples. We propose a domain specific language with probabilistic semantics that is parameterized with declarative data type definitions. The probabilistic semantics is based on three key aspects: (i) approximate predicate matching, (ii) joint learning of data type interpretation, and (iii) weighted branches. This probabilistic semantics enables the language to handle non-uniform, unstructured, and ambiguous data. We then present a synthesis algorithm that learns the desired program in this language from a set of input-output examples. We have implemented our algorithm as an Excel add-in and present its successful evaluation on 55 benchmark problems obtained from online help forums and Excel product team.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2837668&ftid=1659057&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:24:48>},
}

@inproceedings{Bakke:2011:SUI:1978942.1979313,
  author =	 {Bakke, Eirik and Karger, David and Miller, Rob},
  title =	 {A Spreadsheet-based User Interface for Managing
                  Plural Relationships in Structured Data},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '11},
  year =	 2011,
  isbn =	 {978-1-4503-0228-9},
  location =	 {Vancouver, BC, Canada},
  pages =	 {2541--2550},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1978942.1979313},
  doi =		 {10.1145/1978942.1979313},
  acmid =	 1979313,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {databases, foreign key relationships, hierarchical
                  views, one-to-many relationships, spreadsheets},
  abstract = 	 {A key feature of relational database applications is managing \emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40\% faster on average.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1979313&ftid=964796&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:25:06>},
}

@article{Vass:2006:JMB:1137243.1137474,
  author =	 {Vass, Marc T. and Shaffer, Clifford A. and
                  Ramakrishnan, Naren and Watson, Layne T. and Tyson,
                  John J.},
  title =	 {The JigCell Model Builder: A Spreadsheet Interface
                  for Creating Biochemical Reaction Network Models},
  journal =	 {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
  issue_date =	 {April 2006},
  volume =	 3,
  number =	 2,
  month =	 apr,
  year =	 2006,
  issn =	 {1545-5963},
  pages =	 {155--164},
  numpages =	 10,
  url =		 {http://dx.doi.org/10.1109/TCBB.2006.27},
  doi =		 {10.1109/TCBB.2006.27},
  acmid =	 1137474,
  publisher =	 {IEEE Computer Society Press},
  address =	 {Los Alamitos, CA, USA},
  keywords =	 {Biochemical reaction networks, bioinformatics,
                  modeling, user interface paradigms.},
  review = 	 {fbie: rejected <2016-01-15 13:25:09>},
}

@article{Burnett:1998:GDE:274444.274445,
  author =	 {Burnett, Margaret M. and Gottfried, Herkimer J.},
  title =	 {Graphical Definitions: Expanding Spreadsheet
                  Languages Through Direct Manipulation and Gestures},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {March 1998},
  volume =	 5,
  number =	 1,
  month =	 mar,
  year =	 1998,
  issn =	 {1073-0516},
  pages =	 {1--33},
  numpages =	 33,
  url =		 {http://doi.acm.org/10.1145/274444.274445},
  doi =		 {10.1145/274444.274445},
  acmid =	 274445,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {direct manipulation, forms/3, gestures, programming
                  by demonstration},
  abstract = 	 {In the past, attempts to extend the spreadsheet paradigm to support graphical objects, such as colored circles or user-defined graphical types, have led to approaches featuring either a direct way of creating objects graphically or strong compatibility with the spreadsheet paradigm, but not both. This inability to conveniently go beyond numbers and strings without straying outside the spreadsheet paradigm has been a limiting factor in the applicability of spreadsheet languages. In this article we present graphical definitions, an approach that removes this limitation, allowing both simple and complex graphical objects to be programmed directly using direct manipulation and gestures, in a manner that fits seamlessly within the spreadsheet paradigm. We  also describe an empirical study, in which subjects programmed such objects faster and with fewer errors using this approach than when using a traditional approach to formula specification. Because the approach is expressive enough to be used with both built-in and user-defined types, it allows the directness of demonstrational and spreadsheet techniques to be used in programming a wider range of applications than has been possible before.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=274445&ftid=40935&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:25:15>},
}

@inproceedings{Saint-Paul:2008:DSY:1353343.1353427,
  author =	 {Saint-Paul, R{\'e}gis and Benatallah, Boualem and
                  Vayssi\`{e}re, Julien},
  title =	 {Data Services in Your Spreadsheet!},
  booktitle =	 {Proceedings of the 11th International Conference on
                  Extending Database Technology: Advances in Database
                  Technology},
  series =	 {EDBT '08},
  year =	 2008,
  isbn =	 {978-1-59593-926-5},
  location =	 {Nantes, France},
  pages =	 {690--694},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1353343.1353427},
  doi =		 {10.1145/1353343.1353427},
  acmid =	 1353427,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {End-user programmers---the 45 million of them, as estimated for 2001 in US alone [7]---routinely use spreadsheet to visualize, manipulate, and analyze data. Thanks to this environment, they can build applications that solve their daily problems. Even building a report can be seen as programming an application that takes corporate data as input and outputs a presentation. To build this application, spreadsheet users have to import data and place them in spreadsheet cells, highlight the important pieces, compute maybe some aggregates, add a chart or two. If well done, this application will be used each time data are updated to effortlessly produce a fresh report.},
  review = 	 {fbie: accepted <2016-01-15 13:25:35>},
}

@inproceedings{Quinn:2014:AEH:2531602.2531728,
  author =	 {Quinn, Alexander J. and Bederson, Benjamin B.},
  title =	 {AskSheet: Efficient Human Computation for Decision
                  Making with Spreadsheets},
  booktitle =	 {Proceedings of the 17th ACM Conference on Computer
                  Supported Cooperative Work \&\#38; Social Computing},
  series =	 {CSCW '14},
  year =	 2014,
  isbn =	 {978-1-4503-2540-0},
  location =	 {Baltimore, Maryland, USA},
  pages =	 {1456--1466},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2531602.2531728},
  doi =		 {10.1145/2531602.2531728},
  acmid =	 2531728,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {crowdsourcing, human computation, value of
                  information},
  abstract = 	 {The wealth of resources online has empowered individuals and businesses with an unprecedented volume of information to aid in decision making processes. However, finding the many details needed for a non-trivial decision can be very labor-intensive. We present AskSheet, a general system that leverages human computation to acquire the inputs to an arbitrary decision spreadsheet provided by the user. The key innovation is the ability to prioritize the inputs by analyzing the user's spreadsheet formulas to calculate value of information for each of the blanks. By directing workers to find the details that impact the end result most, it results in a conclusive decision without gathering all of the inputs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2531728&ftid=1429422&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:25:49>},
}

@inproceedings{Smedley:1996:EUS:948449.948473,
  author =	 {Smedley, Trevor J. and Cox, Philip T. and Byrne,
                  Shannon L.},
  title =	 {Expanding the Utility of Spreadsheets Through the
                  Integration of Visual Programming and User Interface
                  Objects},
  booktitle =	 {Proceedings of the Workshop on Advanced Visual
                  Interfaces},
  series =	 {AVI '96},
  year =	 1996,
  isbn =	 {0-89791-834-7},
  location =	 {Gubbio, Italy},
  pages =	 {148--155},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/948449.948473},
  doi =		 {10.1145/948449.948473},
  acmid =	 948473,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {One of the primary uses of spreadsheets is in forecasting future events. This involves investigating "what-if" scenarios --- creating a spreadsheet, experimenting with different values for inputs, and observing how they effect the computed values. Unfortunately, current spreadsheets provide little support for this type of interaction. Data values must be typed in, and computed values can be observed only as numbers, or on simple charts. In this work we extend a spreadsheet which makes use of a visual language for expressing formulae to also incorporate the use of user interface objects. This allows the user to create any type of input and output interfaces they wish, increasing the utility of spreadsheets for investigating "what-if" scenarios.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=948473&ftid=240044&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:25:54>},
}

@article{Burnett:2002:SMD:586081.586083,
  author =	 {Burnett, Margaret and Yang, Sherry and Summet, Jay},
  title =	 {A Scalable Method for Deductive Generalization in
                  the Spreadsheet Paradigm},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {December 2002},
  volume =	 9,
  number =	 4,
  month =	 dec,
  year =	 2002,
  issn =	 {1073-0516},
  pages =	 {253--284},
  numpages =	 32,
  url =		 {http://doi.acm.org/10.1145/586081.586083},
  doi =		 {10.1145/586081.586083},
  acmid =	 586083,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Forms/3, Human-computer interaction, concrete
                  programming, generalization, graphical programming,
                  spreadsheet languages},
  abstract = 	 {In this paper, we present an efficient method for automatically generalizing programs written in spreadsheet languages. The strategy is to do generalization through incremental analysis of logical relationships among concrete program entities from the perspective of a particular computational goal. The method uses deductive dataflow analysis with algebraic back-substitution rather than inference with heuristics, and there is no need for generalization-related dialog with the user. We present the algorithms and their time complexities and show that, because the algorithms perform their analyses incrementally, on only the on-screen program elements rather than on the entire program, the method is scalable. Performance data is presented to help demonstrate the scalability.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=586083&ftid=86667&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:26:01>},
}

@inproceedings{Brunette:2013:ODK:2444776.2444790,
  author =	 {Brunette, Waylon and Sundt, Mitchell and Dell,
                  Nicola and Chaudhri, Rohit and Breit, Nathan and
                  Borriello, Gaetano},
  title =	 {Open Data Kit 2.0: Expanding and Refining
                  Information Services for Developing Regions},
  booktitle =	 {Proceedings of the 14th Workshop on Mobile Computing
                  Systems and Applications},
  series =	 {HotMobile '13},
  year =	 2013,
  isbn =	 {978-1-4503-1421-3},
  location =	 {Jekyll Island, Georgia},
  pages =	 {10:1--10:6},
  articleno =	 10,
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2444776.2444790},
  doi =		 {10.1145/2444776.2444790},
  acmid =	 2444790,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ICTD, data tables, mobile computing, mobile
                  databases, open data kit, paper forms, sensing,
                  smartphones, spreadsheets, vision},
  abstract = 	 {Open Data Kit (ODK) is an open-source, modular toolkit that enables organizations to build application-specific information services for use in resource-constrained environments. ODK is one of the leading data collection solutions available and has been deployed by a wide variety of organizations in dozens of countries around the world. This paper discusses how recent feedback from users and developers led us to redesign the ODK system architecture. Specifically, the design principles for ODK 2.0 focus on: 1) favoring runtime languages over compile time languages to make customizations easier for individuals with limited programming experience; 2) implementing basic data structures as single rows within a table of data; 3) storing that data in a database that is accessible across applications and client devices; and 4) increasing the diversity of input types by enabling new data input methods from sensors. We discuss how these principles have led to the refinement of the existing ODK tools, and the creation of several new tools that aim to improve the toolkit, expand its range of applications, and make it more customizable by users.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2444790&ftid=1349665&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:26:05>},
}

@article{Spenke:1989:SIL:67450.67466,
  author =	 {Spenke, M. and Beilken, C.},
  title =	 {A Spreadsheet Interface for Logic Programming},
  journal =	 {SIGCHI Bull.},
  volume =	 20,
  number =	 {SI},
  month =	 mar,
  year =	 1989,
  issn =	 {0736-6906},
  pages =	 {75--80},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/67450.67466},
  doi =		 {10.1145/67450.67466},
  acmid =	 67466,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We present PERPLEX, a programming environment intended for the end-user. In its design, the concepts of logic programming and spreadsheets are combined. Thus, on the one hand, logic programming becomes an interactive, incremental task where the user gets direct visual feedback, on the other hand, functionality and scope of a conventional spreadsheet program are considerably extended. In order to perform calculations and queries, constraints are imposed on the contents of the spreadsheet cells. New predicates can be defined using a programming-by-example technique: Rules are extracted from the user's solutions for example problems. Thus, concrete intermediate results take over the role of abstract logic variables in the programming process. PERPLEX has been successfully implemented on a Symbolics Lisp Machine.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=67466&ftid=5734&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:26:13>},
}

@inproceedings{Spenke:1989:SIL:67449.67466,
  author =	 {Spenke, M. and Beilken, C.},
  title =	 {A Spreadsheet Interface for Logic Programming},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '89},
  year =	 1989,
  isbn =	 {0-89791-301-9},
  pages =	 {75--80},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/67449.67466},
  doi =		 {10.1145/67449.67466},
  acmid =	 67466,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We present PERPLEX, a programming environment intended for the end-user. In its design, the concepts of logic programming and spreadsheets are combined. Thus, on the one hand, logic programming becomes an interactive, incremental task where the user gets direct visual feedback, on the other hand, functionality and scope of a conventional spreadsheet program are considerably extended. In order to perform calculations and queries, constraints are imposed on the contents of the spreadsheet cells. New predicates can be defined using a programming-by-example technique: Rules are extracted from the user's solutions for example problems. Thus, concrete intermediate results take over the role of abstract logic variables in the programming process. PERPLEX has been successfully implemented on a Symbolics Lisp Machine.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=67466&ftid=5734&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:26:17>},
}

@inproceedings{Myers:1991:GTS:108844.108903,
  author =	 {Myers, Brad A.},
  title =	 {Graphical Techniques in a Spreadsheet for Specifying
                  User Interfaces},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '91},
  year =	 1991,
  isbn =	 {0-89791-383-3},
  location =	 {New Orleans, Louisiana, USA},
  pages =	 {243--249},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/108844.108903},
  doi =		 {10.1145/108844.108903},
  acmid =	 108903,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=108903&ftid=49620&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:26:25>},
}

@inproceedings{Horey:2010:TSP:2163970.2163971,
  author =	 {Horey, James and Nelson, Eric and Maccabe, Arthur
                  B.},
  title =	 {Tables: A Spreadsheet-inspired Programming Model for
                  Sensor Networks},
  booktitle =	 {Proceedings of the 6th IEEE International Conference
                  on Distributed Computing in Sensor Systems},
  series =	 {DCOSS'10},
  year =	 2010,
  isbn =	 {3-642-13650-8, 978-3-642-13650-4},
  location =	 {Santa Barbara, CA},
  pages =	 {1--14},
  numpages =	 14,
  url =		 {http://dx.doi.org/10.1007/978-3-642-13651-1_1},
  doi =		 {10.1007/978-3-642-13651-1_1},
  acmid =	 2163971,
  publisher =	 {Springer-Verlag},
  address =	 {Berlin, Heidelberg},
  review = 	 {fbie: rejected <2016-01-15 13:26:28>},
}

@inproceedings{Barik:2015:FUR:2820518.2820594,
  author =	 {Barik, Titus and Lubick, Kevin and Smith, Justin and
                  Slankas, John and Murphy-Hill, Emerson},
  title =	 {Fuse: A Reproducible, Extendable, Internet-scale
                  Corpus of Spreadsheets},
  booktitle =	 {Proceedings of the 12th Working Conference on Mining
                  Software Repositories},
  series =	 {MSR '15},
  year =	 2015,
  location =	 {Florence, Italy},
  pages =	 {486--489},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=2820518.2820594},
  acmid =	 2820594,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Spreadsheets are perhaps the most ubiquitous form of end-user programming software. This paper describes a corpus, called Fuse, containing 2,127,284 URLs that return spreadsheets (and their HTTP server responses), and 249,376 unique spreadsheets, contained within a public web archive of over 26.83 billion pages. Obtained using nearly 60,000 hours of computation, the resulting corpus exhibits several useful properties over prior spreadsheet corpora, including reproducibility and extendability. Our corpus is unencumbered by any license agreements, available to all, and intended for wide usage by end-user software engineering researchers. In this paper, we detail the data and the spreadsheet extraction process, describe the data schema, and discuss the trade-offs of Fuse with other corpora.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2820594&ftid=1617946&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:26:52>},
}

@inproceedings{Nardi:1990:ESD:99332.99355,
  author =	 {Nardi, Bonnie A. and Miller, James R.},
  title =	 {An Ethnographic Study of Distributed Problem Solving
                  in Spreadsheet Development},
  booktitle =	 {Proceedings of the 1990 ACM Conference on
                  Computer-supported Cooperative Work},
  series =	 {CSCW '90},
  year =	 1990,
  isbn =	 {0-89791-402-3},
  location =	 {Los Angeles, California, USA},
  pages =	 {197--208},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/99332.99355},
  doi =		 {10.1145/99332.99355},
  acmid =	 99355,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In contrast to the common view of spreadsheets as “single-user” programs, we have found that spreadsheets offer surprisingly strong support for cooperative development of a wide variety of applications. Ethnographic interviews with spreadsheet users showed that nearly all of the spreadsheets used in the work environments studied were the result of collaborative work by people with different levels of programming and domain expertise. Cooperation among spreadsheet users was spontaneous and casual; users activated existing informal social networks to initiate collaboration.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=99355&ftid=15985&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:26:57>},
}

@article{Searle:1986:IIL:22008.22023,
  author =	 {Searle, John R.},
  title =	 {IOTA3: The Integration of Lotus Spreadsheets and
                  APL},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 1986,
  volume =	 16,
  number =	 4,
  month =	 may,
  year =	 1986,
  issn =	 {0163-6006},
  pages =	 {103--106},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/22008.22023},
  doi =		 {10.1145/22008.22023},
  acmid =	 22023,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A software system named IOTA3 is described which represents an integration of the popular Lotus Corporation spreadsheets (1-2-3 and Symphony) and the language APL. IOTA3 allows the spreadsheet user to extend the worksheet environment to include many of the features of the APL environment. Conversely, it allows the APL user to think of the spreadsheet as an extension of the workspace.
The paper describes the various levels at which integration may be achieved, the costs and benefits of doing so, and the problems that were encountered and/or solved along the way. The system is based on the IBM Personal Computer and has been written for a number of APL implementations.},
  review = 	 {fbie: rejected <2016-01-15 13:27:01>},
}

@inproceedings{Searle:1986:IIL:22415.22023,
  author =	 {Searle, John R.},
  title =	 {IOTA3: The Integration of Lotus Spreadsheets and
                  APL},
  booktitle =	 {Proceedings of the International Conference on APL},
  series =	 {APL '86},
  year =	 1986,
  isbn =	 {0-901865-35-4},
  location =	 {Mancheester, United Kingdom},
  pages =	 {103--106},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/22415.22023},
  doi =		 {10.1145/22415.22023},
  acmid =	 22023,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A software system named IOTA3 is described which represents an integration of the popular Lotus Corporation spreadsheets (1-2-3 and Symphony) and the language APL. IOTA3 allows the spreadsheet user to extend the worksheet environment to include many of the features of the APL environment. Conversely, it allows the APL user to think of the spreadsheet as an extension of the workspace.
The paper describes the various levels at which integration may be achieved, the costs and benefits of doing so, and the problems that were encountered and/or solved along the way. The system is based on the IBM Personal Computer and has been written for a number of APL implementations.},
  review = 	 {fbie: rejected <2016-01-15 13:27:17>},
}

@inproceedings{Sikora:2015:SMM:2825041.2825074,
  author =	 {Sikora, Jerzy and Sroka, Jacek and Tyszkiewicz,
                  Jerzy},
  title =	 {Spreadsheet As a Multi-platform Mobile Application},
  booktitle =	 {Proceedings of the Second ACM International
                  Conference on Mobile Software Engineering and
                  Systems},
  series =	 {MOBILESoft '15},
  year =	 2015,
  isbn =	 {978-1-4799-1934-5},
  location =	 {Florence, Italy},
  pages =	 {140--141},
  numpages =	 2,
  url =		 {http://dl.acm.org/citation.cfm?id=2825041.2825074},
  acmid =	 2825074,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {The idea we want to advocate is the rapid prototyping of mobile multi-platform applications in the form of vanilla spreadsheets based on spreadsheet formulas, data validation and conditional formatting for tasks like entering and validating data, computing results and generating reports. Spreadsheet software systems, available on all major desktop and mobile platforms, provide runtime environment for such spreadsheet applications without the need for any plugins. Apart from playing the rÔle of a virtual machine, the environment provides also the user interface. Therefore such a spreadsheet becomes instantly a multi-platform application, working both on-line and off-line. We report on our case study of creating a mobile tool for archaeologists working in the field: a specialized spreadsheet for managing stratigraphic information. The resulting application passed satisfactorily a test of six weeks of regular excavations. Techniques used in the development can be considered as the first good practices for developing spreadsheet mobile applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2825074&ftid=1622072&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:27:22>},
}

@article{Juhasz:1999:USS:571535.571568,
  author =	 {Juhasz, Zoltan},
  title =	 {Using Spreadsheets As a Simple and Effective
                  Teaching Tool for Predicting and Visualizing
                  Parallel Program Performance},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {June 1999},
  volume =	 31,
  number =	 2,
  month =	 jun,
  year =	 1999,
  issn =	 {0097-8418},
  pages =	 {51--54},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/571535.571568},
  doi =		 {10.1145/571535.571568},
  acmid =	 571568,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes how we can use a spreadsheet program as an inexpensive and readily available tool to help students understand the execution behavior of parallel programs. Using the proposed method a performance prediction model can be created in a matter of minutes and the performance of the parallel system can be visualized and animated by using standard three-dimensional surface plots and user interface control objects.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=571568&ftid=82277&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:28:26>},
}

@article{Landram:1986:SCP:7538.7542,
  author =	 {Landram, Frank G. and Cook, James R. and Johnston,
                  Marvin},
  title =	 {Spreadsheet Calculations of Probabilities from the
                  F, T, {\$\chi\$}2, and Normal Distribution},
  journal =	 {Commun. ACM},
  issue_date =	 {Nov. 1986},
  volume =	 29,
  number =	 11,
  month =	 nov,
  year =	 1986,
  issn =	 {0001-0782},
  pages =	 {1090--1092},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/7538.7542},
  doi =		 {10.1145/7538.7542},
  acmid =	 7542,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {By computing probabilities from the normalization of the F distribution (instead of by numerical integration methods), statistical capabilities in spreadsheet operations can be greatly expanded and enhanced.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=7542&ftid=16685&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:28:34>},
}

@inproceedings{Hermans:2015:IWS:2819009.2819252,
  author =	 {Hermans, Felienne and Paige, Richard F. and Sestoft,
                  Peter},
  title =	 {2Nd International Workshop on Software Engineering
                  Methods in Spreadsheets (SEMS 2015)},
  booktitle =	 {Proceedings of the 37th International Conference on
                  Software Engineering - Volume 2},
  series =	 {ICSE '15},
  year =	 2015,
  location =	 {Florence, Italy},
  pages =	 {1005--1006},
  numpages =	 2,
  url =		 {http://dl.acm.org/citation.cfm?id=2819009.2819252},
  acmid =	 2819252,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Spreadsheets are heavily used in industry, because they are easily written and adjusted, using an intuitive visual interface. They often start out as simple tools; however, over time spreadsheets can become increasingly complex, up to the point where they become complicated and inflexible. In many ways, spreadsheet are similar to software: both concern the storage and manipulation of data and the presentation of results to the user. Because of this similarity, many methods and techniques from software engineering can be applied to spreadsheets. The role of SEMS, the International Workshop on Software Engineering Methods in Spreadsheets is to explore the possibilities of applying successful methods from software engineering to spreadsheets. Some, like testing and visualization, have been tried before and can be built upon. For methods that have not yet been tried on spreadsheets, SEMS will serve as a platform for early feedback. The SEMS program included an industrial keynote, "spreadsheet stories" (success or failure), short and long research papers, a good mix of industrial and academic researchers, as well as lively discussion and debate.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2819252&ftid=1617135&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:28:48>},
}

@inproceedings{Woo:2006:SAP:1127777.1127842,
  author =	 {Woo, Alec and Seth, Siddharth and Olson, Tim and
                  Liu, Jie and Zhao, Feng},
  title =	 {A Spreadsheet Approach to Programming and Managing
                  Sensor Networks},
  booktitle =	 {Proceedings of the 5th International Conference on
                  Information Processing in Sensor Networks},
  series =	 {IPSN '06},
  year =	 2006,
  isbn =	 {1-59593-334-4},
  location =	 {Nashville, Tennessee, USA},
  pages =	 {424--431},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1127777.1127842},
  doi =		 {10.1145/1127777.1127842},
  acmid =	 1127842,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SQL server, data streams, excel, networked sensors},
  abstract = 	 {We present a spreadsheet approach to simplifying the process of managing, programming, and interacting with sensor networks and visualizing, archiving and retrieving sensor data. An Excel spreadsheet prototype has been built to demonstrate the idea. This environment provides Excel users, who are already familiar with spreadsheet applications, a convenient and powerful tool for programming and data analysis. We discuss the architecture of this prototype and our experience in implementing the tool. We show two different classes of sensor-net applications built using this platform. We also present performance data on the scalability of the tool with respect to data rate and number of data streams.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1127842&ftid=349891&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:28:53>},
}

@inproceedings{Wilde:1990:SIG:97243.97268,
  author =	 {Wilde, Nicholas and Lewis, Clayton},
  title =	 {Spreadsheet-based Interactive Graphics: From
                  Prototype to Tool},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '90},
  year =	 1990,
  isbn =	 {0-201-50932-6},
  location =	 {Seattle, Washington, USA},
  pages =	 {153--160},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/97243.97268},
  doi =		 {10.1145/97243.97268},
  acmid =	 97268,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The NoPumpG prototype [7,8] suggested that the spreadsheet model of computation could simplify the creation of some types of interactive graphical application when compared with other approaches. We report here experience in developing an enhanced follow-on system, NoPumpII, and describe three applications developed using it. We conclude that (1) the potential advantages of the spreadsheet model are realized in this application experience, (2) revisions to the prototype design have permitted an increase in the complexity and scale of applications, and (3) there remain limitations in the current design which, if redressed, would further enlarge the scope of application. More generally we conclude that alternative computational models are an important area of exploration for HCI research.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=97268&ftid=16581&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:00>},
}

@article{Piersol:1986:OSA:960112.28737,
  author =	 {Piersol, Kurt W.},
  title =	 {Object-oriented Spreadsheets: The Analytic
                  Spreadsheet Package},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {Nov. 1986},
  volume =	 21,
  number =	 11,
  month =	 jun,
  year =	 1986,
  issn =	 {0362-1340},
  pages =	 {385--390},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/960112.28737},
  doi =		 {10.1145/960112.28737},
  acmid =	 28737,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The ASP package, a spreadsheet implemented in Smalltalk-80, is discussed. A description of the unique data manipulation features of ASP is given. A discussion of how these features arise from the Smalltalk-80 environment is included, with emphasis on features not common to all object oriented languages.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=28737&ftid=32265&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:29:21>},
}

@inproceedings{Piersol:1986:OSA:28697.28737,
  author =	 {Piersol, Kurt W.},
  title =	 {Object-oriented Spreadsheets: The Analytic
                  Spreadsheet Package},
  booktitle =	 {Conference Proceedings on Object-oriented
                  Programming Systems, Languages and Applications},
  series =	 {OOPLSA '86},
  year =	 1986,
  isbn =	 {0-89791-204-7},
  location =	 {Portland, Oregon, USA},
  pages =	 {385--390},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/28697.28737},
  doi =		 {10.1145/28697.28737},
  acmid =	 28737,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The ASP package, a spreadsheet implemented in Smalltalk-80, is discussed. A description of the unique data manipulation features of ASP is given. A discussion of how these features arise from the Smalltalk-80 environment is included, with emphasis on features not common to all object oriented languages.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=28737&ftid=32265&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:29:22>},
}

@article{Puckett:1987:IAS:384282.28334,
  author =	 {Puckett, Tom},
  title =	 {Implementation of an APL\&Mdash;Based Spreadsheet
                  Manager},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {May 1987},
  volume =	 17,
  number =	 4,
  month =	 jan,
  year =	 1987,
  issn =	 {0163-6006},
  pages =	 {163--172},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/384282.28334},
  doi =		 {10.1145/384282.28334},
  acmid =	 28334,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes the implementation of the STSC Spreadsheet Manager for users of STSC's APL*PLUS® PC System. The discussion is primarily from the standpoint of the product's internal workings. Important aspects are selection and interfacing of the languages to be used in the implementation (APL, C, and assembler), compatibility with Lotus® data structures, mappings between data in the APL and Lotus environments, manipulation of data in a spreadsheet context, and separation of function between APL and C environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=28334&ftid=11907&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:28>},
}

@inproceedings{Puckett:1987:IAS:28315.28334,
  author =	 {Puckett, Tom},
  title =	 {Implementation of an APL\&Mdash;Based Spreadsheet
                  Manager},
  booktitle =	 {Proceedings of the International Conference on APL:
                  APL in Transition},
  series =	 {APL '87},
  year =	 1987,
  isbn =	 {0-89791-226-8},
  location =	 {Dallas, Texas, USA},
  pages =	 {163--172},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/28315.28334},
  doi =		 {10.1145/28315.28334},
  acmid =	 28334,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes the implementation of the STSC Spreadsheet Manager for users of STSC's APL*PLUS® PC System. The discussion is primarily from the standpoint of the product's internal workings. Important aspects are selection and interfacing of the languages to be used in the implementation (APL, C, and assembler), compatibility with Lotus® data structures, mappings between data in the APL and Lotus environments, manipulation of data in a spreadsheet context, and separation of function between APL and C environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=28334&ftid=11907&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:31>},
}

@inproceedings{Gottfried:1997:PCO:266399.266405,
  author =	 {Gottfried, Herkimer J. and Burnett, Margaret M.},
  title =	 {Programming Complex Objects in Spreadsheets: An
                  Empirical Study Comparing Textual Formula Entry with
                  Direct Manipulation and Gestures},
  booktitle =	 {Papers Presented at the Seventh Workshop on
                  Empirical Studies of Programmers},
  series =	 {ESP '97},
  year =	 1997,
  isbn =	 {0-89791-992-0},
  location =	 {Alexandria, Virginia, USA},
  pages =	 {42--68},
  numpages =	 27,
  url =		 {http://doi.acm.org/10.1145/266399.266405},
  doi =		 {10.1145/266399.266405},
  acmid =	 266405,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=266405&ftid=35519&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:37>},
}

@inproceedings{Bailey:1987:SDP:31820.31812,
  author =	 {Bailey, M. Gene},
  title =	 {Spreadsheets and Databases\&Mdash;Alternatives to
                  Programming for Non-computer Science Majors},
  booktitle =	 {Proceedings of the Eighteenth SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '87},
  year =	 1987,
  isbn =	 {0-89791-217-9},
  location =	 {St. Louis, Missouri, USA},
  pages =	 {499--503},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/31820.31812},
  doi =		 {10.1145/31820.31812},
  acmid =	 31812,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Microcomputers have become easier and easier to use an emphasis is placed on software design for users with little or no experience. With a minimal amount of training, students or employees can become productive. Yet, academic programs still teach programming as a fundamental part of computer literacy. This paper proposes that the programming portion of the class be eliminated and replaced with a study of spreadsheets and databases. The paper discusses the manner in which spreadsheet and database design can be approached to maximize learning.An important concept that is learned in any programming class is algorithm development. Students learn how to analyze the problem and to set up the step-by-step solution. This process must be done before any coding can begin. Spreadsheets offer the same type of learning and are much more appropriate for non-computer science majors. Students must formulate the problem, determine the equations and formulas necessary to solve it, and then set up the worksheet. Spreadsheet applications are found in every discipline and their design requires a minimal amount of computer knowledge and mathematics.Learning to set up a database and design the queries necessary to obtain information from the database is a concept important to computer literacy. Once again, students learn to “program” by learning to construct their questions in a manner that is meaningful to the software package.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=31812&ftid=16132&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:43>},
}

@article{Bailey:1987:SDP:31726.31812,
  author =	 {Bailey, M. Gene},
  title =	 {Spreadsheets and Databases\&Mdash;Alternatives to
                  Programming for Non-computer Science Majors},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Feb. 1987},
  volume =	 19,
  number =	 1,
  month =	 feb,
  year =	 1987,
  issn =	 {0097-8418},
  pages =	 {499--503},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/31726.31812},
  doi =		 {10.1145/31726.31812},
  acmid =	 31812,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Microcomputers have become easier and easier to use an emphasis is placed on software design for users with little or no experience. With a minimal amount of training, students or employees can become productive. Yet, academic programs still teach programming as a fundamental part of computer literacy. This paper proposes that the programming portion of the class be eliminated and replaced with a study of spreadsheets and databases. The paper discusses the manner in which spreadsheet and database design can be approached to maximize learning.An important concept that is learned in any programming class is algorithm development. Students learn how to analyze the problem and to set up the step-by-step solution. This process must be done before any coding can begin. Spreadsheets offer the same type of learning and are much more appropriate for non-computer science majors. Students must formulate the problem, determine the equations and formulas necessary to solve it, and then set up the worksheet. Spreadsheet applications are found in every discipline and their design requires a minimal amount of computer knowledge and mathematics.Learning to set up a database and design the queries necessary to obtain information from the database is a concept important to computer literacy. Once again, students learn to “program” by learning to construct their questions in a manner that is meaningful to the software package.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=31812&ftid=16132&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:29:47>},
}

@article{Lewis:1985:ESI:1165385.317466,
  author =	 {Lewis, Clayton},
  title =	 {Extending the Spreadsheet Interface to Handle
                  Approximate Quantities and Relationships},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {April 1985},
  volume =	 16,
  number =	 4,
  month =	 apr,
  year =	 1985,
  issn =	 {0736-6906},
  pages =	 {55--59},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1165385.317466},
  doi =		 {10.1145/1165385.317466},
  acmid =	 317466,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Conventional spreadsheet programs offer a very convenient user interface for many quantitative tasks, but they are restricted to handling precisely-specified quantities and calculations. ASP is a generalized spreadsheet that extends the basic spreadsheet paradigm to encompass quantities which are not known exactly, and functions which are not known well enough to permit calculation. ASP works by propagating assertions about quantities and functions through the network of relationships that the spreadsheet defines.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=317466&ftid=16233&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:29:55>},
}

@inproceedings{Lewis:1985:ESI:317456.317466,
  author =	 {Lewis, Clayton},
  title =	 {Extending the Spreadsheet Interface to Handle
                  Approximate Quantities and Relationships},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '85},
  year =	 1985,
  isbn =	 {0-89791-149-0},
  location =	 {San Francisco, California, USA},
  pages =	 {55--59},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/317456.317466},
  doi =		 {10.1145/317456.317466},
  acmid =	 317466,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Conventional spreadsheet programs offer a very convenient user interface for many quantitative tasks, but they are restricted to handling precisely-specified quantities and calculations. ASP is a generalized spreadsheet that extends the basic spreadsheet paradigm to encompass quantities which are not known exactly, and functions which are not known well enough to permit calculation. ASP works by propagating assertions about quantities and functions through the network of relationships that the spreadsheet defines.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=317466&ftid=16233&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:29:58>},
}

@article{Shinners-Kennedy:1986:UST:953055.5905,
  author =	 {Shinners-Kennedy, Dermot},
  title =	 {Using Spreadsheets to Teach Computer Science},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {February 1986},
  volume =	 18,
  number =	 1,
  month =	 feb,
  year =	 1986,
  issn =	 {0097-8418},
  pages =	 {264--270},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/953055.5905},
  doi =		 {10.1145/953055.5905},
  acmid =	 5905,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes a research project which commenced recently at the NIHE, L. The project investigates the use of micro-computer software to teach aspects of computer science. Spreadsheets are the subject of this report. The potential of spreadsheet systems for teaching assembler programming is considered. We outline a model for enabling students to acquire fundamental computer science concepts using a simplistic “language machine”. The language machine is embedded in a programmable spreadsheet package which acts as the host language. The aim of the project is to explore the possibility of creating interactive, robust and instructional computer models using some of the more powerful spreadsheet packages in an imaginative fashion.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=5905&ftid=268100&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:03>},
}

@inproceedings{Shinners-Kennedy:1986:UST:5600.5905,
  author =	 {Shinners-Kennedy, Dermot},
  title =	 {Using Spreadsheets to Teach Computer Science},
  booktitle =	 {Proceedings of the Seventeenth SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '86},
  year =	 1986,
  isbn =	 {0-89791-178-4},
  location =	 {Cincinnati, Ohio, USA},
  pages =	 {264--270},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/5600.5905},
  doi =		 {10.1145/5600.5905},
  acmid =	 5905,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes a research project which commenced recently at the NIHE, L. The project investigates the use of micro-computer software to teach aspects of computer science. Spreadsheets are the subject of this report. The potential of spreadsheet systems for teaching assembler programming is considered. We outline a model for enabling students to acquire fundamental computer science concepts using a simplistic “language machine”. The language machine is embedded in a programmable spreadsheet package which acts as the host language. The aim of the project is to explore the possibility of creating interactive, robust and instructional computer models using some of the more powerful spreadsheet packages in an imaginative fashion.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=5905&ftid=268100&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:06>},
}

@article{Pacini:2004:LPS:1026487.1008102,
  author =	 {Pacini, Giuliano and Fiorentino, Giuseppe and
                  Fabrizio, Annalina},
  title =	 {Learning Problem Solving with Spreadsheet and
                  Database Tools},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {September 2004},
  volume =	 36,
  number =	 3,
  month =	 jun,
  year =	 2004,
  issn =	 {0097-8418},
  pages =	 {267--267},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1026487.1008102},
  doi =		 {10.1145/1026487.1008102},
  acmid =	 1008102,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {self-assessment, self-learning},
  abstract = 	 {Teaching skills for problem solving is usually accomplished on the basis of good examples of problems and corresponding sound solutions. By studying well-constructed examples the student learns how to analyze and decompose non-elementary problems and learns how to provide well-organized solutions.The tools we demonstrate support the teacher in presenting problems in an effective way and help the student in solving them. The teacher chooses a problem and provides a solution within Access or Excel, usually reducing the original problem to a collection of simpler, logically related sub-problems. The system thoroughly analyzes the teacher's solution and provides feedback about its structure as well as many automatically generated solution hints for the student. The teacher may add his own suggestions and establishes the form and content of the problem's presentation. Essentially, the teacher can specify which aspects of his own solution should be visible to the student. In this way, the difficulties for the student to solve the task can be largely controlled.The problem is proposed as a (possibly incomplete) set of sub-problems whose mutual relations may be left partially unspecified. In the same vein, some of the suggestions may be hidden in the initial problem presentation. The student can ask for hints during his solution attempts, and receives them at the price of penalties in the final evaluation. The results that the teacher's solution produces for the different sub-problems are supplied to the student (just the results, not the solutions). This provides three main benefits. The first one is motivational: the teacher's result is a clearly visible goal to reproduce and, by simple comparison, provides immediate feedback about the correctness of the student's solution attempts. The second benefit stems from the fact that the student is allowed to face the collection of sub-problems in a more flexible way. In fact, he can exploit the teacher's results to solve a particular sub-problem, independently from the sub-problems that he has (or has not) already solved. Finally, since the teacher's hidden solutions provide results that are assumed to be reliable, if the student uses them instead of his own results, error propagation is totally prevented.The system uses the teacher's results to automatically check the correctness of the student's results by comparison, and by considering different data samples the system infers the correctness of the student's solution. Moreover, since correctness is established by comparing results, the system will accept any solution that produces the same results as those arising from the teacher's solution, regardless of how the former are obtained. Experimentation with the system at the Italian Naval Academy has given good evidence that non-elementary problems can be proposed in a working context where students are stimulated to elaborate personal comprehension and to develop original solution techniques.The engineering of the system has been funded by the AICA-CRUI project "IT4PS - Information Technology for Problem Solving".},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1008102&ftid=268884&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:10>},
}

@inproceedings{Pacini:2004:LPS:1007996.1008102,
  author =	 {Pacini, Giuliano and Fiorentino, Giuseppe and
                  Fabrizio, Annalina},
  title =	 {Learning Problem Solving with Spreadsheet and
                  Database Tools},
  booktitle =	 {Proceedings of the 9th Annual SIGCSE Conference on
                  Innovation and Technology in Computer Science
                  Education},
  series =	 {ITiCSE '04},
  year =	 2004,
  isbn =	 {1-58113-836-9},
  location =	 {Leeds, United Kingdom},
  pages =	 {267--267},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1007996.1008102},
  doi =		 {10.1145/1007996.1008102},
  acmid =	 1008102,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {self-assessment, self-learning},
  abstract = 	 {Teaching skills for problem solving is usually accomplished on the basis of good examples of problems and corresponding sound solutions. By studying well-constructed examples the student learns how to analyze and decompose non-elementary problems and learns how to provide well-organized solutions.The tools we demonstrate support the teacher in presenting problems in an effective way and help the student in solving them. The teacher chooses a problem and provides a solution within Access or Excel, usually reducing the original problem to a collection of simpler, logically related sub-problems. The system thoroughly analyzes the teacher's solution and provides feedback about its structure as well as many automatically generated solution hints for the student. The teacher may add his own suggestions and establishes the form and content of the problem's presentation. Essentially, the teacher can specify which aspects of his own solution should be visible to the student. In this way, the difficulties for the student to solve the task can be largely controlled.The problem is proposed as a (possibly incomplete) set of sub-problems whose mutual relations may be left partially unspecified. In the same vein, some of the suggestions may be hidden in the initial problem presentation. The student can ask for hints during his solution attempts, and receives them at the price of penalties in the final evaluation. The results that the teacher's solution produces for the different sub-problems are supplied to the student (just the results, not the solutions). This provides three main benefits. The first one is motivational: the teacher's result is a clearly visible goal to reproduce and, by simple comparison, provides immediate feedback about the correctness of the student's solution attempts. The second benefit stems from the fact that the student is allowed to face the collection of sub-problems in a more flexible way. In fact, he can exploit the teacher's results to solve a particular sub-problem, independently from the sub-problems that he has (or has not) already solved. Finally, since the teacher's hidden solutions provide results that are assumed to be reliable, if the student uses them instead of his own results, error propagation is totally prevented.The system uses the teacher's results to automatically check the correctness of the student's results by comparison, and by considering different data samples the system infers the correctness of the student's solution. Moreover, since correctness is established by comparing results, the system will accept any solution that produces the same results as those arising from the teacher's solution, regardless of how the former are obtained. Experimentation with the system at the Italian Naval Academy has given good evidence that non-elementary problems can be proposed in a working context where students are stimulated to elaborate personal comprehension and to develop original solution techniques.The engineering of the system has been funded by the AICA-CRUI project "IT4PS - Information Technology for Problem Solving".},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1008102&ftid=268884&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:12>},
}

@article{Aonuma:1987:ISM:377719.55629,
  author =	 {Aonuma, T.},
  title =	 {An Interactive Simulation Modeling System: DYNAGRAPH
                  for Multi-period Planning on an APL Spreadsheet},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {Dec. 1987},
  volume =	 18,
  number =	 2,
  month =	 dec,
  year =	 1987,
  issn =	 {0163-6006},
  pages =	 {10--18},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/377719.55629},
  doi =		 {10.1145/377719.55629},
  acmid =	 55629,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A Modeling System named DYNAGRAPH has been developed on the IBM 5550 Personal Computer with NEXUS 5500 Graphics to interactively build dynamic simulation models using APL functions. A model for the simulation is represented by APL expressions in the rows of an APL Spreadsheet. The modeling of dynamic systems is achieved by a state-variable method.
The paper introduces DYNAGRAPH and the underlying modeling method. Some of the modeling functions for dynamic simulations are presented. We claim that the method is suitable and convenient for modeling problems of moderate size, especially when using APL in teaching or business environments: DYNAGRAPH is useful as a training tool and an APL program generator to enhance APL applications in management science.},
  review = 	 {fbie: rejected <2016-01-15 13:30:18>},
}

@inproceedings{Aonuma:1987:ISM:55626.55629,
  author =	 {Aonuma, T.},
  title =	 {An Interactive Simulation Modeling System: DYNAGRAPH
                  for Multi-period Planning on an APL Spreadsheet},
  booktitle =	 {Proceedings of the International Conference on APL},
  series =	 {APL '88},
  year =	 1988,
  isbn =	 {0-89791-253-5},
  location =	 {Sydney, Australia},
  pages =	 {10--18},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/55626.55629},
  doi =		 {10.1145/55626.55629},
  acmid =	 55629,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A Modeling System named DYNAGRAPH has been developed on the IBM 5550 Personal Computer with NEXUS 5500 Graphics to interactively build dynamic simulation models using APL functions. A model for the simulation is represented by APL expressions in the rows of an APL Spreadsheet. The modeling of dynamic systems is achieved by a state-variable method.
The paper introduces DYNAGRAPH and the underlying modeling method. Some of the modeling functions for dynamic simulations are presented. We claim that the method is suitable and convenient for modeling problems of moderate size, especially when using APL in teaching or business environments: DYNAGRAPH is useful as a training tool and an APL program generator to enhance APL applications in management science.},
  review = 	 {fbie: rejected <2016-01-15 13:30:21>},
}

@inproceedings{Benfield:2009:FFD:1668113.1668121,
  author =	 {Benfield, Lee},
  title =	 {FMD: Functional Development in Excel},
  booktitle =	 {Proceedings of the 2009 Video Workshop on Commercial
                  Users of Functional Programming: Functional
                  Programming As a Means, Not an End},
  series =	 {CUFP '09},
  year =	 2009,
  isbn =	 {978-1-60558-943-5},
  location =	 {Edinburgh, Scotland},
  articleno =	 8,
  url =		 {http://doi.acm.org/10.1145/1668113.1668121},
  doi =		 {10.1145/1668113.1668121},
  acmid =	 1668121,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Barclays Capital, like many other investment banks, uses Microsoft Excel as a rapid application development environment for pricing models and other tools. While this may sound bizarre, Excel's flexibility and convenience renders it an immensely useful tool for the Front Office, and our Traders are extremely Excel literate. Excel combines two programming models a zeroth order functional language (the spreadsheet) an imperative programming language (Visual Basic for Applications) The functional model allows very rapid development and great transparency, but the limitations of Excel's built-in functions drives developers to use VBA. Soon the spreadsheet dependency graph is lost and the spreadsheet layer is relegated to a GUI on top of tens/hundreds of thousands of lines of VBA. The logic is tightly tied to Excel, and a server-side implementation involves a complete rewrite in another language, which carries both operational risk and developmental cost. FMD ('Functional Model Deployment') prevents these problems by embedding a functional language cleanly into Excel, effectively extending Excel to be a higher order functional environment. Now complex models can be developed without leaving the pure spreadsheet domain: Before 1.Limited built-in functions need to be extended with add-ins or VBA. 2.Boilerplate code needs to be written to import libraries. 3.Systems need to be rewritten to run outside Excel. (typically ported to C++ / C# back end) After 1.Functions can be defined on-the-fly without leaving the pure spreadsheet side. 2.Dynamic and data-driven wrappers make external libraries directly visible. 3.Spreadsheet 'programs' can be exported and run outside of Excel. The business have fully supported this approach, and are enthusiastic about using FMD - as Simon Peyton Jones identified elsewhere, "Excel is the world's most popular functional language". From their point of view, functional programming in Excel is just an extension of what they've been doing for years!},
  review = 	 {fbie: accepted <2016-01-15 13:30:28>},
}

@inproceedings{Carver:2006:EET:1159733.1159775,
  author =	 {Carver, Jeffrey and Fisher,II, Marc and Rothermel,
                  Gregg},
  title =	 {An Empirical Evaluation of a Testing and Debugging
                  Methodology for Excel},
  booktitle =	 {Proceedings of the 2006 ACM/IEEE International
                  Symposium on Empirical Software Engineering},
  series =	 {ISESE '06},
  year =	 2006,
  isbn =	 {1-59593-218-6},
  location =	 {Rio de Janeiro, Brazil},
  pages =	 {278--287},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1159733.1159775},
  doi =		 {10.1145/1159733.1159775},
  acmid =	 1159775,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical study, end-user software engineering,
                  human subjects},
  abstract = 	 {Spreadsheets are one of the most commonly used types of programs in the world, and it is important that they be sufficiently dependable. To help end users who create spreadsheets do so more reliably, we have created a testing and debugging methodology and environment for use in spreadsheets, known as the WYSIWYT methodology. Our prior experiments with WYSIWYT show that users can utilize it to ensure that their spreadsheets are more dependable, but these experiments to date have considered only an unfamiliar prototype spreadsheet environment, and have not involved spreadsheet creation tasks. In this work we conducted a controlled experiment that addresses these limitations. The results of this study indicate that the use of WYSIWYT did not affect the correctness of spreadsheets created by users, but it did significantly reduce the amount of effort required to create them. Further, the subjects' evaluation of the help provided by WYSIWYT was very positive. Our results provide several insights into the use of the WYSIWYT methodology by end users.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1159775&ftid=378346&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:32>},
}

@inproceedings{Goodell:1997:EC:1120212.1120304,
  author =	 {Goodell, Howie},
  title =	 {End-user Computing},
  booktitle =	 {CHI '97 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '97},
  year =	 1997,
  isbn =	 {0-89791-926-2},
  location =	 {Atlanta, Georgia},
  pages =	 {132--132},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1120212.1120304},
  doi =		 {10.1145/1120212.1120304},
  acmid =	 1120304,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {application-specific languages, end-user computing,
                  machine control, programming by demonstration, user
                  programming},
  abstract = 	 {End-user computing and user programming refer to environments where non-programmers produce complete working computer applications[1]. Well-known examples include spreadsheets, the LOGO "turtle language" for children, and LABVIEW virtual instruments for laboratory automation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1120304&ftid=352550&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:45>},
}

@inproceedings{vanDeursen:2010:PPS:1879211.1879212,
  author =	 {van Deursen, Arie},
  title =	 {A Pragmatic Perspective on Software Visualization},
  booktitle =	 {Proceedings of the 5th International Symposium on
                  Software Visualization},
  series =	 {SOFTVIS '10},
  year =	 2010,
  isbn =	 {978-1-4503-0028-5},
  location =	 {Salt Lake City, Utah, USA},
  pages =	 {1--2},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1879211.1879212},
  doi =		 {10.1145/1879211.1879212},
  acmid =	 1879212,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {adoption, end-user programming, visualization},
  abstract = 	 {For software visualization researchers taking the pragmatic philosophical stance, the ultimate measure of success is adoption in industry. For you as researcher, what can be more satisfying than enthusiastic developers being able to work better and more efficiently thanks to your beautiful visualization of their software? One of the aims of this talk is to reflect on factors affecting impact in practice of software visualization research. How does rigorous empirical evaluation matter? What is the role of foundational research that does not subscribe to the philosophy of pragmatism? Can we make meaningful predictions of adoption in practice if this takes 10 years or more? During the talk, I will illustrate the dilemmas, opportunities, and frustrations involved in trying to achieve practical impact with examples drawn from my own research in such areas as software architecture analysis, documentation generation, and Web 2.0 user interface reverse engineering. I will also shed light on some of my most recent research activities, which includes work in the area of spreadsheet comprehension. This is research that we conduct with a major (Dutch) financial asset management firm. Our work consists of the identification of information needs for professional spreadsheet users, a visualization to address these needs, and an evaluation of this visualization with practitioners conducting real-life spreadsheet tasks. Throughout the talk, I will encourage the audience to engage in the discussion, and contribute their own perspectives on the issues that I raise in my talk.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1879212&ftid=852727&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:51>},
}

@inproceedings{Anslow:2008:TEP:1370847.1370861,
  author =	 {Anslow, Craig and Riehle, Dirk},
  title =	 {Towards End-user Programming with Wikis},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {61--65},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1370847.1370861},
  doi =		 {10.1145/1370847.1370861},
  acmid =	 1370861,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {application wikis, end-user programming, user
                  innovation, wikis},
  abstract = 	 {When business software fails to provide the desired functionality, users typically turn to spreadsheets to perform simple but general computational tasks. However, spreadsheets enforce a view of the world that consists mostly of tables and numbers rather than the domain concepts users have in mind. We are using wikis as a platform for empowering end-users to perform computational tasks of their choice. This paper discusses how core properties of wikis can support end-user programming. We illustrate our approach using wiki prototype software for working with business objects as made available by SAP's business application suite.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370861&ftid=498658&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:30:56>},
}

@inproceedings{Scaffidi:2008:TSD:1368088.1368226,
  author =	 {Scaffidi, Christopher and Myers, Brad and Shaw,
                  Mary},
  title =	 {Tool Support for Data Validation by End-user
                  Programmers},
  booktitle =	 {Proceedings of the 30th International Conference on
                  Software Engineering},
  series =	 {ICSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-079-1},
  location =	 {Leipzig, Germany},
  pages =	 {867--870},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1368088.1368226},
  doi =		 {10.1145/1368088.1368226},
  acmid =	 1368226,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data, end-user programming, validation},
  abstract = 	 {End-user programming tools for creating spreadsheets and webforms offer no data types except "string" for storing many kinds of data, such as person names and street addresses. Consequently, these tools cannot automatically validate these data. To address this problem, we have developed a new userextensible model for string-like data. Each "tope" in this model is a user-defined abstraction that guides the interpretation of strings as a particular kind of data, such as a mailing address. Specifically, each tope implementation contains software functions for recognizing and reformatting that tope's kind of data. With our tools, end-user programmers define new topes and associate them with fields in spreadsheets, webforms, and other programs. This makes it possible at runtime to distinguish between invalid data, valid data, and questionable data that could be valid or invalid. Once identified, questionable and/or invalid data can be double-checked and possibly corrected, thereby increasing the overall reliability of the data.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1368226&ftid=518491&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:31:04>},
}

@inproceedings{Burnett:2006:NSE:1125451.1125766,
  author =	 {Burnett, Margaret and Myers, Brad and Rosson, Mary
                  Beth and Wiedenbeck, Susan},
  title =	 {The Next Step: From End-user Programming to End-user
                  Software Engineering},
  booktitle =	 {CHI '06 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '06},
  year =	 2006,
  isbn =	 {1-59593-298-4},
  location =	 {Montr\&\#233;al, Qu\&\#233;bec, Canada},
  pages =	 {1699--1702},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1125451.1125766},
  doi =		 {10.1145/1125451.1125766},
  acmid =	 1125766,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programming, end-user software
                  engineering, programming by demonstration,
                  psychology of programming, testing},
  abstract = 	 {Is it possible to bring the benefits of rigorous software engineering methodologies to end users? End users create software when they use spreadsheet systems, web authoring tools and graphical languages, when they write educational simulations, spreadsheets, and dynamic e-business web applications. Unfortunately, however, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. A growing number of researchers and developers are working on ways to make the software created by end users more reliable. This workshop brings together researchers who are addressing this topic with industry representatives who are deploying end-user programming applications, to facilitate sharing of real-world problems and solutions.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1125766&ftid=348673&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:31:11>},
}

@inproceedings{Huff:1992:MME:144001.144011,
  author =	 {Huff, Sid L. and Munro, Malcolm C. and Marcolin,
                  Barbara},
  title =	 {Modelling and Measuring End User Sophistication},
  booktitle =	 {Proceedings of the 1992 ACM SIGCPR Conference on
                  Computer Personnel Research},
  series =	 {SIGCPR '92},
  year =	 1992,
  isbn =	 {0-89791-500-3},
  location =	 {Cincinnati, Ohio, USA},
  pages =	 {1--10},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/144001.144011},
  doi =		 {10.1145/144001.144011},
  acmid =	 144011,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=144011&ftid=22853&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:31:15>},
}

@inproceedings{Guthrie:2009:BUP:1668113.1668122,
  author =	 {Guthrie, Gordon},
  title =	 {Building the User Programmable Internet with Erlang},
  booktitle =	 {Proceedings of the 2009 Video Workshop on Commercial
                  Users of Functional Programming: Functional
                  Programming As a Means, Not an End},
  series =	 {CUFP '09},
  year =	 2009,
  isbn =	 {978-1-60558-943-5},
  location =	 {Edinburgh, Scotland},
  articleno =	 9,
  url =		 {http://doi.acm.org/10.1145/1668113.1668122},
  doi =		 {10.1145/1668113.1668122},
  acmid =	 1668122,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {For many people, the programming language of choice is a spreadsheet. This is especially true of people who are not employed as programmers, but write programs for their own use --- often defined as "end-user" programmers---A User-Centred Approach to Functions in Excel (Simon Peyton Jones, Alan Blackwell, Margaret Burnett) The most popular programming language in the world is a functional one --- the humble spreadsheet. The spreadsheet programming paradigm remains tied to the 'document' model due to its firm desktop roots. Hypernumbers are developing a 'spreadsheet-like' programming language and platform for the web that will enable non-technical end-users to build dynamic integrated web-applications. The hypernumbers platform is itself implemented in a functional programming language --- Erlang. The platform is currently in private beta testing with selected users and potential customers.},
  review = 	 {fbie: rejected <2016-01-15 13:31:19>},
}

@inproceedings{Scaffidi:2005:ACE:1083231.1083232,
  author =	 {Scaffidi, Christopher and Shaw, Mary and Myers,
                  Brad},
  title =	 {An Approach for Categorizing End User Programmers to
                  Guide Software Engineering Research},
  booktitle =	 {Proceedings of the First Workshop on End-user
                  Software Engineering},
  series =	 {WEUSE I},
  year =	 2005,
  isbn =	 {1-59593-131-7},
  location =	 {St. Louis, Missouri},
  pages =	 {1--5},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1082983.1083232},
  doi =		 {10.1145/1082983.1083232},
  acmid =	 1083232,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {abstraction, end user programming, end user software
                  engineering},
  abstract = 	 {Over 64 million Americans used computers at work in 1997, and we estimate this number will grow to 90 million in 2012, including over 55 million spreadsheet and database users and 13 million self-reported programmers. Existing characterizations of this end user population based on software usage provide minimal guidance on how to help end user programmers practice better software engineering. We describe an enhanced method of characterizing the end user population, based on categorizing end users according to the ways they represent abstractions. Since the use of abstraction can facilitate or impede achieving key software engineering goals (such as improving reusability and maintainability), this categorization promises an improved ability to highlight niches of end users with special software engineering capabilities or struggles. We have incorporated this approach into an in-progress survey of end user programming practices.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1083232&ftid=328649&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:31:25>},
}

@article{Scaffidi:2005:ACE:1082983.1083232,
  author =	 {Scaffidi, Christopher and Shaw, Mary and Myers,
                  Brad},
  title =	 {An Approach for Categorizing End User Programmers to
                  Guide Software Engineering Research},
  journal =	 {SIGSOFT Softw. Eng. Notes},
  issue_date =	 {July 2005},
  volume =	 30,
  number =	 4,
  month =	 may,
  year =	 2005,
  issn =	 {0163-5948},
  pages =	 {1--5},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1082983.1083232},
  doi =		 {10.1145/1082983.1083232},
  acmid =	 1083232,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {abstraction, end user programming, end user software
                  engineering},
  abstract = 	 {Over 64 million Americans used computers at work in 1997, and we estimate this number will grow to 90 million in 2012, including over 55 million spreadsheet and database users and 13 million self-reported programmers. Existing characterizations of this end user population based on software usage provide minimal guidance on how to help end user programmers practice better software engineering. We describe an enhanced method of characterizing the end user population, based on categorizing end users according to the ways they represent abstractions. Since the use of abstraction can facilitate or impede achieving key software engineering goals (such as improving reusability and maintainability), this categorization promises an improved ability to highlight niches of end users with special software engineering capabilities or struggles. We have incorporated this approach into an in-progress survey of end user programming practices.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1083232&ftid=328649&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:11>},
}

@inproceedings{Burnett:2008:GES:1370847.1370852,
  author =	 {Burnett, Margaret and Wiedenbeck, Susan and
                  Grigoreanu, Valentina and Subrahmaniyan, Neeraja and
                  Beckwith, Laura and Kissinger, Cory},
  title =	 {Gender in End-user Software Engineering},
  booktitle =	 {Proceedings of the 4th International Workshop on
                  End-user Software Engineering},
  series =	 {WEUSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-034-0},
  location =	 {Leipzig, Germany},
  pages =	 {21--24},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1370847.1370852},
  doi =		 {10.1145/1370847.1370852},
  acmid =	 1370852,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, end-user programming, end-user software
                  engineering, gender, self-efficacy, strategy,
                  surprise-explain-reward, tinkering},
  abstract = 	 {In this paper, we describe research that reports gender differences in usage of software engineering tools by end-user programmers. We connect these findings with possible explanations based on theories from other disciplines, and then add to that our recent results that these differences go deeper than software engineering tool usage to software engineering strategies. We enumerate the strategies that work better for males and the ones that work better for females, and discuss implications and possible directions for follow-up.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370852&ftid=498649&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:16>},
}

@inproceedings{Adams:2008:FEU:1370175.1370177,
  author =	 {Adams, Sam S.},
  title =	 {The Future of End User Programming?},
  booktitle =	 {Companion of the 30th International Conference on
                  Software Engineering},
  series =	 {ICSE Companion '08},
  year =	 2008,
  isbn =	 {978-1-60558-079-1},
  location =	 {Leipzig, Germany},
  pages =	 {887--888},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1370175.1370177},
  doi =		 {10.1145/1370175.1370177},
  acmid =	 1370177,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user programming, end user software engineering},
  abstract = 	 {One of the Holy Grails of Computer Science for many decades has been to make the power of computer programming accessible to more and more people. The earliest "high level" languages, FORTRAN and COBOL, were intentionally designed to be written and understood by specific communities of users with problems to solve, namely the Scientific/Engineering and Business communities. As computing became more accessible to more people, the number of dedicated full time programmers mushroomed and formed a community unto itself, who largely created languages and tools by and for themselves to use. The end users, the people with the non-computing problems to solve, became isolated from the computer itself and were forced have their business problems encoded in the increasingly esoteric script of a powerful new programmer priesthood. But even throughout these "dark ages", a small number of valiant dissenters survived and flourished in distant monasteries and hermitages, dedicating their lives and technical prowess to liberate computing from its raised floor temples. Resistance was stiff, but not futile, as every decade or so breakthroughs like spreadsheets, Hypercard, 4GLs and HTML empowered more and more "non-programmers" to create their own computing solutions. Now, well into the second era of the Web, consumer-oriented websites like Flickr and YouTube routinely offer end users "snippets" of JavaScript code to reuse in their own software creations, their Facebook and MySpace pages. Projects like IBM's CoScripter have achieved programming by demonstration for end users. Mashup tools abound, and the Web is filled with billions of customized applications, most created by end users themselves. Have we finally achieved the goals of those happy few who dreamed of a world where programming was as common as dialing a telephone? Have we finally arrived at the Long Tail of Programming? And if we have built it, did they come? This talk will assess the current state of end user programming and present a heretical perspective about the future of this endeavor from a confessed true believer.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1370177&ftid=516159&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:20>},
}

@inproceedings{Myers:2004:EUC:985921.986161,
  author =	 {Myers, Brad A. and Burnett, Margaret},
  title =	 {End Users Creating Effective Software},
  booktitle =	 {CHI '04 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '04},
  year =	 2004,
  isbn =	 {1-58113-703-6},
  location =	 {Vienna, Austria},
  pages =	 {1592--1593},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/985921.986161},
  doi =		 {10.1145/985921.986161},
  acmid =	 986161,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programming, end-user software
                  engineering, programming by demonstration,
                  psychology of programming, testing},
  abstract = 	 {Is it possible to bring the benefits of rigorous software engineering methodologies to end users? End users create software when they use spreadsheet systems, web authoring tools and graphical languages, when they write educational simulations, spreadsheets, and dynamic e-business web applications. Unfortunately, however, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. A growing number of researchers and developers are working on ways to make the software created by end-users more reliable. This special interest group meeting will help start to form a community of researchers who are addressing this topic.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=986161&ftid=263152&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:25>},
}

@inproceedings{Myers:2005:EUC:1056808.1057093,
  author =	 {Myers, Brad A. and Burnett, Margaret and Rosson,
                  Mary Beth},
  title =	 {End Users Creating Effective Software},
  booktitle =	 {CHI '05 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '05},
  year =	 2005,
  isbn =	 {1-59593-002-7},
  location =	 {Portland, OR, USA},
  pages =	 {2047--2048},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1056808.1057093},
  doi =		 {10.1145/1056808.1057093},
  acmid =	 1057093,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programming, end-user software
                  engineering, programming by demonstration,
                  psychology of programming, testing},
  abstract = 	 {Is it possible to bring the benefits of rigorous software engineering methodologies to end users? End users create software when they use spreadsheet systems, web authoring tools and graphical languages, when they write educational simulations, spreadsheets, and dynamic e-business web applications. Unfortunately, however, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. A growing number of researchers and developers are working on ways to make the software created by end users more reliable. This special interest group meeting will help support the community of researchers who are addressing this topic.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1057093&ftid=308085&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:28>},
}

@inproceedings{Subrahmaniyan:2008:TVC:1357054.1357153,
  author =	 {Subrahmaniyan, Neeraja and Beckwith, Laura and
                  Grigoreanu, Valentina and Burnett, Margaret and
                  Wiedenbeck, Susan and Narayanan, Vaishnavi and
                  Bucht, Karin and Drummond, Russell and Fern, Xiaoli},
  title =	 {Testing vs. Code Inspection vs. What else?: Male and
                  Female End Users' Debugging Strategies},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '08},
  year =	 2008,
  isbn =	 {978-1-60558-011-1},
  location =	 {Florence, Italy},
  pages =	 {617--626},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1357054.1357153},
  doi =		 {10.1145/1357054.1357153},
  acmid =	 1357153,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, end-user programming, end-user software
                  engineering, gender, strategy},
  abstract = 	 {Little is known about the strategies end-user programmers use in debugging their programs, and even less is known about gender differences that may exist in these strategies. Without this type of information, designers of end-user programming systems cannot know the "target" at which to aim, if they are to support male and female end-user programmers. We present a study investigating this issue. We asked end-user programmers to debug spreadsheets and to describe their debugging strategies. Using mixed methods, we analyzed their strategies and looked for relationships among participants' strategy choices, gender, and debugging success. Our results indicate that males and females debug in quite different ways, that opportunities for improving support for end-user debugging strategies for both genders are abundant, and that tools currently available to end-user debuggers may be especially deficient in supporting debugging strategies used by females.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1357153&ftid=499192&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:34>},
}

@article{Le:2014:FFD:2666356.2594333,
  author =	 {Le, Vu and Gulwani, Sumit},
  title =	 {FlashExtract: A Framework for Data Extraction by
                  Examples},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {June 2014},
  volume =	 49,
  number =	 6,
  month =	 jun,
  year =	 2014,
  issn =	 {0362-1340},
  pages =	 {542--553},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2666356.2594333},
  doi =		 {10.1145/2666356.2594333},
  acmid =	 2594333,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, program synthesis, programming
                  by examples},
  abstract = 	 {Various document types that combine model and view (e.g., text files, webpages, spreadsheets) make it easy to organize (possibly hierarchical) data, but make it difficult to extract raw data for any further manipulation or querying. We present a general framework FlashExtract to extract relevant data from semi-structured documents using examples. It includes: (a) an interaction model that allows end-users to give examples to extract various fields and to relate them in a hierarchical organization using structure and sequence constructs. (b) an inductive synthesis algorithm to synthesize the intended program from few examples in any underlying domain-specific language for data extraction that has been built using our specified algebra of few core operators (map, filter, merge, and pair). We describe instantiation of our framework to three different domains: text files, webpages, and spreadsheets. On our benchmark comprising 75 documents, FlashExtract is able to extract intended data using an average of 2.36 examples in 0.84 seconds per field.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2594333&ftid=1460094&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:38>},
}

@inproceedings{Le:2014:FFD:2594291.2594333,
  author =	 {Le, Vu and Gulwani, Sumit},
  title =	 {FlashExtract: A Framework for Data Extraction by
                  Examples},
  booktitle =	 {Proceedings of the 35th ACM SIGPLAN Conference on
                  Programming Language Design and Implementation},
  series =	 {PLDI '14},
  year =	 2014,
  isbn =	 {978-1-4503-2784-8},
  location =	 {Edinburgh, United Kingdom},
  pages =	 {542--553},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2594291.2594333},
  doi =		 {10.1145/2594291.2594333},
  acmid =	 2594333,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, program synthesis, programming
                  by examples},
  abstract = 	 {Various document types that combine model and view (e.g., text files, webpages, spreadsheets) make it easy to organize (possibly hierarchical) data, but make it difficult to extract raw data for any further manipulation or querying. We present a general framework FlashExtract to extract relevant data from semi-structured documents using examples. It includes: (a) an interaction model that allows end-users to give examples to extract various fields and to relate them in a hierarchical organization using structure and sequence constructs. (b) an inductive synthesis algorithm to synthesize the intended program from few examples in any underlying domain-specific language for data extraction that has been built using our specified algebra of few core operators (map, filter, merge, and pair). We describe instantiation of our framework to three different domains: text files, webpages, and spreadsheets. On our benchmark comprising 75 documents, FlashExtract is able to extract intended data using an average of 2.36 examples in 0.84 seconds per field.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2594333&ftid=1460094&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:41>},
}

@inproceedings{Beckwith:2005:EED:1054972.1055094,
  author =	 {Beckwith, Laura and Burnett, Margaret and
                  Wiedenbeck, Susan and Cook, Curtis and Sorte,
                  Shraddha and Hastings, Michelle},
  title =	 {Effectiveness of End-user Debugging Software
                  Features: Are There Gender Issues?},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '05},
  year =	 2005,
  isbn =	 {1-58113-998-5},
  location =	 {Portland, Oregon, USA},
  pages =	 {869--878},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1054972.1055094},
  doi =		 {10.1145/1054972.1055094},
  acmid =	 1055094,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, end-user programming, end-user software
                  engineering, gender, surprise-explain-reward},
  abstract = 	 {Although gender differences in a technological world are receiving significant research attention, much of the research and practice has aimed at how society and education can impact the successes and retention of female computer science professionals-but the possibility of gender issues within software has received almost no attention. If gender issues exist with some types of software features, it is possible that accommodating them by changing these features can increase effectiveness, but only if we know what these issues are. In this paper, we empirically investigate gender differences for end users in the context of debugging spreadsheets. Our results uncover significant gender differences in self-efficacy and feature acceptance, with females exhibiting lower self-efficacy and lower feature acceptance. The results also show that these differences can significantly reduce females' effectiveness.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1055094&ftid=305338&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:45>},
}

@inproceedings{Bray:2010:UED:1822018.1822025,
  author =	 {Bray, Zachary and Kristensson, Per Ola},
  title =	 {Using Ensembles of Decision Trees to Automate
                  Repetitive Tasks in Web Applications},
  booktitle =	 {Proceedings of the 2Nd ACM SIGCHI Symposium on
                  Engineering Interactive Computing Systems},
  series =	 {EICS '10},
  year =	 2010,
  isbn =	 {978-1-4503-0083-4},
  location =	 {Berlin, Germany},
  pages =	 {35--40},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1822018.1822025},
  doi =		 {10.1145/1822018.1822025},
  acmid =	 1822025,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end-user programming, programming by example},
  abstract = 	 {Web applications such as web-based email, spreadsheets and form filling applications have become ubiquitous. However, many of the tasks that users try to accomplish with such web applications are highly repetitive. In this paper we present the design of a system we have developed that learns and thereafter automates users' repetitive tasks in web applications. Our system infers users' intentions using an ensemble of decision trees. This enables it to handle branching, generalization and recurrent changes of relative and absolute positions. Our evaluation shows that our system converges to the correct solution after 3--8 iterations when the pattern is noise-free, and after 3--14 iterations for a noise level between 5--35\%.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1822025&ftid=812971&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:51>},
}

@article{Risch:1988:FAI:53580.53582,
  author =	 {Risch, Tore and Reboh, Ren{\'e} and Hart, Peter
                  E. and Duda, Richard O.},
  title =	 {A Functional Approach to Integrating Database and
                  Expert Systems},
  journal =	 {Commun. ACM},
  issue_date =	 {Dec. 1988},
  volume =	 31,
  number =	 12,
  month =	 dec,
  year =	 1988,
  issn =	 {0001-0782},
  pages =	 {1424--1437},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/53580.53582},
  doi =		 {10.1145/53580.53582},
  acmid =	 53582,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A new system architecture shares certain characteristics with database systems, expert systems, functional programming languages, and spreadsheet systems, but is very different from any of these.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=53582&ftid=16486&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:32:57>},
}

@inproceedings{Fujima:2007:WAO:1331740.1331817,
  author =	 {Fujima, Jun and Yoshihara, Shohei and Tanaka,
                  Yuzuru},
  title =	 {Web Application Orchestration Using Excel},
  booktitle =	 {Proceedings of the IEEE/WIC/ACM International
                  Conference on Web Intelligence},
  series =	 {WI '07},
  year =	 2007,
  isbn =	 {0-7695-3026-5},
  pages =	 {743--749},
  numpages =	 7,
  url =		 {http://dx.doi.org/10.1109/WI.2007.153},
  doi =		 {10.1109/WI.2007.153},
  acmid =	 1331817,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:32:58>},
}

@article{Sato:1989:CEC:77308.77310,
  author =	 {Sato, O.},
  title =	 {Controlling End-user Computing: An Analytical
                  Framework},
  journal =	 {SIGSAC Rev.},
  issue_date =	 {Fall 1989},
  volume =	 7,
  number =	 3,
  month =	 oct,
  year =	 1989,
  issn =	 {0277-920X},
  pages =	 {6--12},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/77308.77310},
  doi =		 {10.1145/77308.77310},
  acmid =	 77310,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The emergence of Microcomputer, off the shelf software such as spreadsheet, telecommunication, and improvement of user-interface of them make End-User Computing (EUC) as a important application of computer technology in business. EUC growth rate is sky-rocketing now (Sprague R. H. Jr., and B. C. McNurlin (1986)). Every office use many microcomputers. Everyone uses it personally for his/her business. Moreover, many critical decision are made through microcomputers or by using information from microcomputers. DDS (Decision Support Systems) and ESS (Executive Support System) are examples (Rockart, J. F. and D. W. DeLong (1988)). But the more the number of user of microcomputers, the control of EUC becomes more important.},
  review = 	 {fbie: rejected <2016-01-15 13:33:03>},
}

@inproceedings{Myers:2006:IRO:1125451.1125472,
  author =	 {Myers, Brad A. and Ko, Andrew J. and Burnett,
                  Margaret M.},
  title =	 {Invited Research Overview: End-user Programming},
  booktitle =	 {CHI '06 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '06},
  year =	 2006,
  isbn =	 {1-59593-298-4},
  location =	 {Montr\&\#233;al, Qu\&\#233;bec, Canada},
  pages =	 {75--80},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1125451.1125472},
  doi =		 {10.1145/1125451.1125472},
  acmid =	 1125472,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programmers (ESP), end-user
                  software engineering, natural programming,
                  programming by demonstration, programming by
                  example, psychology of programming, visual
                  programming},
  abstract = 	 {In the past few decades there has been considerable work on empowering end users to be able to write their own programs, and as a result, users are indeed doing so. In fact, we estimate that over 12 million people in American workplaces would say that they "do programming" at work, and almost 50 million people use spreadsheets or databases (and therefore may potentially program), compared to only 3 million professional programmers. The "programming" systems used by these end users include spreadsheet systems, web authoring tools, business process authoring tools such as Visual Basic, graphical languages for demonstrating the desired behavior of educational simulations, and even professional languages such as Java. The motivation for end-user programming is to have the computer be useful for each person's specific individual needs. While the empirical study of programming has been an HCI topic since the beginning the field, it is only recently that there has been a focus on the End-User Programmer as a separate class from novices who are assumed to be studying to be professional programmers. Another recent focus is on making end-user programming more reliable, using "End-User Software Engineering." This paper gives a brief summary of some current and past research in the area of End-User Programming.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1125472&ftid=348387&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:08>},
}

@inproceedings{Lin:2009:EPM:1502650.1502667,
  author =	 {Lin, James and Wong, Jeffrey and Nichols, Jeffrey
                  and Cypher, Allen and Lau, Tessa A.},
  title =	 {End-user Programming of Mashups with Vegemite},
  booktitle =	 {Proceedings of the 14th International Conference on
                  Intelligent User Interfaces},
  series =	 {IUI '09},
  year =	 2009,
  isbn =	 {978-1-60558-168-2},
  location =	 {Sanibel Island, Florida, USA},
  pages =	 {97--106},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1502650.1502667},
  doi =		 {10.1145/1502650.1502667},
  acmid =	 1502667,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {automation, data integration, end-user programming,
                  mashup, programming by demonstration, web},
  abstract = 	 {Mashups are an increasingly popular way to integrate data from multiple web sites to fit a particular need, but it often requires substantial technical expertise to create them. To lower the barrier for creating mashups, we have extended the CoScripter web automation tool with a spreadsheet-like environment called Vegemite. Our system uses direct-manipulation and programming-by-demonstration tech-niques to automatically populate tables with information collected from various web sites. A particular strength of our approach is its ability to augment a data set with new values computed by a web site, such as determining the driving distance from a particular location to each of the addresses in a data set. An informal user study suggests that Vegemite may enable a wider class of users to address their information needs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1502667&ftid=609394&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:13>},
}

@inproceedings{Pelizzi:2015:WWA:2841113.2841124,
  author =	 {Pelizzi, Riccardo and Sekar, R.},
  title =	 {WebSheets: Web Applications for Non-Programmers},
  booktitle =	 {Proceedings of the 2015 New Security Paradigms
                  Workshop},
  series =	 {NSPW '15},
  year =	 2015,
  isbn =	 {978-1-4503-3754-0},
  location =	 {Twente, Netherlands},
  pages =	 {137--147},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/2841113.2841124},
  doi =		 {10.1145/2841113.2841124},
  acmid =	 2841124,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Spreadsheets are a very successful programming paradigm. Their success stems from user's familiarity with tabular data, and their previous experience in performing manual computations on such data. Since tabular data is familiar to users in the context of web applications as well, we propose WebSheets, a new paradigm for developing web applications using a spreadsheet-like language. WebSheets can enable simple web applications to be developed without "programming," in much the same way that non-programmers create budgets or expense reports using spreadsheets. More importantly, WebSheets enable users to express fine-grained privacy policies on their data in a simple manner, thus putting them in charge of their own privacy and security concerns.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2841124&ftid=1651250&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:21>},
}

@inproceedings{Myers:2008:EUS:1358628.1358687,
  author =	 {Myers, Brad A. and Burnett, Margaret M. and Rosson,
                  Mary Beth and Ko, Andrew J. and Blackwell, Alan},
  title =	 {End User Software Engineering: Chi'2008 Special
                  Interest Group Meeting},
  booktitle =	 {CHI '08 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '08},
  year =	 2008,
  isbn =	 {978-1-60558-012-8},
  location =	 {Florence, Italy},
  pages =	 {2371--2374},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1358628.1358687},
  doi =		 {10.1145/1358628.1358687},
  acmid =	 1358687,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programmers (esp), end users
                  shaping effective software (euses), end-user
                  software engineering (euse), natural programming,
                  psychology of programming},
  abstract = 	 {End users create software whenever they write, for instance, educational simulations, spreadsheets, or dynamic e-business web applications. Researchers are working to bring the benefits of rigorous software engineering methodologies to these end users to try to make their software more reliable. Unfortunately, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. This special interest group meeting has two purposes: to incorporate attendees' and feedback into an emerging survey of the state of this interesting new sub-area, and generally to bring together the community of researchers who are addressing this topic, with the companies that are creating end-user programming tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1358687&ftid=510144&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:26>},
}

@inproceedings{Robertson:2004:IIS:985692.985729,
  author =	 {Robertson, T. J. and Prabhakararao, Shrinu and
                  Burnett, Margaret and Cook, Curtis and Ruthruff,
                  Joseph R. and Beckwith, Laura and Phalgune, Amit},
  title =	 {Impact of Interruption Style on End-user Debugging},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '04},
  year =	 2004,
  isbn =	 {1-58113-702-8},
  location =	 {Vienna, Austria},
  pages =	 {287--294},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/985692.985729},
  doi =		 {10.1145/985692.985729},
  acmid =	 985729,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {debugging, end-user programming, end-user software
                  engineering, interruptions, surprise-explain-reward},
  abstract = 	 {Although researchers have begun to explicitly support end-user programmers' debugging by providing information to help them find bugs, there is little research addressing the proper mechanism to alert the user to this information. The choice of alerting mechanism can be important, because as previous research has shown, different interruption styles have different potential advantages and disadvantages. To explore impacts of interruptions in the end-user debugging domain, this paper describes an empirical comparison of two interruption styles that have been used to alert end-user programmers to debugging information. Our results show that negotiated-style interruptions were superior to immediate-style interruptions in several issues of importance to end-user debugging, and further suggest that a reason for this superiority may be that immediate-style interruptions encourage different debugging strategies.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=985729&ftid=262307&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:35>},
}

@inproceedings{Myers:2007:EUS:1240866.1240964,
  author =	 {Myers, Brad A. and Burnett, Margaret M. and
                  Wiedenbeck, Susan and Ko, Andrew J.},
  title =	 {End User Software Engineering: CHI 2007 Special
                  Interest Group Meeting},
  booktitle =	 {CHI '07 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '07},
  year =	 2007,
  isbn =	 {978-1-59593-642-4},
  location =	 {San Jose, CA, USA},
  pages =	 {2125--2128},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1240866.1240964},
  doi =		 {10.1145/1240866.1240964},
  acmid =	 1240964,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {empirical studies of programmers (ESP), end users
                  shaping effective software (EUSES), end-user
                  software engineering (EUSE), natural programming,
                  psychology of programming},
  abstract = 	 {Recently, researchers have been working to bring the benefits of rigorous software engineering methodologies to end users who find themselves in programming situations, to try to make their software more reliable. End users create software whenever they write, for instance, educational simulations, spreadsheets, or dynamic e-business web applications. Unfortunately, errors are pervasive in end-user software, and the resulting impact is sometimes enormous. This special interest group meeting has three purposes: to bring the results of a recent (February 2007) week-long "Dagstuhl" meeting on end-user software engineering to interested researchers at CHI; to incorporate attendees' ideas and feedback into an emerging survey of the state of this interesting new subarea; and generally to bring together the community of researchers who are addressing this topic, with the companies that are creating end-user programming tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1240964&ftid=416946&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:40>},
}

@inproceedings{Bertazzoni:1990:RRA:98894.98907,
  author =	 {Bertazzoni, C. and Giannotti, Fosca},
  title =	 {RASP: A Resource Allocator for Software Projects},
  booktitle =	 {Proceedings of the 3rd International Conference on
                  Industrial and Engineering Applications of
                  Artificial Intelligence and Expert Systems - Volume
                  2},
  series =	 {IEA/AIE '90},
  year =	 1990,
  isbn =	 {0-89791-372-8},
  location =	 {Charleston, South Carolina, USA},
  pages =	 {628--637},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/98894.98907},
  doi =		 {10.1145/98894.98907},
  acmid =	 98907,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Rasp is a resource allocator that tries to apply artificial intelligence techniques in the project management field. Rasp expresses and manipulates all aspects concerning resource allocation exploiting a combined approach which integrates the logic programming paradigm with spreadsheet technology.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=98907&ftid=296041&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:44>},
}

@inproceedings{Fujima:2004:CCC:1029632.1029664,
  author =	 {Fujima, Jun and Lunzer, Aran and Hornb{\ae}k, Kasper
                  and Tanaka, Yuzuru},
  title =	 {Clip, Connect, Clone: Combining Application Elements
                  to Build Custom Interfaces for Information Access},
  booktitle =	 {Proceedings of the 17th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '04},
  year =	 2004,
  isbn =	 {1-58113-957-8},
  location =	 {Santa Fe, NM, USA},
  pages =	 {175--184},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1029632.1029664},
  doi =		 {10.1145/1029632.1029664},
  acmid =	 1029664,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {customized information access, end-user programming,
                  parallel exploration},
  abstract = 	 {Many applications provide a form-like interface for requesting information: the user fills in some fields, submits the form, and the application presents corresponding results. Such a procedure becomes burdensome if (1) the user must submit many different requests, for example in pursuing a trial-and-error search, (2) results from one application are to be used as inputs for another, requiring the user to transfer them by hand, or (3) the user wants to compare results, but only the results from one request can be seen at a time. We describe how users can reduce this burden by creating custom interfaces using three mechanisms: clipping of input and result elements from existing applications to form cells on a spreadsheet; connecting these cells using formulas, thus enabling result transfer between applications; and cloning cells so that multiple requests can be handled side by side. We demonstrate a prototype of these mechanisms, initially specialised for handling Web applications, and show how it lets users build new interfaces to suit their individual needs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1029664&ftid=285532&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:49>},
}

@inproceedings{Ozer:2006:DAT:1182807.1182844,
  author =	 {Ozer, Stuart and Gray, Jim and Szalay, Alex and
                  Terzis, Andreas and Musaloiu-E, Razvan and Szlavecz,
                  Katalin and Burns, Randal and Cogan, Josh},
  title =	 {Data Analysis Tools for Sensor-based Science},
  booktitle =	 {Proceedings of the 4th International Conference on
                  Embedded Networked Sensor Systems},
  series =	 {SenSys '06},
  year =	 2006,
  isbn =	 {1-59593-343-3},
  location =	 {Boulder, Colorado, USA},
  pages =	 {341--342},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1182807.1182844},
  doi =		 {10.1145/1182807.1182844},
  acmid =	 1182844,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data cubes, sensor networks},
  abstract = 	 {Science is increasingly driven by data collected automatically from arrays of inexpensive sensors. The collected data volumes require a different approach from the scientists' current Excel spreadsheet storage and analysis model. Spreadsheets work well for small data sets; but scientists want high level summaries of their data for various statistical analyses without sacrificing the ability to drill down to every bit of the raw data. This demonstration describes our prototype data analysis system that is suitable for browsing and visualization - like a spreadsheet - but scalable to much larger data sets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1182844&ftid=395698&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:52>},
}

@inproceedings{Goldman:2002:CBS:1030453.1030678,
  author =	 {Goldman, Lawrence I.},
  title =	 {Crystal Ball Software Tutorial: Crystal Ball
                  Professional Introductory Tutorial},
  booktitle =	 {Proceedings of the 34th Conference on Winter
                  Simulation: Exploring New Frontiers},
  series =	 {WSC '02},
  year =	 2002,
  isbn =	 {0-7803-7615-3},
  location =	 {San Diego, California},
  pages =	 {1539--1545},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=1030453.1030678},
  acmid =	 1030678,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Crystal Ball® 2000 Professional Edition is a suite of easy-to-use Microsoft® Excel® add-in software that helps you analyze the risks and uncertainties associated with your spreadsheet models. The suite includes analysis tools for Monte Carlo simulation (Crystal Ball), time-series forecasting (CB Predictor), and optimization (OptQuest) as well as developer kits for building custom interfaces and processes. Spreadsheets alone are inadequate for assessing the probability of an event because they lack the ability to generate and analyze alternative scenarios in a sophisticated way. Spreadsheet add-ins such as Crystal Ball can provide this functionality and help modelers gain new insights into the mechanisms that drive their models and affect positive outcomes. This tutorial uses the example of an emerging media product to discuss how the analystical tools of Monte Carlo simulation and time-series forecasting can provide a greater understanding and quantification of the risks inherent in a spreadsheet-based business decision.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1030678&ftid=292971&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:33:57>},
}

@article{Jones:1991:BRU:140738.1060510,
  note =	 {Reviewer-Jones, Larry},
  title =	 {Book Review: USING 1-2-3 RELEASE 3.1 by Rebecca
                  Altman, Et. Al. (Que Corporation, 1990)},
  journal =	 {SIGSMALL/PC Notes},
  issue_date =	 {Fall/Winter 1991},
  volume =	 17,
  number =	 {3-4},
  month =	 sep,
  year =	 1991,
  issn =	 {0893-2875},
  pages =	 {61--},
  url =		 {http://doi.acm.org/10.1145/140738.1060510},
  doi =		 {10.1145/140738.1060510},
  acmid =	 1060510,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This book is typical of the USING series of books produced by Que Corporation. As such, it attempts to meet the needs of all users, "new spreadsheet users, and users who have upgraded to Release 3.1." Unfortunately, spreadsheet programs are becoming so complex that it is difficult for any book to satisfy such a diverse audience. Therefore, someone tends to suffer and, in this case, it's the new user.},
  review = 	 {fbie: rejected <2016-01-15 13:34:02>},
}

@inproceedings{Ozturk:2003:FCT:1030818.1031002,
  author =	 {Ozturk, Orkun and Coburn, Melissa Boom and
                  Kitterman, Steve},
  title =	 {Factory Capacity and Throughput Planning:
                  Conceptualization, Design and Implementation of a
                  Static Capacity Model},
  booktitle =	 {Proceedings of the 35th Conference on Winter
                  Simulation: Driving Innovation},
  series =	 {WSC '03},
  year =	 2003,
  isbn =	 {0-7803-8132-7},
  location =	 {New Orleans, Louisiana},
  pages =	 {1373--1376},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=1030818.1031002},
  acmid =	 1031002,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {This paper describes the methodology used for development of a static capacity model. It is a well-known fact that no matter how sophisticated the dynamic models are, there is always a need for the simple spreadsheet model. The spreadsheet model helps one carry out simple and fast analyses whenever they are needed. At the Seagate Technology's Recording Head Operations Wafer Manufacturing facility (Bloomington, MN) industrial engineers who worked on capacity planning devised their own versions of static spreadsheet models over the years. As useful as these individual models were, being highly custom-tailored and decentralized made them hard to cross-use and manage. To overcome this problem, the IE department designed and implemented a centralized spreadsheet based static capacity model with features that allow industrial engineers to create model outputs the way they want.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1031002&ftid=293356&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:07>},
}

@inproceedings{Diedriech:2008:ODC:1449956.1450056,
  author =	 {Diedriech, David A. and Martoglio, Karen},
  title =	 {Office 2007 at DePauw: A Campus-wide Rollout
                  Strategy},
  booktitle =	 {Proceedings of the 36th Annual ACM SIGUCCS Fall
                  Conference: Moving Mountains, Blazing Trails},
  series =	 {SIGUCCS '08},
  year =	 2008,
  isbn =	 {978-1-60558-074-6},
  location =	 {Portland, OR, USA},
  pages =	 {337--340},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1449956.1450056},
  doi =		 {10.1145/1449956.1450056},
  acmid =	 1450056,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {office, ribbon, strategy, upgrade},
  abstract = 	 {The transition from one version of any highly adopted productivity software to a new version within an institution is always a challenge. Productivity software application systems such as Microsoft Office are certainly not exempt from this. DePauw implemented Microsoft Office over 6 years ago and it has been universally adopted by faculty, staff members and students. We will examine the process in which DePauw University began the gradual process of upgrading everyone on campus to the newest releases of Office, for both Macintosh and PC users. Some of the topics to consider included: when to roll out the new versions; what staff members to include in the decision process and strategy sessions; delivery challenges; training and support; and the final timeline for deployment. First-year students that purchased program laptops this year from Dell had Office 2007 pre-installed on the computers. However, the rest of the student body, as well as the majority of faculty and staff members were still using Office 2003. Implementation, training, and support strategies all had to be readjusted to meet the needs of the campus. Today, Office 2003, 2004 and 2007 are all being used as students, staff and faculty members begin to make the transition to the new versions. By the fall of 2009, Office 2007/2008 will be the standard productivity tools at DePauw.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1450056&ftid=581762&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:11>},
}

@inproceedings{Bostrom:1988:IID:57216.57234,
  author =	 {Bostrom, R. P. and Olfman, L. and Sein, M. K.},
  title =	 {The Importance of Individual Differences in End-user
                  Training: The Case for Learning Style},
  booktitle =	 {Proceedings of the ACM SIGCPR Conference on
                  Management of Information Systems Personnel},
  series =	 {SIGCPR '88},
  year =	 1988,
  isbn =	 {0-89791-262-4},
  location =	 {College park, Maryland, USA},
  pages =	 {133--144},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/57216.57234},
  doi =		 {10.1145/57216.57234},
  acmid =	 57234,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The importance of effective training in ensuring the success of End-User Computing (EUC) has been emphasized by several researchers in MIS. A vast amount of evidence from research in such related areas as educational psychology suggest that individual differences, such as a novice end user's learning style may effect his/her learning of a new EUC software. This paper reports the findings of a series of studies that examined the influence of a novice's learning style in learning of typical EUC tools such as spreadsheets and electronic mail. A consistent pattern of findings emerged that indicate that learning style is an important predictor of learning performance, both by itself and in interaction with training methods. The findings suggest that in the design of training, it is essential to match training methods to individual difference variables. Based on these findings, guidelines are suggested for IS professional involved in EUC training.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=57234&ftid=9177&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:18>},
}

@inproceedings{Scaffidi:2007:DMS:1248821.1248948,
  author =	 {Scaffidi, Christopher},
  title =	 {A Data Model to Support End User Software
                  Engineering},
  booktitle =	 {Companion to the Proceedings of the 29th
                  International Conference on Software Engineering},
  series =	 {ICSE COMPANION '07},
  year =	 2007,
  isbn =	 {0-7695-2892-9},
  pages =	 {79--80},
  numpages =	 2,
  url =		 {http://dx.doi.org/10.1109/ICSECOMPANION.2007.11},
  doi =		 {10.1109/ICSECOMPANION.2007.11},
  acmid =	 1248948,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:34:19>},
}

@article{Manrique:1991:BRM:122459.1060551,
  note =	 {Reviewer-Manrique, Cecilia G.},
  title =	 {Book Review: 1-2-3 Macro Library (3rd Edition) by
                  David Paul Ewing (QUE Corporation 1990)},
  journal =	 {SIGSMALL/PC Notes},
  issue_date =	 {Spring 1991},
  volume =	 17,
  number =	 1,
  month =	 jun,
  year =	 1991,
  issn =	 {0893-2875},
  pages =	 {32--},
  url =		 {http://doi.acm.org/10.1145/122459.1060551},
  doi =		 {10.1145/122459.1060551},
  acmid =	 1060551,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This hefty 734-page book isolates a major feature of Lotus 1-2-3 which is the creation, development and use of MACROS as a tool to facilitate one's work with spreadsheets. Macros are especially useful when one realizes the number of repetitive keystrokes that can be reduced in a given work session if one only knew how and if the software package were capable of storing your keystrokes. Anymore now, most productivity packages whether they be wordprocessors, spreadsheets or databases come equipped with these keystroke-saving features called MACROS. Thus, learning how to make use of MACROS can certainly save the user a lot of keystrokes. However, one should already be proficient in the basics of spreadsheet operations before tackling this book. It assumes the reader already is well-versed in the various features of 1-2-3 and therefore does not even introduce how to create a macro in its first chapter.},
  review = 	 {fbie: rejected <2016-01-15 13:34:22>},
}

@inproceedings{Gardiner:2015:SSD:2745555.2746652,
  author =	 {Gardiner, Steven and Tomasic, Anthony and Zimmerman,
                  John},
  title =	 {SmartWrap: Seeing Datasets with the Crowd's Eyes},
  booktitle =	 {Proceedings of the 12th Web for All Conference},
  series =	 {W4A '15},
  year =	 2015,
  isbn =	 {978-1-4503-3342-9},
  location =	 {Florence, Italy},
  pages =	 {3:1--3:10},
  articleno =	 3,
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2745555.2746652},
  doi =		 {10.1145/2745555.2746652},
  acmid =	 2746652,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user programming, nonvisual accessibility,
                  semantic annotation, web annotation, wrapper
                  construction},
  abstract = 	 {The web contains many datasets presented visually, whose lack of semantic markup renders them difficult to understand and navigate using a screen reader. In this work, we explore the possibility of understanding the semantics of web datasets by asking sighted web users to manually scrape web pages into spreadsheets. Web users constitute a huge population of potential workers, but most are not programmers and may have difficulty understanding and communicating the abstractions involved in labeling web datasets. We present the design of a tool we call SmartWrap that directs the manual scraping work of everyday end users, explicitly including nonprogrammers, towards the construction of reusable programs, called wrappers, that map the scraped website into a structured dataset. To engage with nontechnical end users, we designed the tool to use very simple interactions. We present a user study validating that users with a variety of technical backgrounds were able to use it to construct wrappers. We also validate the SmartWrap approach to acquiring wrappers for a large part of the web by evaluating wrappers contributed by MTurk users using the tool. From the MTurk work we derive estimates for the costs of eliciting wrappers from the crowdworkers for a large proportion of the sampled datasets, and an estimate of what proportion of web datasets can be wrapped by crowdworkers using the tool. We also report some evidence that web users will contribute dataset semantics to the system without pay, motivated either to improve web accessibility or to expedite their own scraping tasks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2746652&ftid=1581857&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:26>},
}

@inproceedings{Martino:2013:SDL:2503512.2503527,
  author =	 {Martino, Jacquelyn and Bellamy, Rachel K. E. and
                  Matchen, Paul and Ossher, Harold L. and Richards,
                  John T. and Swart, Cal},
  title =	 {Sketching Data: Lessons Learned from a Formative
                  User Evaluation},
  booktitle =	 {ACM SIGGRAPH 2013 Mobile},
  series =	 {SIGGRAPH '13},
  year =	 2013,
  isbn =	 {978-1-4503-2341-3},
  location =	 {Anaheim, California},
  pages =	 {11:1--11:1},
  articleno =	 11,
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2503512.2503527},
  doi =		 {10.1145/2503512.2503527},
  acmid =	 2503527,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Mobile devices require new interaction approaches for working with data, as inputting numbers into a spreadsheet on a tablet is especially tedious. Last year we presented SketchGraph [Martino et al. 2012] for sketching data in a fluid manner (Fig. 1). Here, we discuss observations of usability based on a user study.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2503527&ftid=1382461&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:36>},
}

@article{Kuttal:2014:BPV:2592268.2560016,
  author =	 {Kuttal, Sandeep K. and Sarma, Anita and Rothermel,
                  Gregg},
  title =	 {On the Benefits of Providing Versioning Support for
                  End Users: An Empirical Study},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {February 2014},
  volume =	 21,
  number =	 2,
  month =	 feb,
  year =	 2014,
  issn =	 {1073-0516},
  pages =	 {9:1--9:43},
  articleno =	 9,
  numpages =	 43,
  url =		 {http://doi.acm.org/10.1145/2560016},
  doi =		 {10.1145/2560016},
  acmid =	 2560016,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {End-user software engineering, Mashups, Yahoo\&excl;
                  Pipes, debugging, programming barriers, reuse,
                  versioning},
  abstract = 	 {End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, and debug mashups. To investigate this belief, we have added versioning support to a popular wire-oriented mashup environment, Yahoo&excl; Pipes. Our enhanced environment, which we call “Pipes Plumber,” automatically retains versions of pipes and provides an interface with which pipe programmers can browse histories of pipes and retrieve specific versions. We have conducted two studies of this environment: an exploratory study and a larger controlled experiment. Our results provide evidence that versioning helps pipe programmers create and debug mashups. Subsequent qualitative results provide further insights into the barriers faced by pipe programmers, the support for reuse provided by our approach, and the support for debugging provided.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2560016&ftid=1437585&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:43>},
}

@inproceedings{Buxton:1995:SEW:224401.224755,
  author =	 {Buxton, Kenneth V. and Gatland, Robert},
  title =	 {Simulating the Effects of Work-in-process on
                  Customer Satisfaction in a Manufacturing
                  Environment},
  booktitle =	 {Proceedings of the 27th Conference on Winter
                  Simulation},
  series =	 {WSC '95},
  year =	 1995,
  isbn =	 {0-7803-3018-8},
  location =	 {Arlington, Virginia, USA},
  pages =	 {940--944},
  numpages =	 5,
  url =		 {http://dx.doi.org/10.1145/224401.224755},
  doi =		 {10.1145/224401.224755},
  acmid =	 224755,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:34:45>},
}

@inproceedings{Lorenzen:2006:TGU:1189215.1189171,
  author =	 {Lorenzen, Torben and Sattar, Abdul},
  title =	 {Teach Graphics Using Excel in Place of a Graphing
                  Calculator},
  booktitle =	 {Working Group Reports on ITiCSE on Innovation and
                  Technology in Computer Science Education},
  series =	 {ITiCSE-WGR '06},
  year =	 2006,
  isbn =	 {1-59593-603-3},
  location =	 {Bologna, Italy},
  pages =	 {61--63},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/1189215.1189171},
  doi =		 {10.1145/1189215.1189171},
  acmid =	 1189171,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Excel, graphics, graphing calculator, linear
                  algebra},
  abstract = 	 {Excel spreadsheets were developed to teach the underlying math in a computer graphics course including reviewing basic linear algebra operations, tracing a series of OpenGL transformations, and creating Bezier curves and surfaces with forward differences. Each spreadsheet contains an English overview of the mathematical process and the numerical result of each sub step thus providing a high level of abstraction. Double clicking a numerical result shows the underlying equation and operands used. The authors recommend using Excel in place of a graphing calculator in a computer graphics course.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1189171&ftid=393879&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:50>},
}

@article{Lorenzen:2006:TGU:1189136.1189171,
  author =	 {Lorenzen, Torben and Sattar, Abdul},
  title =	 {Teach Graphics Using Excel in Place of a Graphing
                  Calculator},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {December 2006},
  volume =	 38,
  number =	 4,
  month =	 jun,
  year =	 2006,
  issn =	 {0097-8418},
  pages =	 {61--63},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/1189136.1189171},
  doi =		 {10.1145/1189136.1189171},
  acmid =	 1189171,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Excel, graphics, graphing calculator, linear
                  algebra},
  abstract = 	 {Excel spreadsheets were developed to teach the underlying math in a computer graphics course including reviewing basic linear algebra operations, tracing a series of OpenGL transformations, and creating Bezier curves and surfaces with forward differences. Each spreadsheet contains an English overview of the mathematical process and the numerical result of each sub step thus providing a high level of abstraction. Double clicking a numerical result shows the underlying equation and operands used. The authors recommend using Excel in place of a graphing calculator in a computer graphics course.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1189171&ftid=393879&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:34:53>},
}

@inproceedings{Fu:2005:SOR:1162708.1162728,
  author =	 {Fu, Michael C. and Glover, Fred W. and April, Jay},
  title =	 {Simulation Optimization: A Review, New Developments,
                  and Applications},
  booktitle =	 {Proceedings of the 37th Conference on Winter
                  Simulation},
  series =	 {WSC '05},
  year =	 2005,
  isbn =	 {0-7803-9519-0},
  location =	 {Orlando, Florida},
  pages =	 {83--95},
  numpages =	 13,
  url =		 {http://dl.acm.org/citation.cfm?id=1162708.1162728},
  acmid =	 1162728,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {We provide a descriptive review of the main approaches for carrying out simulation optimization, and sample some recent algorithmic and theoretical developments in simulation optimization research. Then we survey some of the software available for simulation languages and spreadsheets, and present several illustrative applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1162728&ftid=378715&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:01>},
}

@inproceedings{Lunzer:2006:RCC:1166253.1166276,
  author =	 {Lunzer, Aran and Hornb{\ae}k, Kasper},
  title =	 {RecipeSheet: Creating, Combining and Controlling
                  Information Processors},
  booktitle =	 {Proceedings of the 19th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '06},
  year =	 2006,
  isbn =	 {1-59593-313-1},
  location =	 {Montreux, Switzerland},
  pages =	 {145--154},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1166253.1166276},
  doi =		 {10.1145/1166253.1166276},
  acmid =	 1166276,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user programming, information visualization,
                  personal information management, scientific workflow
                  systems, subjunctive interfaces},
  abstract = 	 {Many tasks require users to extract information from diverse sources, to edit or process this information locally, and to explore how the end results are affected by changes in the information or in its processing. We present the RecipeSheet, a general-purpose tool for assisting users in such tasks. The RecipeSheet lets users create information processors, called recipes, which may take input in a variety of forms such as text, Web pages, or XML, and produce results in a similar variety of forms. The processing carried out by a recipe may be specified using a macro or query language, of which we currently support Rexx, Smalltalk and XQuery, or by capturing the behaviour of a Web application or Web service. In the RecipeSheet's spreadsheet-inspired user interface, information appears in cells, with inter-cell dependencies defined by recipes rather than formulas. Users can also intervene manually to control which information flows through the dependency connections. Through a series of examples we illustrate how tasks that would be challenging in existing environments are supported by the RecipeSheet.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1166276&ftid=381897&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:17>},
}

@article{Delaney:1989:TSM:65294.65305,
  author =	 {Delaney, Michael M.},
  title =	 {Testing Student Micro Computer Skills Through Direct
                  Computer Use},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Feb. 1989},
  volume =	 21,
  number =	 1,
  month =	 feb,
  year =	 1989,
  issn =	 {0097-8418},
  pages =	 {103--107},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/65294.65305},
  doi =		 {10.1145/65294.65305},
  acmid =	 65305,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper introduces the concept of testing students' microcomputer skills through direct computer use. Techniques are discussed which make it feasible for the instructor to grade the disk and printout that are produced by each student. The process can be generally applied to testing many different skill areas, and has been effectively used for tests on DOS and utilities, wordprocessing, spreadsheet work, and data base. Practical examples of test creation and grading of spreadsheet tests are presented. Further developments of the technique are suggested.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=65305&ftid=12773&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:21>},
}

@inproceedings{Delaney:1989:TSM:65293.65305,
  author =	 {Delaney, Michael M.},
  title =	 {Testing Student Micro Computer Skills Through Direct
                  Computer Use},
  booktitle =	 {Proceedings of the Twentieth SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '89},
  year =	 1989,
  isbn =	 {0-89791-298-5},
  location =	 {Louisville, Kentucky, USA},
  pages =	 {103--107},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/65293.65305},
  doi =		 {10.1145/65293.65305},
  acmid =	 65305,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper introduces the concept of testing students' microcomputer skills through direct computer use. Techniques are discussed which make it feasible for the instructor to grade the disk and printout that are produced by each student. The process can be generally applied to testing many different skill areas, and has been effectively used for tests on DOS and utilities, wordprocessing, spreadsheet work, and data base. Practical examples of test creation and grading of spreadsheet tests are presented. Further developments of the technique are suggested.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=65305&ftid=12773&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 14:13:15>},
}

@inproceedings{Rosson:2005:EU:1094855.1094857,
  author =	 {Rosson, Mary Beth},
  title =	 {The End of Users},
  booktitle =	 {Companion to the 20th Annual ACM SIGPLAN Conference
                  on Object-oriented Programming, Systems, Languages,
                  and Applications},
  series =	 {OOPSLA '05},
  year =	 2005,
  isbn =	 {1-59593-193-7},
  location =	 {San Diego, CA, USA},
  pages =	 {3--3},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1094855.1094857},
  doi =		 {10.1145/1094855.1094857},
  acmid =	 1094857,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Over the past 20 years, user interface designers and usability engineers have studied and refined human-computer interaction techniques with the goal of improving people's productivity and experience. But the target of these efforts, "the end-user," is fast becoming a thing of the past. Many people now construct software on their own, building artifacts that range from email filters to spreadsheet simulations to interactive web applications. These individuals are use-developers: they build ad hoc solutions to everyday computing needs.Will use-developers help to resolve the software crisis? Given the right tools, people and groups may be able to rapidly develop custom solutions to many context-specific computing requirements, eliminating the wait for IT professionals to analyze and engineer a solution. Or are these individuals a danger to society? Use-developers are informal programmers with no training in software construction methods or computing paradigms. They have little intrinsic motivation to test their products for even basic concerns like correctness or safety. In this talk I argue that the transformation of end-user to use-developer is well underway and discuss the prospects for maximizing the benefits to society while addressing the risks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1094857&ftid=329638&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:34>},
}

@inproceedings{Martino:2012:SGD:2342896.2342926,
  author =	 {Martino, Jacquelyn and Matchen, Paul and Ossher,
                  Harold and Bellamy, Rachel and Swart, Cal},
  title =	 {SketchGraph: Gestural Data Input for Mobile Tablet
                  Devices},
  booktitle =	 {ACM SIGGRAPH 2012 Posters},
  series =	 {SIGGRAPH '12},
  year =	 2012,
  isbn =	 {978-1-4503-1682-8},
  location =	 {Los Angeles, California},
  pages =	 {23:1--23:1},
  articleno =	 23,
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2342896.2342926},
  doi =		 {10.1145/2342896.2342926},
  acmid =	 2342926,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {As tablets become ever more powerful and popular, people want to use them broadly, including for business applications like spreadsheet data graphing. Tablets are better suited to informal exploration through sketching, however, than to inputting data into a spreadsheet. It would be much more appealing, and suitable to the medium, to sketch a graph as if you were drawing on a napkin. We describe an early prototype to support a gestural, graphical interface for inputting and updating graph data that is as easy as drawing a few strokes. With it, users can focus on exploring their domain, rather than on the mechanics of data entry.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2342926&ftid=1269985&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:38>},
}

@article{Brady:1990:BRE:101317.1060435,
  note =	 {Reviewer-Brady, Michael J.},
  title =	 {Book Review: EXCEL TIPS, TRICKS, AND TRAPS by Ron
                  Person (Que, 1989)},
  journal =	 {SIGSMALL/PC Notes},
  issue_date =	 {Aug. 1990},
  volume =	 16,
  number =	 3,
  month =	 sep,
  year =	 1990,
  issn =	 {0893-2875},
  pages =	 {25--27},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/101317.1060435},
  doi =		 {10.1145/101317.1060435},
  acmid =	 1060435,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This "dictionary" for Excel users provides numerous examples of what the title promises. It assumes that the reader has at least a modest familiarity with the Microsoft Excel spreadsheet program; it will be of little interest to any others. The book is, essentially, a compendium of the kind of tips often found in the user-to-user and help columns in PC-oriented magazines.},
  review = 	 {fbie: rejected <2016-01-15 13:35:43>},
}

@inproceedings{Yancey:1984:GMB:800013.809507,
  author =	 {Yancey, David P. and Carringer, Robert A.},
  title =	 {Generalized Model Building Within an Integrated
                  Decision Support System},
  booktitle =	 {Proceedings of the 16th Conference on Winter
                  Simulation},
  series =	 {WSC '84},
  year =	 1984,
  location =	 {Dallas, TX},
  pages =	 {516--523},
  numpages =	 8,
  url =		 {http://dl.acm.org/citation.cfm?id=800013.809507},
  acmid =	 809507,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {This paper describes of a Generalized Model Builder (GMB) for use within a framework for integrating multiple analytic tools, operating from an integrated model database. This system provides a uniform interface for a variety of applications, including: simulation, optimization, financial analysis, steady-state network analysis, scheduling-balancing heuristics, and project planning. Graphical, prompt, and spreadsheet-like interfaces are described.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=809507&ftid=284846&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:35:47>},
}

@inproceedings{Hu:2004:PED:1014007.1014025,
  author =	 {Hu, Zhenjiang and Mu, Shin-Cheng and Takeichi,
                  Masato},
  title =	 {A Programmable Editor for Developing Structured
                  Documents Based on Bidirectional Transformations},
  booktitle =	 {Proceedings of the 2004 ACM SIGPLAN Symposium on
                  Partial Evaluation and Semantics-based Program
                  Manipulation},
  series =	 {PEPM '04},
  year =	 2004,
  isbn =	 {1-58113-835-0},
  location =	 {Verona, Italy},
  pages =	 {178--189},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1014007.1014025},
  doi =		 {10.1145/1014007.1014025},
  acmid =	 1014025,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {bidirectional transformation, document engineering,
                  editor, functional programming, view updating},
  abstract = 	 {This paper presents a novel editor supporting interactive refinement in the development of structured documents. The user performs a sequence of editing operations on the document view, and the editor automatically derives an efficient and reliable document source and a transformation that produces the document view. The editor is unique in its programmability, in the sense that the transformation can be obtained through editing operations. The main tricks behind are the utilization of the view-updating technique developed in the database community, and a new bidirectional transformation language that cannot only describe the relationship between the document source and its view, but also data dependency in the view.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1014025&ftid=273950&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:03>},
}

@inproceedings{Eyitayo:2011:SRI:2047594.2047668,
  author =	 {Eyitayo, Oduronke T.},
  title =	 {Do Students Have the Relevant ICT Skills They Need
                  to Do Their Research Projects},
  booktitle =	 {Proceedings of the 2011 Conference on Information
                  Technology Education},
  series =	 {SIGITE '11},
  year =	 2011,
  isbn =	 {978-1-4503-1017-8},
  location =	 {West Point, New York, USA},
  pages =	 {287--292},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2047594.2047668},
  doi =		 {10.1145/2047594.2047668},
  acmid =	 2047668,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ICT, IT education, computer skills, performance
                  measurement, proficiency},
  abstract = 	 {The final year research project is the capstone of undergraduate studies. Finding out the skills students have at final year helps determine how ready they are for their research projects as well as how prepared they are for the job market. In order to ascertain the Information Communication and Technology (ICT) literacy levels of students, a study was carried out using year four (final year) students across several faculties and departments in the University of Botswana using computer self efficacy instrument and Task characteristics. Prior to administering the questionnaire, a pilot test was conducted and reliabilty and validity tests were done. The data was analysed using SPSS. Chi-square and Cross Tabulation statistics were carried out. The results of the study revealed that students were lacking in skills needed specifically for academic research. Amongst others, the study recommends that the university should provide students with an IT fluency centre for individuals to concentrate on developing their skills. Workshops and demonstrations are recommended in which students can be given individual attention. A broader focus will be to incorporate technology into the curriculum of all courses and to improve the curriculum for the General Education Courses to include the desired skills.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2047668&ftid=1049102&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:07>},
}

@inproceedings{Haverkamp:1987:MMC:41866.41916,
  author =	 {Haverkamp, Allan},
  title =	 {Micros and Minis - Conflict Resolution},
  booktitle =	 {Proceedings of the 15th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '87},
  year =	 1987,
  isbn =	 {0-89791-241-1},
  location =	 {Kansas City, Missouri, USA},
  pages =	 {285--285},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/41866.41916},
  doi =		 {10.1145/41866.41916},
  acmid =	 41916,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Micro computers situated in micro computer labs and the desire of faculty to switch to using micro computers and micro-based packages as a tool for teaching is growing rapidly on campuses. This can have its advantages but also, from an economic as well as a practical point of view, is often loaded with disadvantages which can far outweigh the advantages of using a mini or mainframe computer.
This paper will focus on some of the advantages and disadvantages, both the obvious and the sometimes obscure, which surround the micro vs. mini or mainframe tool for teaching. From an economic standpoint the discussion will point out the costs of maintaining a micro lab on a cost per student basis taking into account not only the initial hardware and software costs, but also the cost of system administration and hardware maintenance. From a practical standpoint the discussion will point out what little differences there are between packages which can be used on a micro and similar packages that can be used on a mainframe and how easily a student can adapt to using a slightly different but similar-in-purpose package. While it is important that a student be taught how to use tools such as a fourth generation language and a spreadsheet package, that fourth generation language or spreadsheet package does not have to be the most popular package being used on micros. There are very good fourth generation packages and spreadsheet packages available for minis and mainframes.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=41916&ftid=13898&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:11>},
}

@article{Jones:2003:UAF:944746.944721,
  author =	 {Jones, Simon Peyton and Blackwell, Alan and Burnett,
                  Margaret},
  title =	 {A User-centred Approach to Functions in Excel},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {September 2003},
  volume =	 38,
  number =	 9,
  month =	 aug,
  year =	 2003,
  issn =	 {0362-1340},
  pages =	 {165--176},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/944746.944721},
  doi =		 {10.1145/944746.944721},
  acmid =	 944721,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We describe extensions to the Excel spreadsheet that integrate user-defined functions into the spreadsheet grid, rather than treating them as a "bolt-on". Our first objective was to bring the benefits of additional programming language features to a system that is often not recognised as a programming language. Second, in a project involving the evolution of a well-established language, compatibility with previous versions is a major issue, and maintaining this compatibility was our second objective. Third and most important, the commercial success of spreadsheets is largely due to the fact that many people find them more usable than programming languages for programming-like tasks. Thus, our third objective (with resulting constraints) was to maintain this usability advantage.Simply making Excel more like a conventional programming language would not meet these objectives and constraints. We have therefore taken an approach to our design work that emphasises the cognitive requirements of the user as a primary design criterion. The analytic approach that we demonstrate in this project is based on recent developments in the study of programming usability, including the Cognitive Dimensions of Notations and the Attention Investment model of abstraction use. We believe that this approach is also applicable to the design and extension of other programming languages and environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=944721&ftid=233102&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:36:16>},
}

@inproceedings{Jones:2003:UAF:944705.944721,
  author =	 {Jones, Simon Peyton and Blackwell, Alan and Burnett,
                  Margaret},
  title =	 {A User-centred Approach to Functions in Excel},
  booktitle =	 {Proceedings of the Eighth ACM SIGPLAN International
                  Conference on Functional Programming},
  series =	 {ICFP '03},
  year =	 2003,
  isbn =	 {1-58113-756-7},
  location =	 {Uppsala, Sweden},
  pages =	 {165--176},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/944705.944721},
  doi =		 {10.1145/944705.944721},
  acmid =	 944721,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We describe extensions to the Excel spreadsheet that integrate user-defined functions into the spreadsheet grid, rather than treating them as a "bolt-on". Our first objective was to bring the benefits of additional programming language features to a system that is often not recognised as a programming language. Second, in a project involving the evolution of a well-established language, compatibility with previous versions is a major issue, and maintaining this compatibility was our second objective. Third and most important, the commercial success of spreadsheets is largely due to the fact that many people find them more usable than programming languages for programming-like tasks. Thus, our third objective (with resulting constraints) was to maintain this usability advantage.Simply making Excel more like a conventional programming language would not meet these objectives and constraints. We have therefore taken an approach to our design work that emphasises the cognitive requirements of the user as a primary design criterion. The analytic approach that we demonstrate in this project is based on recent developments in the study of programming usability, including the Cognitive Dimensions of Notations and the Attention Investment model of abstraction use. We believe that this approach is also applicable to the design and extension of other programming languages and environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=944721&ftid=233102&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: accepted <2016-01-15 13:36:19>},
}

@inproceedings{Adelfio:2014:IRT:2675354.2675355,
  author =	 {Adelfio, Marco D. and Samet, Hanan},
  title =	 {Itinerary Retrieval: Travelers, Like Traveling
                  Salesmen, Prefer Efficient Routes},
  booktitle =	 {Proceedings of the 8th Workshop on Geographic
                  Information Retrieval},
  series =	 {GIR '14},
  year =	 2014,
  isbn =	 {978-1-4503-3135-7},
  location =	 {Dallas, Texas},
  pages =	 {1:1--1:8},
  articleno =	 1,
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2675354.2675355},
  doi =		 {10.1145/2675354.2675355},
  acmid =	 2675355,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {route efficiency, trajectory retrieval, travel
                  itineraries},
  abstract = 	 {Internet users share large quantities of text and multimedia content that becomes easily accessible to others via hyperlinks and search engine results. However, structured datasets generally lack this level of exposure. One example is the travel itinerary, which many Internet users post online in the form of a spreadsheet or web page table, yet the collection of such itineraries remains difficult to search or browse due to insufficient parsing and indexing by search engines. Enabling interaction with user-uploaded itineraries could provide valuable information to trip planners who are researching travel options and to businesses attempting to understand travel patterns. This work examines the challenges of identifying and extracting itineraries from spreadsheets and web page tables to support such applications, with a focus on differentiating between itineraries and other documents with geographic content.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2675355&ftid=1531157&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:26>},
}

@inproceedings{Fischer:2014:PMA:2616606.2616848,
  author =	 {Fischer, Bernhard and Cech, Christian and Muhr,
                  Hannes},
  title =	 {Power Modeling and Analysis in Early Design Phases},
  booktitle =	 {Proceedings of the Conference on Design, Automation
                  \& Test in Europe},
  series =	 {DATE '14},
  year =	 2014,
  isbn =	 {978-3-9815370-2-4},
  location =	 {Dresden, Germany},
  pages =	 {197:1--197:6},
  articleno =	 197,
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=2616606.2616848},
  acmid =	 2616848,
  publisher =	 {European Design and Automation Association},
  address =	 {3001 Leuven, Belgium, Belgium},
  keywords =	 {comparison, early design phase, electronic system
                  level, industrial use case, power analysis, power
                  modeling},
  abstract = 	 {Low power consumption of electronic devices has been an important requirement for many cyber-physical systems in field. Today, power dissipation is often estimated by spreadsheet-based power analysis. A leading-edge high-level power analysis method has the objective of providing high confidence levels in early design stages, where power design decisions have severe impact. This work examines and compares three high-level power analysis approaches (spreadsheet-based, Synopsys Platform Architect MCO, and DOCEA Aceplorer) by an industrial use case. The first chapter introduces into general power analysis concepts. Chapter two presents different power analysis methods and tools that are applied on an industrial signal-processing use case described in chapter three. Chapter four compares these tools and methods by selected criteria such as power modeling effort and quality of results. Chapter five concludes about the investigated methods.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2616848&ftid=1456892&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:30>},
}

@article{Clarke:1988:MOC:52965.53021,
  author =	 {Clarke, Alice L. and Adkins, Gerald W.},
  title =	 {A Microcomputer Oriented Computer Literacy Course},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Feb. 1988},
  volume =	 20,
  number =	 1,
  month =	 feb,
  year =	 1988,
  issn =	 {0097-8418},
  pages =	 {225--229},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/52965.53021},
  doi =		 {10.1145/52965.53021},
  acmid =	 53021,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The development of a computer literacy course at the University of Georgia is described. Demographic information regarding students taking the class is provided. The course consists of two main parts:
1) microcomputer lab sessions devoted to working with word processing, spreadsheet, and data base software and to programming in BASIC; and
2) readings in a course text and viewing of telecourse tapes.
Course content and testing procedures are described in detail. How the course is changing with time and experience is also discussed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=53021&ftid=13296&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:37>},
}

@inproceedings{Clarke:1988:MOC:52964.53021,
  author =	 {Clarke, Alice L. and Adkins, Gerald W.},
  title =	 {A Microcomputer Oriented Computer Literacy Course},
  booktitle =	 {Proceedings of the Nineteenth SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '88},
  year =	 1988,
  isbn =	 {0-89791-256-X},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {225--229},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/52964.53021},
  doi =		 {10.1145/52964.53021},
  acmid =	 53021,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The development of a computer literacy course at the University of Georgia is described. Demographic information regarding students taking the class is provided. The course consists of two main parts:
1) microcomputer lab sessions devoted to working with word processing, spreadsheet, and data base software and to programming in BASIC; and
2) readings in a course text and viewing of telecourse tapes.
Course content and testing procedures are described in detail. How the course is changing with time and experience is also discussed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=53021&ftid=13296&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:40>},
}

@inproceedings{Yeo:2001:GDL:365024.365060,
  author =	 {Yeo, Alvin W.},
  title =	 {Global-software Development Lifecycle: An
                  Exploratory Study},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '01},
  year =	 2001,
  isbn =	 {1-58113-327-8},
  location =	 {Seattle, Washington, USA},
  pages =	 {104--111},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/365024.365060},
  doi =		 {10.1145/365024.365060},
  acmid =	 365060,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Hoftede's cultural dimensions, global-software
                  development, internationalisation, localisation,
                  usability evaluation},
  abstract = 	 {This study was conducted to explore the efficacy of the global-software development lifecycle (global-SDLC), which comprises design, implementation and usability evaluation phase. A spreadsheet was adapted using the global-SDLC process to accommodate a number of cultures. The design and implementation phases were efficacious. However, in the usability evaluation phase, the usability evaluation techniques were only efficacious when participants, who were experienced computer users and participants who were familiar with the experimenter, were employed. Explanations, from cultural literature such as Hofstede, are presented and implications of these findings on the usability evaluation phase and the global-SDLC are also described.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=365060&ftid=49309&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:47>},
}

@inproceedings{Melton:2001:AMU:564124.564261,
  author =	 {Melton, Ryan Heath and Culbreth, C. Thomas and
                  Roberts, Stephen D. and Joines, Jeffrey A.},
  title =	 {Automation in Modeling: Using Automation for
                  Finishing Room Capacity Planning},
  booktitle =	 {Proceedings of the 33Nd Conference on Winter
                  Simulation},
  series =	 {WSC '01},
  year =	 2001,
  isbn =	 {0-7803-7309-X},
  location =	 {Arlington, Virginia},
  pages =	 {959--967},
  numpages =	 9,
  url =		 {http://dl.acm.org/citation.cfm?id=564124.564261},
  acmid =	 564261,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  abstract = 	 {Capacity planning of a furniture finishing system using both deterministic analysis and stochastic simulation is conveniently performed with the aid ActiveX Automation. Users interactively build a complete model of a finishing system with an Excel interface, which creates a deterministic model. The spreadsheet de-couples data input from the simulation model construction and execution, and provides a user-friendly tool for analyzing a finishing system. Using the spreadsheet, simulation data is provided to the deterministic model, and an Arena simulation model and animation of individual finishing line operations is constructed through ActiveX automation. A manufacturing manager unfamiliar with modeling techniques can use the interface to plan the finishing system and conduct simulation experiments with various input parameters such as line loading techniques, operations balancing, and line speeds. Through the interface, results from the simulation can be used in an iterative process to analyze and refine design parameters of the finishing line.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=564261&ftid=85208&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:51>},
}

@article{Dyck:1987:BTC:31726.31814,
  author =	 {Dyck, V. Arnie and Black, James P. and Fenton,
                  Shirley L.},
  title =	 {Beyond Traditional Computer Literacy},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Feb. 1987},
  volume =	 19,
  number =	 1,
  month =	 feb,
  year =	 1987,
  issn =	 {0097-8418},
  pages =	 {508--512},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/31726.31814},
  doi =		 {10.1145/31726.31814},
  acmid =	 31814,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A new approach to computer literacy is emerging, an approach that de-emphasizes the traditional overview of hardware and software and minimizes the teaching of traditional programming methodology. This paper describes the design and implementation of a literacy course intended to develop effective users of common applications software, including word processing, spreadsheets, graphics and database management. The paper continues by demonstrating how many academic computer science concepts can be effectively introduced using this approach.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=31814&ftid=16151&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:56>},
}

@inproceedings{Dyck:1987:BTC:31820.31814,
  author =	 {Dyck, V. Arnie and Black, James P. and Fenton,
                  Shirley L.},
  title =	 {Beyond Traditional Computer Literacy},
  booktitle =	 {Proceedings of the Eighteenth SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '87},
  year =	 1987,
  isbn =	 {0-89791-217-9},
  location =	 {St. Louis, Missouri, USA},
  pages =	 {508--512},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/31820.31814},
  doi =		 {10.1145/31820.31814},
  acmid =	 31814,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A new approach to computer literacy is emerging, an approach that de-emphasizes the traditional overview of hardware and software and minimizes the teaching of traditional programming methodology. This paper describes the design and implementation of a literacy course intended to develop effective users of common applications software, including word processing, spreadsheets, graphics and database management. The paper continues by demonstrating how many academic computer science concepts can be effectively introduced using this approach.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=31814&ftid=16151&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:36:59>},
}

@inproceedings{Mentzelou:2009:PSP:1836029.1836034,
  author =	 {Mentzelou, Paraskevi},
  title =	 {The Presentation of a Simple and Practical ROI Model
                  for the e-Learning Process},
  booktitle =	 {Proceedings of the First Kuwait Conference on
                  e-Services and e-Systems},
  series =	 {eConf '09},
  year =	 2009,
  isbn =	 {978-1-60558-797-4},
  location =	 {Kuwait},
  pages =	 {5:1--5:6},
  articleno =	 5,
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1836029.1836034},
  doi =		 {10.1145/1836029.1836034},
  acmid =	 1836034,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ROI, application packages, e-learning, information
                  communication technology (ICT), model development},
  abstract = 	 {Information and Communication Technology (ICT) offers in the learning process individual teaching approaches, knowledge gain in any place or time of individual preference, the ability to study a large number of subjects, the power to students and adults to control their learning process and finally the ability to gain knowledge on a number of subjects which through the traditional ways is impossible. All these factors make eLearning an attractive learning approach. This approach has been welcomed from the educational community, industry, commerce and from the community in general. A number of approaches for measuring learning systems cost-effectiveness through quantitative methods are used but this is not enough as learning represents a value by itself and this should be measured too. This study deals with the presentation of a simple and practical ROI model for the e-Learning process in an organisation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1836034&ftid=827826&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:04>},
}

@inproceedings{Huang:1986:QDI:317559.322753,
  author =	 {Huang, Kuan-Tsae and Bolmarcich, Anthony and Katz,
                  Steven and Li, Richard},
  title =	 {QBE/PC: The Design of an Integrated Software System
                  for a Personal Computer},
  booktitle =	 {Proceedings of the 1986 ACM SIGSMALL/PC Symposium on
                  Small Systems},
  series =	 {SIGSMALL '86},
  year =	 1986,
  isbn =	 {0-89791-211-X},
  location =	 {San Francisco, California, USA},
  pages =	 {92--100},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/317559.322753},
  doi =		 {10.1145/317559.322753},
  acmid =	 322753,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Integrated software has become rather popular in recent years. After the spreadsheet found wide acceptance among application users, many vendors rushed to integrate several well-defined business application tasks within a spreadsheet environment. Such systems, however, are limited in that they cannot replace a conventional database. Businesses must keep data in a formal database to maintain data consistency and facilitate sharing. This paper describes the design and implementation of an integrated software system which captures the ease-of-use of many of the current integrated systems, and also provides a relational database for common data storage, allowing for data sharing among several integrated business applications. In addition, the system provides an unusually powerful visual interface which can be used to build custom applications without the need for traditional programming.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=322753&ftid=13250&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:10>},
}

@inproceedings{Savage:2006:IS:1218112.1218536,
  author =	 {Savage, Sam},
  title =	 {Interactive Simulation},
  booktitle =	 {Proceedings of the 38th Conference on Winter
                  Simulation},
  series =	 {WSC '06},
  year =	 2006,
  isbn =	 {1-4244-0501-7},
  location =	 {Monterey, California},
  pages =	 {2293--2293},
  numpages =	 1,
  url =		 {http://dl.acm.org/citation.cfm?id=1218112.1218536},
  acmid =	 1218536,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {A new generation of software performs Monte Carlo simulation nearly instantaneously on arbitrary spreadsheet models. In effect, it does for probability distributions what the spreadsheet did for numbers. In addition, the concept of a Stochastic Information System is introduced, in which distributions are stored as realizations of a stochastic process. A single variable is stored as a Stochastic Information Packet (SIP), a multivariate distribution as a Stochastic Library Unit, Relationships Preserved (SLURP). This leads to the Fundamental Equality of SLURP algebra: P(F(x, y)) = F(P(x, y)) where x and y are random variables, P(x, y) is the SLURP representing their joint distribution, and F is a function of x and y. Live computer demonstrations will include distribution arithmetic, the Flaw of Averages, a retirement simulation developed for a New York trust company, and interactive portfolio model used at a major petroleum firm.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1218536&ftid=399462&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:13>},
}

@inproceedings{Grier:1987:SMC:318371.318630,
  author =	 {Grier, David Alan},
  title =	 {Systems for Monte Carlo Work},
  booktitle =	 {Proceedings of the 19th Conference on Winter
                  Simulation},
  series =	 {WSC '87},
  year =	 1987,
  isbn =	 {0-911801-32-4},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {428--433},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/318371.318630},
  doi =		 {10.1145/318371.318630},
  acmid =	 318630,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {With the proliferation of computers has come a proliferation of simulation. Monte Carlo experiments can now be run by a vast range of programs from simple. Basic environments to spreadsheets: yet little attention has been paid to the problem of designing a system to do Monte Carlo problems. The ideas for a system described in this paper not only simplifies the problem of programming a Monte Carlo experiment but also attempts to maintain standards of experimental design and to encourage careful analysis.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318630&ftid=9473&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:17>},
}

@inproceedings{Prabhakar:2002:BVM:506443.506604,
  author =	 {Prabhakar, Sandeep and Conklin, Nathan and North,
                  Chris and Thirunavukkarasu, Muthukumar and
                  Dandapani, Anusha and Panchanathan, Ganesh},
  title =	 {Breakdown Visualization: Multiple Foci Polyarchies
                  of Values and Attributes},
  booktitle =	 {CHI '02 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '02},
  year =	 2002,
  isbn =	 {1-58113-454-1},
  location =	 {Minneapolis, Minnesota, USA},
  pages =	 {800--801},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/506443.506604},
  doi =		 {10.1145/506443.506604},
  acmid =	 506604,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {breakdown, financial visualization, multiple foci,
                  polyarchy structure, visual decomposition,
                  visualization},
  abstract = 	 {Breakdown analysis involves decomposing data into sub-groups to allow for comparison and identification of problem areas. Good analysis requires the ability to group data based on attributes or values. Breakdown Visualization provides a mechanism to support this analysis through user guided decomposition and exploration of tabular data with a polyarchy structure. This is useful in domains such as sports statistics and corporate financial reports. Breakdown Visualization utilizes a spreadsheet format for comparison of adjacent visualizations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=506604&ftid=75108&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:22>},
}

@inproceedings{Charnes:2000:OPU:510378.510404,
  author =	 {Charnes, John M.},
  title =	 {Options Pricing: Using Simulation for Option
                  Pricing},
  booktitle =	 {Proceedings of the 32Nd Conference on Winter
                  Simulation},
  series =	 {WSC '00},
  year =	 2000,
  isbn =	 {0-7803-6582-8},
  location =	 {Orlando, Florida},
  pages =	 {151--157},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=510378.510404},
  acmid =	 510404,
  publisher =	 {Society for Computer Simulation International},
  address =	 {San Diego, CA, USA},
  abstract = 	 {Monte Carlo simulation is a popular method for pricing financial options and other derivative securities because of the availability of powerful workstations and recent advances in applying the tool. The existence of easy-to-use software makes simulation accessible to many users who would otherwise avoid programming the algorithms necessary to value derivative securities. This paper presents examples of option pricing and variance reduction, and demonstrates their implementation with Crystal Ball 2000, a spreadsheet simulation add-in program.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=510404&ftid=77490&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:27>},
}

@article{Smith:2000:RTT:570440.570503,
  author =	 {Smith, Adrian},
  title =	 {Redistribution of Totals Through Hierarchical Data:
                  An Application of Benkard's Distributed Round},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {June 2000},
  volume =	 30,
  number =	 4,
  month =	 jun,
  year =	 2000,
  issn =	 {0163-6006},
  pages =	 {212--218},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/570440.570503},
  doi =		 {10.1145/570440.570503},
  acmid =	 570503,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The early days of APL are full of examples of spreadsheet-style applications which allow the user to maintain aggregated values and quickly redistribute the changes across base data. Generally these use a simple pro-rata approach which always leads to rounding problems where the adjusted values no longer sum to the required total.The example discussed in this paper was developed for the Strategic Planning manager at NestlÉ-Rowntree and a key requirement was to permit rebalancing of adjusted totals throughout an arbitrarily deep tree-structure. In this case a simple pro-rata leads to endless imbalances, and the trick is to use Benkard's distributed rounding which ensures that when changes to aggregates are redistributed, the detail always adds exactly to the required total.The concept is illustrated using the VideoSoft Flexgrid OCX control. The Flexgrid was used here because it has a very simple and powerful approach to managing gridded data where one of the dimensions has an outline structure.},
  review = 	 {fbie: rejected <2016-01-15 13:37:31>},
}

@inproceedings{Smith:2000:RTT:570475.570503,
  author =	 {Smith, Adrian},
  title =	 {Redistribution of Totals Through Hierarchical Data:
                  An Application of Benkard's Distributed Round},
  booktitle =	 {Proceedings of the International Conference on
                  APL-Berlin-2000 Conference},
  series =	 {APL '00},
  year =	 2000,
  isbn =	 {1-58113-182-8},
  location =	 {Berlin, Germany},
  pages =	 {212--218},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/570475.570503},
  doi =		 {10.1145/570475.570503},
  acmid =	 570503,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The early days of APL are full of examples of spreadsheet-style applications which allow the user to maintain aggregated values and quickly redistribute the changes across base data. Generally these use a simple pro-rata approach which always leads to rounding problems where the adjusted values no longer sum to the required total.The example discussed in this paper was developed for the Strategic Planning manager at NestlÉ-Rowntree and a key requirement was to permit rebalancing of adjusted totals throughout an arbitrarily deep tree-structure. In this case a simple pro-rata leads to endless imbalances, and the trick is to use Benkard's distributed rounding which ensures that when changes to aggregates are redistributed, the detail always adds exactly to the required total.The concept is illustrated using the VideoSoft Flexgrid OCX control. The Flexgrid was used here because it has a very simple and powerful approach to managing gridded data where one of the dimensions has an outline structure.},
  review = 	 {fbie: rejected <2016-01-15 13:37:34>},
}

@inproceedings{Hammond:1995:SAB:224401.224776,
  author =	 {Hammond, Donald and Mahesh, Sathi},
  title =	 {A Simulation and Analysis of Bank Teller Manning},
  booktitle =	 {Proceedings of the 27th Conference on Winter
                  Simulation},
  series =	 {WSC '95},
  year =	 1995,
  isbn =	 {0-7803-3018-8},
  location =	 {Arlington, Virginia, USA},
  pages =	 {1077--1080},
  numpages =	 4,
  url =		 {http://dx.doi.org/10.1145/224401.224776},
  doi =		 {10.1145/224401.224776},
  acmid =	 224776,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:37:35>},
}

@inproceedings{Koitzsch:2011:IVM:2431518.2431758,
  author =	 {Koitzsch, Matthias and Noll, Humbert and Nemecek,
                  Alexander and Merhof, Jochen and Michl, Markus and
                  Honold, Alfred and Kleineidam, Gerhard and Lebrecht,
                  Holger},
  title =	 {Implementing Virtual Metrology into Semiconductor
                  Production Processes: An Investment Assessment},
  booktitle =	 {Proceedings of the Winter Simulation Conference},
  series =	 {WSC '11},
  year =	 2011,
  location =	 {Phoenix, Arizona},
  pages =	 {2022--2033},
  numpages =	 12,
  url =		 {http://dl.acm.org/citation.cfm?id=2431518.2431758},
  acmid =	 2431758,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Continuously increasing complexity of semiconductor manufacturing processes drives the need for wafer to wafer and even within wafer control loops metrology. Applying Virtual Metrology (VM) techniques is one promising approach to reduce the time between process, measurement and corrective actions. Prior to implementation -- besides technical aspects like testing -- the investment into VM has to be assessed and justified on the basis of reliable and reasonable data. This paper presents the investment assessment for implementing VM algorithms into plasma etcher tools of a model semiconductor fabrication line. Core of the investment calculation is a spreadsheet-based calculation which allows for a results per quarter evaluation. A Discrete Event Simulation (DES) model was developed to produce relevant input data for the spreadsheet calculation. Potential risks -- e.g., delivery of wrong VM results -- due to the implementation of VM have been identified and evaluated using the standardized method of Failure Mode and Effects Analysis (FMEA).},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2431758&ftid=1338423&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:41>},
}

@inproceedings{Hedegaard:2013:EUU:2470654.2481286,
  author =	 {Hedegaard, Steffen and Simonsen, Jakob Grue},
  title =	 {Extracting Usability and User Experience Information
                  from Online User Reviews},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '13},
  year =	 2013,
  isbn =	 {978-1-4503-1899-0},
  location =	 {Paris, France},
  pages =	 {2089--2098},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2470654.2481286},
  doi =		 {10.1145/2470654.2481286},
  acmid =	 2481286,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {end user reviews, machine learning, natural language
                  processing, usability, user experience},
  abstract = 	 {Internet review sites allow consumers to write detailed reviews of products potentially containing information related to user experience (UX) and usability. Using 5198 sentences from 3492 online reviews of software and video games, we investigate the content of online reviews with the aims of (i) charting the distribution of information in reviews among different dimensions of usability and UX, and (ii) extracting an associated vocabulary for each dimension using techniques from natural language processing and machine learning. We (a) find that 13\%-49\% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions. Our results suggest that a greater understanding of users' preoccupation with different dimensions of usability and UX may be inferred from the large volume of self-reported experiences online, and that research focused on identifying pertinent dimensions of usability and UX may benefit further from empirical studies of user-generated experience reports.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2481286&ftid=1368372&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:47>},
}

@inproceedings{Jenkins:1984:SSW:800019.800605,
  author =	 {Jenkins, Susan},
  title =	 {The Software Sampler Workshop: Intermediate Training
                  for University Microcomputer Users},
  booktitle =	 {Proceedings of the 12th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '84},
  year =	 1984,
  isbn =	 {0-89791-146-6},
  location =	 {Reno, Nevada, USA},
  pages =	 {185--187},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/800019.800605},
  doi =		 {10.1145/800019.800605},
  acmid =	 800605,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The acquisition of microcomputers has changed the nature of user support at the Ohio State University. The pioneer micro users of a few years ago primarily desired assistance in these areas: • introductory terminology, “computerese” vocabulary; • setting up their new systems; • communicating with the mainframes on campus. As users gained experience on their systems, training demands evolved. Now micro users want training in the “big three,” word processing, data base management, and electronic spreadsheets. In this paper, I shall examine this evolution in training support. What is taught, including a basic outline of objectives, and specific examples of materials, will be discussed. Finally, a plan for administration will be given.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=800605&ftid=57818&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:51>},
}

@article{Cohen:1991:CTA:126729.1056061,
  author =	 {Cohen, Maxine S. and Payne, David G. and Pastore,
                  Richard E.},
  title =	 {COMPUTERIZED TASK ANALYSIS},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {Oct. 1991},
  volume =	 23,
  number =	 4,
  month =	 oct,
  year =	 1991,
  issn =	 {0736-6906},
  pages =	 {57--58},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/126729.1056061},
  doi =		 {10.1145/126729.1056061},
  acmid =	 1056061,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We developed an integrated computer-based procedure for conducting task analyses of the human-machine interface. The data base established with this task analysis methodology can be used by various system designers to answer questions at different levels (e.g., assessing individual keystrokes vs. overall mental workload levels) and as the system moves through the design stage. Our methodology is based upon the use of conventional task analysis procedures for data collection purposes but employs computer spreadsheet capabilities for analyzing and presenting these data.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1056061&ftid=310102&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:37:55>},
}

@inproceedings{Liu:2005:EMC:1096601.1096616,
  author =	 {Liu, Dongxi and Hu, Zhenjiang and Takeichi, Masato},
  title =	 {An Environment for Maintaining Computation
                  Dependency in XML Documents},
  booktitle =	 {Proceedings of the 2005 ACM Symposium on Document
                  Engineering},
  series =	 {DocEng '05},
  year =	 2005,
  isbn =	 {1-59593-240-2},
  location =	 {Bristol, United Kingdom},
  pages =	 {42--51},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1096601.1096616},
  doi =		 {10.1145/1096601.1096616},
  acmid =	 1096616,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {XML, computation dependency, functional programming,
                  lazy evaluation, programmable structured document},
  abstract = 	 {In the domain of XML authoring, there have been many tools to help users to edit XML documents. These tools make it easier to produce complex documents by using such technologies as syntax-directed or presentation-oriented editing, etc. However, when an XML document contains data with some computation dependency among them, these tools cannot free users from the burden of maintaining this dependency relationship. By computation dependency, we mean that some data are gotten by computing from other data in the same document.In this paper, we present an environment for authoring XML document, in which users can express the data dependency relationship in one document explicitly rather than implicitly in their minds. Under this environment, the dependent parts of the document are represented as expressions, which in turn can be evaluated to generate the dependent data. Therefore, users need not to compute the dependent data first and then input them manually, as required by the current authoring tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1096616&ftid=334548&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:00>},
}

@inproceedings{Rieman:1992:VVS:142750.142902,
  author =	 {Rieman, John and Davies, Susan and Roberts,
                  Jonathan},
  title =	 {A Visit to a Very Small Database: Lessons from
                  Managing the Review of Papers Submitted for CHI'91},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '92},
  year =	 1992,
  isbn =	 {0-89791-513-5},
  location =	 {Monterey, California, USA},
  pages =	 {471--478},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/142750.142902},
  doi =		 {10.1145/142750.142902},
  acmid =	 142902,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {databases, design methodologies, small systems},
  abstract = 	 {Many of the principles that guide user-interface design for commercial systems do not scale down to simple applications developed on personal computers. These “very small systems” are typicaly designed within a high-level application such as a database or a spreadsheet. The entire development process may take no more than a few days. In this restricted context, iterative design and usability testing are unaffordable luxuries, while detailed task analysis and early focus on users fail because the task and users will not coalesce until the system is in place. We describe our experiences with developing and using a very small sytem. We present suggestions for successful design in similar situations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=142902&ftid=18028&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:08>},
}

@article{Kokol:1990:APD:101317.101319,
  author =	 {Kokol, P.},
  title =	 {Automatic Program Development Using PIA-CASE Tool},
  journal =	 {SIGSMALL/PC Notes},
  issue_date =	 {Aug. 1990},
  volume =	 16,
  number =	 3,
  month =	 sep,
  year =	 1990,
  issn =	 {0893-2875},
  pages =	 {8--21},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/101317.101319},
  doi =		 {10.1145/101317.101319},
  acmid =	 101319,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The PIA - CASE tool supports the PIA (Provisional Implementation Approach) which is a specific reduction of the Extended Operational Paradigm (EOP). EOP is based on the M3UO framework which takes into account Multidimensional, Multiview and Multilingual aspects of the information system development process and realizable ideas of operational prototyping and transformational paradigms. The PIA CASE tool is a continuation of the JSP Tutor and transforms the JSP operational specification expressed graphically by JSP structure diagrams and textually with newly developed Pointer-Less Array-Less Oriented Language (PLALOL) into spreadsheet and macros.},
  review = 	 {fbie: rejected <2016-01-15 13:38:16>},
}

@inproceedings{Yamanaka:2013:NTI:2508468.2514927,
  author =	 {Yamanaka, Shota and Miyashita, Homei},
  title =	 {The Nudging Technique: Input Method Without
                  Fine-grained Pointing by Pushing a Segment},
  booktitle =	 {Proceedings of the Adjunct Publication of the 26th
                  Annual ACM Symposium on User Interface Software and
                  Technology},
  series =	 {UIST '13 Adjunct},
  year =	 2013,
  isbn =	 {978-1-4503-2406-9},
  location =	 {St. Andrews, Scotland, United Kingdom},
  pages =	 {3--4},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2508468.2514927},
  doi =		 {10.1145/2508468.2514927},
  acmid =	 2514927,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {drag-and-drop, graphical user interfaces (guis),
                  mouse cursor operation., nudging technique, pointing
                  technique},
  abstract = 	 {The Nudging Technique is a new manipulation paradigm for GUIs. With traditional techniques, the user sometimes has to perform a fine-grained operation (e.g., pointing at the edge of a window to resize). When the user makes a mistake in the pointing, problems may arise such as an accidental switching of the foreground window. The nudging technique relieves the user from the fine pointing before dragging; the user just moves the cursor to a target then pushes it. Visual and acoustic feedbacks also help the user's operation. We describe two application examples: window resizing and spreadsheet cell resizing systems.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2514927&ftid=1404194&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:20>},
}

@inproceedings{Ahnn:2008:ULD:1462735.1462752,
  author =	 {Ahnn, Jong Hoon and Birman, Ken and Ostrowski,
                  Krzysztof and Van Renesse, Robbert},
  title =	 {Using Live Distributed Objects for Office
                  Automation: Demo Proposal},
  booktitle =	 {Proceedings of the ACM/IFIP/USENIX Middleware '08
                  Conference Companion},
  series =	 {Companion '08},
  year =	 2008,
  isbn =	 {978-1-60558-369-3},
  location =	 {Leuven, Belgium},
  pages =	 {70--73},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1462735.1462752},
  doi =		 {10.1145/1462735.1462752},
  acmid =	 1462752,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SOA, distributed systems, live distributed objects,
                  middleware, office automation},
  abstract = 	 {Web services and platforms such as .NET make it easy to integrate interactive end-user applications with backend services. However, it remains hard to build collaborative applications in which information is shared within teams. We present a new drag-and-drop technology, in which standard office documents (spreadsheets, databases, etc.) are interconnected with eventdriven middleware ("live distributed objects"), to create distributed applications in which changes to underlying data propagate quickly to downstream applications. Information is replicated in a consistent manner, making it easy for team members to share updates and to coordinate their actions. In this demo, we present our middleware platform in office automation settings which is highly automated and highly configurable.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1462752&ftid=589686&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:26>},
}

@inproceedings{Workman:2000:SDD:510378.510669,
  author =	 {Workman, Russell W.},
  title =	 {Simulation of the Drug Development Process: A Case
                  Study from the Pharmaceutical Industry},
  booktitle =	 {Proceedings of the 32Nd Conference on Winter
                  Simulation},
  series =	 {WSC '00},
  year =	 2000,
  isbn =	 {0-7803-6582-8},
  location =	 {Orlando, Florida},
  pages =	 {1995--1998},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=510378.510669},
  acmid =	 510669,
  publisher =	 {Society for Computer Simulation International},
  address =	 {San Diego, CA, USA},
  abstract = 	 {This paper uses a case study from the pharmaceutical industry to show how simulation modeling can be applied to understanding large, highly-complex processes such as drug development. I conclude that simulation provides an enhanced resource planning capability compared with that provided by traditional spreadsheet analysis. This capability difference stems from the ability of a simulation to better reflect the variation which defines such complicated processes. The conditions which facilitate exploitation of this advantage include: capturing process information at the correct level of abstraction; successfully incorporating this information into a simulation model; and allowing easy user access to critical parameters via an intuitive interface.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=510669&ftid=70425&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:31>},
}

@inproceedings{Kandogan:2009:SPC:1641587.1641589,
  author =	 {Kandogan, Eser and Maglio, Paul P. and Haber, Eben
                  M. and Bailey, John H.},
  title =	 {Scripting Practices in Complex Systems Management},
  booktitle =	 {Proceedings of the Symposium on Computer Human
                  Interaction for the Management of Information
                  Technology},
  series =	 {CHiMiT '09},
  year =	 2009,
  isbn =	 {978-1-60558-572-7},
  location =	 {Baltimore, Maryland},
  pages =	 {2:9--2:18},
  articleno =	 2,
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1641587.1641589},
  doi =		 {10.1145/1641587.1641589},
  acmid =	 1641589,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {System administrators are end-users too. And as end-users, they develop tools, create web pages, write command-line scripts, use spreadsheets, and repurpose existing tools. In short, they engage in end-user programming activities in support of their systems management work. We examined system administrator practices in software tool development, operations, and maintenance based on ethnographic field studies at service delivery centers and data centers across the United States. Our findings suggest that software practices were mostly informal and collaborative and mixed within formal change processes; tool development and debugging were interleaved with tool use and maintenance as they interacted with live systems; and the complexity of large-scale systems and the risks involved in changing live and critical systems put increased demands on system administrators. We argue that system administrators might benefit from certain software engineering methodologies such as agile software development and software modeling.},
  review = 	 {fbie: rejected <2016-01-15 13:38:36>},
}

@inproceedings{Allen:2013:HBB:2675807.2675898,
  author =	 {Allen, Nicholas},
  title =	 {Honda's Black Box Simulation Tool},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  location =	 {Washington, D.C.},
  pages =	 {3923--3923},
  numpages =	 1,
  url =		 {http://dl.acm.org/citation.cfm?id=2675807.2675898},
  acmid =	 2675898,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {The Black Box Simulation Tool allows non-experts to tap into the power of discrete event simulation in Automod through the use of an Excel spreadsheet. A simplified way to create simulations can provide quicker results while maintaining a high-level of analysis capability. The model is developed as a generic 'process loop' model with the user-defined inputs creating a time-based virtual environment rather than one based on conveyors, vehicles, queues, etc. With its roots in machining processes, the tool has also been successfully used to model automotive paint shops, weld shops and engine assembly lines. The tool has also been used for proof-of-concept and proof-of-theory examples.},
  review = 	 {fbie: rejected <2016-01-15 13:38:40>},
}

@inproceedings{Allen:2013:HBB:2675983.2675898,
  author =	 {Allen, Nicholas},
  title =	 {Honda's Black Box Simulation Tool},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  isbn =	 {978-1-4799-2077-8},
  location =	 {Washington, D.C.},
  pages =	 {3923--3923},
  numpages =	 1,
  url =		 {http://dl.acm.org/citation.cfm?id=2675983.2675898},
  acmid =	 2675898,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {The Black Box Simulation Tool allows non-experts to tap into the power of discrete event simulation in Automod through the use of an Excel spreadsheet. A simplified way to create simulations can provide quicker results while maintaining a high-level of analysis capability. The model is developed as a generic 'process loop' model with the user-defined inputs creating a time-based virtual environment rather than one based on conveyors, vehicles, queues, etc. With its roots in machining processes, the tool has also been successfully used to model automotive paint shops, weld shops and engine assembly lines. The tool has also been used for proof-of-concept and proof-of-theory examples.},
  review = 	 {fbie: rejected <2016-01-15 13:38:49>},
}

@article{Neff:1987:DBC:38714.38767,
  author =	 {Neff, R. K.},
  title =	 {Data Bases, Compound Objects, and Networked
                  Workstations: Beyond Distributed Computing
                  (Abstract)},
  journal =	 {SIGMOD Rec.},
  issue_date =	 {Dec. 1987},
  volume =	 16,
  number =	 3,
  month =	 dec,
  year =	 1987,
  issn =	 {0163-5808},
  pages =	 {1--1},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/38714.38767},
  doi =		 {10.1145/38714.38767},
  acmid =	 38767,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Requirements for future data base systems are developed from the perspective of the user of a networked workstation who naturally deals with compound objects. Objects considered include full text, diagrams, maps, sound recordings, images from film and video and of art objects, spreadsheets, etc. Searching requirements and strategies over multi-objects are also considered. The context of such data base systems is the library, in its electronic or digital version. Comments are presented with respect to the digital learning environment of the future. Current related projects at Berkeley are described.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=38767&ftid=26215&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:38:55>},
}

@inproceedings{Neff:1987:DBC:38713.38767,
  author =	 {Neff, R. K.},
  title =	 {Data Bases, Compound Objects, and Networked
                  Workstations: Beyond Distributed Computing
                  (Abstract)},
  booktitle =	 {Proceedings of the 1987 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '87},
  year =	 1987,
  isbn =	 {0-89791-236-5},
  location =	 {San Francisco, California, USA},
  pages =	 {1--1},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/38713.38767},
  doi =		 {10.1145/38713.38767},
  acmid =	 38767,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Requirements for future data base systems are developed from the perspective of the user of a networked workstation who naturally deals with compound objects. Objects considered include full text, diagrams, maps, sound recordings, images from film and video and of art objects, spreadsheets, etc. Searching requirements and strategies over multi-objects are also considered. The context of such data base systems is the library, in its electronic or digital version. Comments are presented with respect to the digital learning environment of the future. Current related projects at Berkeley are described.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=38767&ftid=26215&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:00>},
}

@inproceedings{Nichols:1995:TMT:223904.223955,
  author =	 {Nichols, Sarah and Ritter, Frank E.},
  title =	 {A Theoretically Motivated Tool for Automatically
                  Generating Command Aliases},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '95},
  year =	 1995,
  isbn =	 {0-201-84705-1},
  location =	 {Denver, Colorado, USA},
  pages =	 {393--400},
  numpages =	 8,
  url =		 {http://dx.doi.org/10.1145/223904.223955},
  doi =		 {10.1145/223904.223955},
  acmid =	 223955,
  publisher =	 {ACM Press/Addison-Wesley Publishing Co.},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 13:39:04>},
}

@inproceedings{Girardot:1991:AEL:114054.114075,
  author =	 {Girardot, Jean Jacques},
  title =	 {APL As an Embedded Language: The Ultimate
                  Application?},
  booktitle =	 {Proceedings of the International Conference on APL
                  '91},
  series =	 {APL '91},
  year =	 1991,
  isbn =	 {0-89791-441-4},
  location =	 {Palo Alto, California, USA},
  pages =	 {186--196},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/114054.114075},
  doi =		 {10.1145/114054.114075},
  acmid =	 114075,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes a new approach to the development of customized applications. It first discusses two problems whith APL programming: writting efficient programs, and building user interfaces. It then describes the proposed solution, that consists in writting the skeleton of the application in an efficient compiled language, using some predefined building blocks, and developing the other parts in APL.This approach is closer to integrated systems, such as spreadsheets, or data-base managers, than to traditional APL applications executed under the control of an interpreter. It differs from these integrated systems in the fact that the development cost is kept low, so that new applications, highly customized for specific end users may be built from scratch, or more exactly, from predefined building blocks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=114075&ftid=28884&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:17>},
}

@article{Girardot:1991:AEL:114055.114075,
  author =	 {Girardot, Jean Jacques},
  title =	 {APL As an Embedded Language: The Ultimate
                  Application?},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {Aug. 1991},
  volume =	 21,
  number =	 4,
  month =	 jul,
  year =	 1991,
  issn =	 {0163-6006},
  pages =	 {186--196},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/114055.114075},
  doi =		 {10.1145/114055.114075},
  acmid =	 114075,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes a new approach to the development of customized applications. It first discusses two problems whith APL programming: writting efficient programs, and building user interfaces. It then describes the proposed solution, that consists in writting the skeleton of the application in an efficient compiled language, using some predefined building blocks, and developing the other parts in APL.This approach is closer to integrated systems, such as spreadsheets, or data-base managers, than to traditional APL applications executed under the control of an interpreter. It differs from these integrated systems in the fact that the development cost is kept low, so that new applications, highly customized for specific end users may be built from scratch, or more exactly, from predefined building blocks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=114075&ftid=28884&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:20>},
}

@article{Hudson:1990:ISF:98188.98201,
  author =	 {Hudson, Scott E. and Mohamed, Shamim P.},
  title =	 {Interactive Specification of Flexible User Interface
                  Displays},
  journal =	 {ACM Trans. Inf. Syst.},
  issue_date =	 {July 1990},
  volume =	 8,
  number =	 3,
  month =	 jul,
  year =	 1990,
  issn =	 {1046-8188},
  pages =	 {269--288},
  numpages =	 20,
  url =		 {http://doi.acm.org/10.1145/98188.98201},
  doi =		 {10.1145/98188.98201},
  acmid =	 98201,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {One of the problems with conventional UIMSs is that very often there is no graphical way to specify interfaces. This paper describes OPUS, the user interface editor of the Penguims UIMS. This system allows the presentation component of graphical user interfaces to be specified interactively in a graphical notation without explicit programming. The Penguims UIMS supports an underlying model of computation based loosely on spreadsheets. In particular, it supports incremental computations based on a system of equations (one-way constraints) over a set of named values (spreadsheet cells). These equations are used to provide immediate feedback at all levels of the interface. They are used to incrementally determine the position and dynamic appearance of    the individual interactor objects that make up the interface. They are also used to connect the presentation directly to underlying application data thereby supporting semantic feedback. The OPUS user interface editor employs a special graphical notation for specifying the presentation component of a user interface. This notation allows the power of the underlying computational model to be expressed simply and quickly. The resulting presentations are very flexible in nature. They can automatically respond to changes in the size and position of display objects and can directly support derivation of their appearance from application data objects.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=98201&ftid=14194&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:26>},
}

@inproceedings{Suri:1988:RMT:318123.318142,
  author =	 {Suri, Rajan and Tomsicek, Michael},
  title =	 {Rapid Modeling Tools for Manufacturing Simulation
                  and Analysis},
  booktitle =	 {Proceedings of the 20th Conference on Winter
                  Simulation},
  series =	 {WSC '88},
  year =	 1988,
  isbn =	 {0-911801-42-1},
  location =	 {San Diego, California, USA},
  pages =	 {25--32},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/318123.318142},
  doi =		 {10.1145/318123.318142},
  acmid =	 318142,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We present a set of five compatible tools for rapid modeling and analysis of discrete manufacturing systems. Lotus 1-2-3 spreadsheets form the database and most fundamental analysis tool for basic calculations. Manuplan II provides the user with a powerful tool to study the dynamics of manufacturing systems through analytical modeling: with this tool, models can be built in hours and each “what-if” is analyzed in minutes. SimStarter allows almost instantaneous conversion of the analytical model into simulation code. Siman provides detailed simulation modeling abilities in a package designed for the industrial user. Finally, Cinema gives manufacturing analysts the power of animation to present their results to co-workers and management in a convincing manner. All of these tools are designed to work together: Manuplan II has a Lotus 1-2-3 interface, SimStarter connects Manuplan II and Siman, and Cinema works directly with Siman code. Using this integrated set of tools, analysts can rapidly investigate decisions in all stages of the design and operation of manufacturing systems. This leads to cost-effective and timely analysis of manufacturing decisions, and hence to greater productivity and competitive position of the manufacturing enterprise.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318142&ftid=16154&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:30>},
}

@article{Motil:1991:BAI:107005.107044,
  author =	 {Motil, John},
  title =	 {Begin-BIG an Approach to the Introductory Computing
                  Course},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Mar. 1991},
  volume =	 23,
  number =	 1,
  month =	 mar,
  year =	 1991,
  issn =	 {0097-8418},
  pages =	 {226--230},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/107005.107044},
  doi =		 {10.1145/107005.107044},
  acmid =	 107044,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=107044&ftid=29278&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:34>},
}

@inproceedings{Motil:1991:BAI:107004.107044,
  author =	 {Motil, John},
  title =	 {Begin-BIG an Approach to the Introductory Computing
                  Course},
  booktitle =	 {Proceedings of the Twenty-second SIGCSE Technical
                  Symposium on Computer Science Education},
  series =	 {SIGCSE '91},
  year =	 1991,
  isbn =	 {0-89791-377-9},
  location =	 {San Antonio, Texas, USA},
  pages =	 {226--230},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/107004.107044},
  doi =		 {10.1145/107004.107044},
  acmid =	 107044,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=107044&ftid=29278&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:36>},
}

@inproceedings{Worring:2015:IIC:2671188.2749312,
  author =	 {Worring, Marcel and Koelma, Dennis C.},
  title =	 {Insight in Image Collections by Multimedia Pivot
                  Tables},
  booktitle =	 {Proceedings of the 5th ACM on International
                  Conference on Multimedia Retrieval},
  series =	 {ICMR '15},
  year =	 2015,
  isbn =	 {978-1-4503-3274-3},
  location =	 {Shanghai, China},
  pages =	 {291--298},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2671188.2749312},
  doi =		 {10.1145/2671188.2749312},
  acmid =	 2749312,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {exploration, information visualization, visual
                  analytics},
  abstract = 	 {We propose a multimedia analytics solution for getting insight in image collections by extending the powerful method of pivot tables, found in the ubiquitous spreadsheets, to multimedia. Our proposed solution is designed by considering the characteristics of multimedia data as well as insight and provides integral access to visual content through concept detection results, tags, geolocation, and other metadata. We present a set of scenarios of using the pivot tables for a collection of images, tags, and metadata from Flickr. User experiments have been instrumental in realizing the final design presented in this paper. The accompanying video shows the solution in action.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2749312&ftid=1594016&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:41>},
}

@article{Ennals:2007:UFP:1291220.1291187,
  author =	 {Ennals, Rob and Gay, David},
  title =	 {User-friendly Functional Programming for Web
                  Mashups},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {September 2007},
  volume =	 42,
  number =	 9,
  month =	 oct,
  year =	 2007,
  issn =	 {0362-1340},
  pages =	 {223--234},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1291220.1291187},
  doi =		 {10.1145/1291220.1291187},
  acmid =	 1291187,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {browser, end-used programming, mashup, web},
  abstract = 	 {MashMaker is a web-based tool that makes it easy for a normal user to create web mashups by browsing around, without needing to type, or plan in advance what they want to do. Like a web browser, Mashmaker allows users to create mashups by browsing, rather than writing code, and allows users to bookmark interesting things they find, forming new widgets - reusable mashup fragments. Like a spreadsheet, MashMaker mixes program and data and allows ad-hoc unstructured editing of programs. MashMaker is also a modern functional programming language with non-side effecting expressions, higher order functions, and lazy evaluation. MashMaker programs can be manipulated either textually, or through an interactive tree representation, in which a program is presented together with the values it produces. In order to cope with this unusual domain, MashMaker contains a number of deviations from normal function languages. The most notable of these is that, in order to allow the programmer to write programs directly on their data, all data is stored in a single tree, and evaluation of an expression always takes place at a specific point in this tree, which also functions as its scope.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1291187&ftid=457139&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:47>},
}

@inproceedings{Ennals:2007:UFP:1291151.1291187,
  author =	 {Ennals, Rob and Gay, David},
  title =	 {User-friendly Functional Programming for Web
                  Mashups},
  booktitle =	 {Proceedings of the 12th ACM SIGPLAN International
                  Conference on Functional Programming},
  series =	 {ICFP '07},
  year =	 2007,
  isbn =	 {978-1-59593-815-2},
  location =	 {Freiburg, Germany},
  pages =	 {223--234},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/1291151.1291187},
  doi =		 {10.1145/1291151.1291187},
  acmid =	 1291187,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {browser, end-used programming, mashup, web},
  abstract = 	 {MashMaker is a web-based tool that makes it easy for a normal user to create web mashups by browsing around, without needing to type, or plan in advance what they want to do. Like a web browser, Mashmaker allows users to create mashups by browsing, rather than writing code, and allows users to bookmark interesting things they find, forming new widgets - reusable mashup fragments. Like a spreadsheet, MashMaker mixes program and data and allows ad-hoc unstructured editing of programs. MashMaker is also a modern functional programming language with non-side effecting expressions, higher order functions, and lazy evaluation. MashMaker programs can be manipulated either textually, or through an interactive tree representation, in which a program is presented together with the values it produces. In order to cope with this unusual domain, MashMaker contains a number of deviations from normal function languages. The most notable of these is that, in order to allow the programmer to write programs directly on their data, all data is stored in a single tree, and evaluation of an expression always takes place at a specific point in this tree, which also functions as its scope.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1291187&ftid=457139&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:51>},
}

@inproceedings{Kang:2010:ILR:2433508.2433672,
  author =	 {Kang, Keebom and McDonald, Mary},
  title =	 {Impact of Logistics on Readiness and Life Cycle
                  Cost: A Design of Experiments Approach},
  booktitle =	 {Proceedings of the Winter Simulation Conference},
  series =	 {WSC '10},
  year =	 2010,
  isbn =	 {978-1-4244-9864-2},
  location =	 {Baltimore, Maryland},
  pages =	 {1336--1346},
  numpages =	 11,
  url =		 {http://dl.acm.org/citation.cfm?id=2433508.2433672},
  acmid =	 2433672,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {In this paper we develop two models that can be used to identify critical logistics factors that impact military readiness and the life cycle cost. The first one, a discrete-event simulation model, estimates the operational availability of a weapon system given input parameters under a certain scenario. The second one, a spreadsheet model, computes the life cycle cost using the same input parameters for the simulation model. Our approach is intended to serve as a basis for discussion between program offices concerned with cost and operational commands concerned with operational availability.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2433672&ftid=1339598&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:39:55>},
}

@inproceedings{Lockwood:2015:GHF:2684746.2721404,
  author =	 {Lockwood, John and Adler, Michael and Mansur, Dan
                  and Chiou, Derek and Strickland, Mike and Cong,
                  Jason and Teig, Steve},
  title =	 {Growing a Healthy FPGA Ecosystem},
  booktitle =	 {Proceedings of the 2015 ACM/SIGDA International
                  Symposium on Field-Programmable Gate Arrays},
  series =	 {FPGA '15},
  year =	 2015,
  isbn =	 {978-1-4503-3315-3},
  location =	 {Monterey, California, USA},
  pages =	 {160--160},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2684746.2721404},
  doi =		 {10.1145/2684746.2721404},
  acmid =	 2721404,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Field Programmable Gate Array, cloud computing,
                  datacenter, microprocessor},
  abstract = 	 {The personal computer market grew exponentially in the 1980's for vendors such as Apple, Microsoft, and Intel when there was a healthy mix of software, tools, and microprocessor devices. At the time, killer applications that drove the market were spreadsheets, compilers, and games that ran on the personal computer. Thirty years later, we now have a similar opportunity to grow a healthy ecosystem as developers and vendors bring killer applications, tools, and programmable logic devices to the market to accelerate datacenters for cloud computing.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2721404&ftid=1542247&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:00>},
}

@inproceedings{Schuster:1987:LAS:318371.318706,
  author =	 {Schuster, Edmund W.},
  title =	 {A Logistics Application of Simulation to Determine
                  Distribution Costs Resulting from a Forward
                  Warehouse Operation},
  booktitle =	 {Proceedings of the 19th Conference on Winter
                  Simulation},
  series =	 {WSC '87},
  year =	 1987,
  isbn =	 {0-911801-32-4},
  location =	 {Atlanta, Georgia, USA},
  pages =	 {845--852},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/318371.318706},
  doi =		 {10.1145/318371.318706},
  acmid =	 318706,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Often it is difficult to compute the cost of a forward warehouse operation given uncertain demand and complex billing systems. The simulation to be presented serves as a decision support system which aids logistics management in determining distribution costs associated with a forward warehouse based on transportation, warehouse and inventory considerations. A unique aspect of the simulation is that it is a microcomputer spreadsheet application using technology common to many business environments. Practical uses of the simulation include such corporate policy issues as warehouse location, cost increase evaluation, customer service projections and analysis of different billing systems.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318706&ftid=9111&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:04>},
}

@inproceedings{Dillon:2006:VSR:1124772.1124849,
  author =	 {Dillon, Andrew and Kleinman, Lisa and Choi, Gil Ok
                  and Bias, Randolph},
  title =	 {Visual Search and Reading Tasks Using ClearType and
                  Regular Displays: Two Experiments},
  booktitle =	 {Proceedings of the SIGCHI Conference on Human
                  Factors in Computing Systems},
  series =	 {CHI '06},
  year =	 2006,
  isbn =	 {1-59593-372-7},
  location =	 {Montr\&\#233;al, Qu\&\#233;bec, Canada},
  pages =	 {503--511},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/1124772.1124849},
  doi =		 {10.1145/1124772.1124849},
  acmid =	 1124849,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ClearType, information tasks, readability, visual
                  displays},
  abstract = 	 {Two experiments comparing user performance on ClearType and Regular displays are reported. In the first, 26 participants scanned a series of spreadsheets for target information. Speed of performance was significantly faster with ClearType. In the second experiment, 25 users read two articles for meaning. Reading speed was significantly faster for ClearType. In both experiments no differences in accuracy of performance or visual fatigue scores were observed. The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1124849&ftid=348293&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:12>},
}

@inproceedings{Crafton:2004:RTN:1027802.1027859,
  author =	 {Crafton, Teresa and Janz, Kenneth},
  title =	 {Reenvisioning Training: New Partnerships and Focus},
  booktitle =	 {Proceedings of the 32Nd Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '04},
  year =	 2004,
  isbn =	 {1-58113-869-5},
  location =	 {Baltimore, MD, USA},
  pages =	 {250--255},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1027802.1027859},
  doi =		 {10.1145/1027802.1027859},
  acmid =	 1027859,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {collaboration, documentation, faculty development,
                  instructor-led training, learning, staff
                  development, survey, technology needs assessment,
                  technology training, training needs assessment,
                  workshop},
  abstract = 	 {With the continually changing nature of technology and the fragmented delivery of professional development on campus, Indiana State University was looking for new methods of providing technology training to faculty. After years of providing the standard instructor-led training in word processing, spreadsheets, presentation software, and email, the training unit was dissolved and merged with Instructional and Research Technology Services, a new unit on campus, whose vision is to engage internal and external audiences in collaborative efforts that enhance opportunities for faculty and students in their application of innovative instructional and research technologies. This merger also allows new opportunities for collaboration with the Center for Teaching and Learning, a unit responsible for supporting, promoting, and enhancing quality teaching at Indiana State University through a broad range of programs, services, and resources. This paper and presentation describes how technology training, instead of being a disconnected afterthought, has now become an integral part of a multi-dimensional professional development program for faculty.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1027859&ftid=288470&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:17>},
}

@article{Paik:2015:PUP:2814459.2776891,
  author =	 {Paik, Jaehyon and Kim, Jong W. and Ritter, Frank
                  E. and Reitter, David},
  title =	 {Predicting User Performance and Learning in
                  Human--Computer Interaction with the Herbal
                  Compiler},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {October 2015},
  volume =	 22,
  number =	 5,
  month =	 aug,
  year =	 2015,
  issn =	 {1073-0516},
  pages =	 {25:1--25:26},
  articleno =	 25,
  numpages =	 26,
  url =		 {http://doi.acm.org/10.1145/2776891},
  doi =		 {10.1145/2776891},
  acmid =	 2776891,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ACT-R, Computational cognitive modeling, GOMS, KLM,
                  evaluating user interfaces, expertise, user
                  modeling},
  abstract = 	 {We report a way to build a series of GOMS-like cognitive user models representing a range of performance at different stages of learning. We use a spreadsheet task across multiple sessions as an example task; it takes about 20--30 min. to perform. The models were created in ACT-R using a compiler. The novice model has 29 rules and 1,152 declarative memory task elements (chunks)—it learns to create procedural knowledge to perform the task. The expert model has 617 rules and 614 task chunks (that it does not use) and 538 command string chunks—it gets slightly faster through limited declarative learning of the command strings and some further production compilation; there are a range of intermediate models. These models were tested against aggregate and individual human learning data, confirming the models’ predictions. This work suggests that user models can be created that learn like users while doing the task.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2776891&ftid=1615461&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:21>},
}

@inproceedings{Tawhid:2012:UAH:2188286.2188304,
  author =	 {Tawhid, Rasha and Petriu, Dorina},
  title =	 {User-friendly Approach for Handling Performance
                  Parameters During Predictive Software Performance
                  Engineering},
  booktitle =	 {Proceedings of the 3rd ACM/SPEC International
                  Conference on Performance Engineering},
  series =	 {ICPE '12},
  year =	 2012,
  isbn =	 {978-1-4503-1202-8},
  location =	 {Boston, Massachusetts, USA},
  pages =	 {109--120},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2188286.2188304},
  doi =		 {10.1145/2188286.2188304},
  acmid =	 2188304,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {atl, marte, model-driven development, performance
                  completion, performance model, spl, uml},
  abstract = 	 {A Software Product Line (SPL) is a set of similar software systems that share a common set of features. Instead of building each product from scratch, SPL development takes advantage of the reusability of the core assets shared among the SPL members. In this work, we integrate performance analysis in the early phases of SPL development process, applying the same reusability concept to the performance annotations. Instead of annotating from scratch the UML model of every derived product, we propose to annotate the SPL model once with generic performance annotations. After deriving the model of a product from the family model by an automatic transformation, the generic performance annotations need to be bound to concrete product-specific values provided by the developer. Dealing manually with a large number of performance annotations, by asking the developer to inspect every diagram in the generated model and to extract these annotations is an error-prone process. In this paper we propose to automate the collection of all generic parameters from the product model and to present them to the developer in a user-friendly format (e.g., a spreadsheet per diagram, indicating each generic parameter together with guiding information that helps the user in providing concrete binding values). There are two kinds of generic parametric annotations handled by our approach: product-specific (corresponding to the set of features selected for the product) and platform-specific (such as device choices, network connections, middleware, and runtime environment). The following model transformations for (a) generating a product model with generic annotations from the SPL model, (b) building the spreadsheet with generic parameters and guiding information, and (c) performing the actual binding are all realized in the Atlas Transformation Language (ATL).},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2188304&ftid=1206024&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:28>},
}

@inproceedings{Berlage:1992:UTS:142621.142648,
  author =	 {Berlage, Thomas},
  title =	 {Using Taps to Separate the User Interface from the
                  Application Code},
  booktitle =	 {Proceedings of the 5th Annual ACM Symposium on User
                  Interface Software and Technology},
  series =	 {UIST '92},
  year =	 1992,
  isbn =	 {0-89791-549-6},
  location =	 {Monteray, California, USA},
  pages =	 {191--198},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/142621.142648},
  doi =		 {10.1145/142621.142648},
  acmid =	 142648,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {change propagation, command objects, user interface
                  management systems},
  abstract = 	 {A new mechanism based on taps is introduced to separate the output from the application code in graphical interactive interfaces. The mechanism is implemented in GINA, an object-oriented application framework. Taps maintain a functional mapping from application data to interface objects that is described in a general-purpose programming language. Taps are triggered automatically by user actions. Compared to constraints or the MVC model, taps do not need execution or memory support from the application objects, at the expense of a performance penalty. Screen updates, which pose the largest performance problem, are minimized by checking for attribute changes and window visibility. A comparison operation is used to maintain structural consistency between hierarchies of application and interface objects. Taps can be defined interactively using formulas in a spreadsheet-like tool.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=142648&ftid=18322&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:33>},
}

@inproceedings{Agustina:2013:TIW:2441955.2442028,
  author =	 {Agustina and Gu, Ning and Ignat, Claudia-Lavinia and
                  MacFadden, Michael and Shen, Haifeng and Sun, David
                  and Sun, Chengzheng},
  title =	 {The Thirteenth International Workshop on
                  Collaborative Editing Systems},
  booktitle =	 {Proceedings of the 2013 Conference on Computer
                  Supported Cooperative Work Companion},
  series =	 {CSCW '13},
  year =	 2013,
  isbn =	 {978-1-4503-1332-2},
  location =	 {San Antonio, Texas, USA},
  pages =	 {299--300},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2441955.2442028},
  doi =		 {10.1145/2441955.2442028},
  acmid =	 2442028,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {collaborative editing systems, groupware},
  abstract = 	 {Collaborative editing (CE) has been an area of continuous research since early days of CSCW. Various CE systems have been studied in academia as research vehicles to investigate key technical issues in building advanced collaborative applications. In recent years, CE techniques have been increasingly adopted and further developed in industry for supporting real-world Internet or Cloud-based CE systems/services, such as Google Docs, Codoxware, IBM OpenCoWeb, Novell Vibe, and SubEthaEdit. This workshop aims to bring together CE academic researchers, industry developers, and end-users to discuss and exchange ideas on contemporary issues in researching, developing, and adopting CE systems. We have successfully organized this workshop annually at CSCW-related conferences. This year's workshop focuses on CE issues and techniques for supporting complex real-world documents (including but not limited to rich text, xml, spreadsheet, 2D/3D digital media, CAD, video, etc.), and evaluation of CE systems for such complex real-world documents.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2442028&ftid=1348659&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:36>},
}

@inproceedings{Shulman:2013:TAS:2479724.2479727,
  author =	 {Shulman, Stuart},
  title =	 {Text Analytics for Social Research},
  booktitle =	 {Proceedings of the 14th Annual International
                  Conference on Digital Government Research},
  series =	 {dg.o '13},
  year =	 2013,
  isbn =	 {978-1-4503-2057-3},
  location =	 {Quebec, Canada},
  pages =	 {295--295},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2479724.2479727},
  doi =		 {10.1145/2479724.2479727},
  acmid =	 2479727,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {archiving, bigdata, classification, coding,
                  machine-learning, metadata, social media, software,
                  text analytics},
  abstract = 	 {This tutorial provides software training in "DiscoverText," which is text analytic software developed by Professor Shulman. His work advances text mining, social media, and natural language processing research. The software training links these worlds via easy to understand explanations of software features that can be tailored for all experience levels and industries. This tutorial introduces users to the powerful tools for archiving, searching and sorting web-based text from sources, including social media, email, open ended answers on surveys, and public comments from a wide range of sources. DiscoverText eases the collection, archiving and sorting of text collected via Twitter and the Facebook Graph APIs, or generic RSS feeds or uploaded in spreadsheets, .zip archives and XML format.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2479727&ftid=1378250&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:41>},
}

@inproceedings{Moore:2003:TPG:947469.947530,
  author =	 {Moore, Sue A.},
  title =	 {Training Program Growth...: From Flat Line to
                  Pulsating},
  booktitle =	 {Proceedings of the 31st Annual ACM SIGUCCS Fall
                  Conference},
  series =	 {SIGUCCS '03},
  year =	 2003,
  isbn =	 {1-58113-665-X},
  location =	 {San Antonio, TX, USA},
  pages =	 {230--233},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/947469.947530},
  doi =		 {10.1145/947469.947530},
  acmid =	 947530,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {computer skills, customize material, documentation,
                  faculty, learning styles, management, manual, needs
                  assessment, partnering, performance, redeveloping,
                  staff, survey, trainer, training, training program},
  abstract = 	 {IT Training and Communications is a division of Information Technology Services (ITS), which provides computer application training for the faculty and staff at Saint Louis University. In the beginning, IT Training and Communications provided training in word processing, database and spreadsheet programs. However, the University community needs were growing in the areas of spreadsheet/database management, database design, and web base applications, as well as in fundamental computer skills. In response to requests from the Saint Louis University's community, we began the process of redeveloping our computer application training program. We decided that all of the courses that we offered should be redesigned into "level" classes, allowing users to build their skills received from training as they applied them in their work environment. A complete course description for each level would be provided so that participants would be able to determine which level of class they should attend, based on the course content and skills taught. In addition, IT Training and Communications wanted to maintain a record of participant's attendance to provide recognition for the time and effort participants spent enhancing their computer knowledge as well as personal and professional growth. Each participant would receive a bound course book, diskette, and a certificate of completion for each level completed.Although we had developed a great program on paper, our resources (people and time primarily) were very limited. Several questions raised their ugly heads:How can we develop 30 different levels of classes?Who will write and design the training materials?How can we accomplish this with a staff of two and no designated budget?How are we going to offset the cost of providing new training materials?How can we provide a fast-turn around?.The ultimate solution was to seek out a resource that could provide materials for us that we could customize to meet our growing needs. We wanted to be sure to meet our customer's needs of providing training that is pertinent to our academic environment, while maintaining the flexibility to apply the training in a variety of academic settings (faculty needs, staff needs, researcher needs, etc.). Not only did we find such a resource, but we were also successful in meeting the challenges of getting this "just in time" learning quickly to our customers.This paper discusses the challenges IT Training and Communications faced in redeveloping the computer application training program, the solutions we found, and the successes that continue as a result of our effort.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=947530&ftid=235396&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:47>},
}

@inproceedings{Starks:2006:DST:1218112.1218474,
  author =	 {Starks, Darrell W. and Schwieters, Robert S. and
                  Creces, Daniel},
  title =	 {A Decision Support Tool for Dofasco's Primary
                  Steelmaking Operations},
  booktitle =	 {Proceedings of the 38th Conference on Winter
                  Simulation},
  series =	 {WSC '06},
  year =	 2006,
  isbn =	 {1-4244-0501-7},
  location =	 {Monterey, California},
  pages =	 {1985--1988},
  numpages =	 4,
  url =		 {http://dl.acm.org/citation.cfm?id=1218112.1218474},
  acmid =	 1218474,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Dofasco Inc. needed a dynamic decision support tool in order to evaluate its primary steelmaking operations. Before working with Rockwell Automation, Dofasco used spreadsheet models and smaller simulations to evaluate capital expenditures at its steel mill. It was determined that modeling all of Dofasco's primary steel operations using Rockwell Software's Arena® coupled with an Excel user interface would allow Dofasco to perform various scenarios in a timely fashion. Through the use of modeling and simulation Dofasco was able to identify bottlenecks in its system, improve throughput by more efficient use of system resources, and understand the impact of proposed system changes before investing additional capital.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1218474&ftid=399489&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:52>},
}

@inproceedings{Fisk:1991:UES:122898.122899,
  author =	 {Fisk, Bob},
  title =	 {Using Excel for Scientific Calculations},
  booktitle =	 {Proceedings of the 19th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '91},
  year =	 1991,
  isbn =	 {0-89791-454-6},
  location =	 {Seattle, Washington, USA},
  pages =	 {3--13},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/122898.122899},
  doi =		 {10.1145/122898.122899},
  acmid =	 122899,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=122899&ftid=17377&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:40:57>},
}

@inproceedings{Sarukkai:1992:PPV:143369.143404,
  author =	 {Sarukkai, Sekhar R. and Gannon, Dennis},
  title =	 {Parallel Program Visualization Using SIEVE.1},
  booktitle =	 {Proceedings of the 6th International Conference on
                  Supercomputing},
  series =	 {ICS '92},
  year =	 1992,
  isbn =	 {0-89791-485-6},
  location =	 {Washington, D. C., USA},
  pages =	 {157--166},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/143369.143404},
  doi =		 {10.1145/143369.143404},
  acmid =	 143404,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In this paper we introduce a new model for the design of performance analysis and visualization tools. The system integrates static code analysis, relational database designs and a spreadsheet model of interactive programming. This system provides a general methodology for visualizing parallel program executions by providing correlation to the source program, a convenient method for rapidly developing new visualizations of the program and a framework for performance studies.
The basic semantics of this model are described and example applications of visualizing the execution of two different parallel programs are considered.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=143404&ftid=17688&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:03>},
}

@inproceedings{Hasan:2014:DMF:2740769.2740862,
  author =	 {Hasan, S. M. Shamimul and Gupta, Sandeep and Fox,
                  Edward A. and Bisset, Keith and Marathe, Madhav V.},
  title =	 {Data Mapping Framework in a Digital Library with
                  Computational Epidemiology Datasets},
  booktitle =	 {Proceedings of the 14th ACM/IEEE-CS Joint Conference
                  on Digital Libraries},
  series =	 {JCDL '14},
  year =	 2014,
  isbn =	 {978-1-4799-5569-5},
  location =	 {London, United Kingdom},
  pages =	 {449--450},
  numpages =	 2,
  url =		 {http://dl.acm.org/citation.cfm?id=2740769.2740862},
  acmid =	 2740862,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  keywords =	 {digital library, epidemiology, simulation},
  abstract = 	 {Computational epidemiology employs computer models and informatics tools to reason about the spatio-temporal spread of diseases. The diversity of models, data sources, data representations, and modalities that are collected, used, and modified motivate the development of a digital library (DL) framework to support computational epidemiology. The heterogeneous content includes metadata, text, tables, spreadsheets, experimental descriptions, and large result files. There is no accepted framework that allows unified access to such content. We propose a framework for a digital library system tailored to such datasets to support computational network epidemiology.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2740862&ftid=1548154&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:13>},
}

@article{Macri:2004:SP:971564.971594,
  author =	 {Macri, Dean},
  title =	 {The Scalability Problem},
  journal =	 {Queue},
  issue_date =	 {February 2004},
  volume =	 1,
  number =	 10,
  month =	 feb,
  year =	 2004,
  issn =	 {1542-7730},
  pages =	 {66--73},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/971564.971594},
  doi =		 {10.1145/971564.971594},
  acmid =	 971594,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Back in the mid-1990s, I worked for a company that developed multimedia kiosk demos. Our biggest client was Intel, and we often created demos that appeared in new PCs on the end-caps of major computer retailers such as CompUSA. At that time, performance was in demand for all application classes from business to consumer. We created demos that showed, for example, how much faster a spreadsheet would recalculate (you had to do that manually back then) on a new processor as compared with the previous year's processor. The differences were immediately noticeable to even a casual observer - and it mattered. Having to wait only 10 seconds for something that previously took 20 or more was a major improvement and led many consumers and businesses to upgrade their PCs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=971594&ftid=253848&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:19>},
}

@article{Gebhardt:1997:TNS:253262.253344,
  author =	 {Gebhardt, Michael and Jarke, Matthias and Jacobs,
                  Stephan},
  title =	 {A Toolkit for Negotiation Support Interfaces to
                  Multi-dimensional Data},
  journal =	 {SIGMOD Rec.},
  issue_date =	 {June 1997},
  volume =	 26,
  number =	 2,
  month =	 jun,
  year =	 1997,
  issn =	 {0163-5808},
  pages =	 {348--356},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/253262.253344},
  doi =		 {10.1145/253262.253344},
  acmid =	 253344,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {CoDecide is an experimental user interface toolkit that offers an extension to spreadsheet concepts specifically geared towards support for cooperative analysis of the kinds of multi-dimensional data encountered in data warehousing. It is distinguished from previous proposals by direct support for drill-down/roll-up analysis without redesign of an interface; more importantly, CoDecide can link multiple views on a data cube for synchronous or asynchronoous cooperation by multiple analysts, through a conceptual model visualizing the problem dimensions on so-called tapes. Tapes generalize the ideas of ranging and pivoting in current data warehouses for the multi-perspective and multi-user case. CoDecide allows the rapid composition of multi-matrix interfaces and their linkage to underlying data sources. A LAN version of CoDecide has been used in a number of design decision support applications. A WWW version representing externally materialized views on databases is currently under development.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=253344&ftid=16935&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:24>},
}

@inproceedings{Gebhardt:1997:TNS:253260.253344,
  author =	 {Gebhardt, Michael and Jarke, Matthias and Jacobs,
                  Stephan},
  title =	 {A Toolkit for Negotiation Support Interfaces to
                  Multi-dimensional Data},
  booktitle =	 {Proceedings of the 1997 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '97},
  year =	 1997,
  isbn =	 {0-89791-911-4},
  location =	 {Tucson, Arizona, USA},
  pages =	 {348--356},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/253260.253344},
  doi =		 {10.1145/253260.253344},
  acmid =	 253344,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {CoDecide is an experimental user interface toolkit that offers an extension to spreadsheet concepts specifically geared towards support for cooperative analysis of the kinds of multi-dimensional data encountered in data warehousing. It is distinguished from previous proposals by direct support for drill-down/roll-up analysis without redesign of an interface; more importantly, CoDecide can link multiple views on a data cube for synchronous or asynchronoous cooperation by multiple analysts, through a conceptual model visualizing the problem dimensions on so-called tapes. Tapes generalize the ideas of ranging and pivoting in current data warehouses for the multi-perspective and multi-user case. CoDecide allows the rapid composition of multi-matrix interfaces and their linkage to underlying data sources. A LAN version of CoDecide has been used in a number of design decision support applications. A WWW version representing externally materialized views on databases is currently under development.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=253344&ftid=16935&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:28>},
}

@inproceedings{Macias:2001:GPM:634067.634273,
  author =	 {Mac\'{\i}as, Jos{\'e} A. and Castells, Pablo},
  title =	 {A Generic Presentation Modeling System for Adaptive
                  Web-based Instructional Applications},
  booktitle =	 {CHI '01 Extended Abstracts on Human Factors in
                  Computing Systems},
  series =	 {CHI EA '01},
  year =	 2001,
  isbn =	 {1-58113-340-5},
  location =	 {Seattle, Washington},
  pages =	 {349--350},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/634067.634273},
  doi =		 {10.1145/634067.634273},
  acmid =	 634273,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {adaptive hypermedia, authoring tools, computer-based
                  learning, knowledge representation, presentation
                  design},
  abstract = 	 {We propose a generic presentation system for adaptive educational hypermedia that is highly independent from domain knowledge representation and application state management. Generality is achieved by providing a framework for the definition of ontologies that best fit specific domains and/or authors. Presentations are described in terms of ontology object classes and relations. An explicit presentation model, separate from course contents, is used to provide course designers with extensive control over the generation of all aspects of presentation, at a moderate development cost.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=634273&ftid=141367&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:32>},
}

@article{Wee:1997:RPW:274883.274885,
  author =	 {Wee, Don M.},
  title =	 {Re-centralizing: The Pendulum Wobbles Back},
  journal =	 {SIGUCCS Newsl.},
  issue_date =	 {Sept./Dec. 1997},
  volume =	 27,
  number =	 {3-4},
  month =	 sep,
  year =	 1997,
  issn =	 {0736-6892},
  pages =	 {8--14},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/274883.274885},
  doi =		 {10.1145/274883.274885},
  acmid =	 274885,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In the 80's, many schools and corporations had "Information Center" departments who were charged with promoting and supporting "end-user computing." We I.C. folks sponsored PC user groups and led discussions on whether people should upgrade right away to WordPerfect 4.2 or wait. We encouraged the spreadsheet guru in Finance to teach short-courses on 1 2--3. We installed a network file server for the Sociology Department, but asked the department to provide someone to do the backups and funnel questions, so we could teach one person how to use the network, who would then teach the rest. As the number of PCs exploded, we helped our institutions cope in the only cost-effective way available: we leveraged the available computer expertise by focusing training, support, and resources on key departmental computing coordinators. [1]},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=274885&ftid=341667&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:38>},
}

@inproceedings{Kulvatunyou:2001:CMS:564124.564262,
  author =	 {Kulvatunyou, Boonserm and Wysk, Richard A.},
  title =	 {Computer-aided Manufacturing Simulation (CAMS)
                  Generation for Interactive Analysis: Concepts,
                  Techniques, and Issues},
  booktitle =	 {Proceedings of the 33Nd Conference on Winter
                  Simulation},
  series =	 {WSC '01},
  year =	 2001,
  isbn =	 {0-7803-7309-X},
  location =	 {Arlington, Virginia},
  pages =	 {968--976},
  numpages =	 9,
  url =		 {http://dl.acm.org/citation.cfm?id=564124.564262},
  acmid =	 564262,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  abstract = 	 {Simulation model is usually developed as a one-time use analytical model by a system analyst (usually from external firm) rather than for a routine and interactive use by a shop floor engineer. This is because it usually takes longer time to generate a result from the simulation, and the simulation model of manufacturing system is usually too sophisticated and time-consuming to use as an interactive tool by the manufacturing/production engineer. A CAMS reduces this complication by encapsulating the 'complicated-logic' and automating the 'tedious data-acquisition' with a more user-friendly interface like a spreadsheet or database input form. This paper describes how CAMS can automatically generate a simulation model; specifically, techniques and issues to structure the model to hide those tasks, so that it is a user-friendly interactive decision support with minimal amount of automation code. The paper concludes with a capacity analysis example from the real industry.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=564262&ftid=85209&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:45>},
}

@inproceedings{Seppanen:2000:MAD:510378.510395,
  author =	 {Seppanen, Marvin S.},
  title =	 {Modeling for Application: Developing Industrial
                  Strength Simulation Models Using Visual Basic for
                  Applications (VBA)},
  booktitle =	 {Proceedings of the 32Nd Conference on Winter
                  Simulation},
  series =	 {WSC '00},
  year =	 2000,
  isbn =	 {0-7803-6582-8},
  location =	 {Orlando, Florida},
  pages =	 {77--82},
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=510378.510395},
  acmid =	 510395,
  publisher =	 {Society for Computer Simulation International},
  address =	 {San Diego, CA, USA},
  abstract = 	 {Since 1984 the author has developed simulation models that use input data from spreadsheets. These original applications used a standalone Basic program to convert Lotus 123® data into Siman Experiment Frames. While this process has evolved overtime, it did not reach a truly viable level until Arena® 3.0 introduced Visual Basic® for Applications (VBA) by Microsoft®. This advanced tutorial demonstrates the basic concepts developed by the author to transfer data between Excel® and Arena. The same techniques can be used to communicate simulation data with a wide range of VBA supported tools, such as Access®, AutoCAD®, and Visio®. Arena permits the model developer to use VBA as the model file is loaded, executed, or terminated or as entities flow through the Arena model modules. This tutorial focuses on the design of Excel workbooks for simulation applications and the transfer of data to/from Arena using VBA.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=510395&ftid=77481&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:41:50>},
}

@inproceedings{Perera:2005:BLW:1094855.1094881,
  author =	 {Perera, Roly and Freeman, Russ},
  title =	 {Beyond the Language Workbench: A Runtime Platform
                  for Practical Semantic Computing},
  booktitle =	 {Companion to the 20th Annual ACM SIGPLAN Conference
                  on Object-oriented Programming, Systems, Languages,
                  and Applications},
  series =	 {OOPSLA '05},
  year =	 2005,
  isbn =	 {1-59593-193-7},
  location =	 {San Diego, CA, USA},
  pages =	 {96--97},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1094855.1094881},
  doi =		 {10.1145/1094855.1094881},
  acmid =	 1094881,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {dynamic aspects, incremental computation, relational
                  programming},
  abstract = 	 {domain/object is a new software environment in the tradition of dynamic languages like Smalltalk, Lisp and Self. Like its predecessors, domain/object blurs the usual distinctions between tools, languages, operating systems, applications and databases. domain/object also adds some interesting twists to the familiar dynamic paradigm, including spreadsheet-style "liveness", versioned execution, transactions, full incrementality and transparency.domain/object is intended as a delivery platform for software that requires tight semantic integration between components, such as development tools and next-generation applications for the semantic web. Incrementality and liveness obviate the need for standard notification schemes such as Observer, ensuring that data and programs are synchronised automatically. Transactions and versioning allow the granularity and frequency of synchronisation to be adjusted to suit the particular application or user. Transparency means that the full structure of the executing program is available for queries, suggesting a considerably more dynamic realisation of aspect-oriented programming.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1094881&ftid=329158&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:52:47>},
}

@inproceedings{Safey:2014:CCM:2740769.2740847,
  author =	 {Safey, Steffan and Bainbridge, David},
  title =	 {When Catalogs Collide: A Mashup of the Bibliographic
                  Records from New Zealand's National Bibliography and
                  the HathiTrust},
  booktitle =	 {Proceedings of the 14th ACM/IEEE-CS Joint Conference
                  on Digital Libraries},
  series =	 {JCDL '14},
  year =	 2014,
  isbn =	 {978-1-4799-5569-5},
  location =	 {London, United Kingdom},
  pages =	 {421--422},
  numpages =	 2,
  url =		 {http://dl.acm.org/citation.cfm?id=2740769.2740847},
  acmid =	 2740847,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {In this article we present work done developing an interactive comparison tool for large-scale catalogs using the general purpose open source digital library toolkit, Greenstone. The two catalogs selected to demonstrate the approach were the Bibliographic Records from New Zealand's National Bibliography and the HathiTrust. With Greenstone's triple-store extension activated, the two collections were ingested to form two Greenstone collections. Next, an interactive visualization tool was developed within the digital library's presentation layer to allow users to explore the two collections, comparing fields from the two collections and producing a variety of visualizations. The required interactivity was accomplished using AJAX calls to the Greenstone triple-store, further supported by the use of Javascript libraries for the presentation of the retrieved data in both visual and spreadsheet forms.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2740847&ftid=1548140&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:52:52>},
}

@inproceedings{Rautama:1997:EAA:268819.268829,
  author =	 {Rautama, E. and Sutinen, E. and Tarhio, J.},
  title =	 {Excel As an Algorithm Animation Environment},
  booktitle =	 {Proceedings of the 2Nd Conference on Integrating
                  Technology into Computer Science Education},
  series =	 {ITiCSE '97},
  year =	 1997,
  isbn =	 {0-89791-923-8},
  location =	 {Uppsala, Sweden},
  pages =	 {24--26},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/268819.268829},
  doi =		 {10.1145/268819.268829},
  acmid =	 268829,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Understanding of fundamental algorithms and designing algorithms for a novel problem are basic skills in Computer Science. Animation is a useful aid in both these areas. We show how to animate algorithms with Microsoft Excel using data visualization and macro programming features of Excel. The user writes an algorithm using the Visual Basic programming language of Excel and defines charts visualizing dynamically the data structures of the algorithm. This approach is suitable especially for small-scale animation, e.g. for course assignments in Computer Science.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=268829&ftid=34917&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:52:59>},
}

@article{Rautama:1997:EAA:268809.268829,
  author =	 {Rautama, E. and Sutinen, E. and Tarhio, J.},
  title =	 {Excel As an Algorithm Animation Environment},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {Sept. 1997},
  volume =	 29,
  number =	 3,
  month =	 jun,
  year =	 1997,
  issn =	 {0097-8418},
  pages =	 {24--26},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/268809.268829},
  doi =		 {10.1145/268809.268829},
  acmid =	 268829,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Understanding of fundamental algorithms and designing algorithms for a novel problem are basic skills in Computer Science. Animation is a useful aid in both these areas. We show how to animate algorithms with Microsoft Excel using data visualization and macro programming features of Excel. The user writes an algorithm using the Visual Basic programming language of Excel and defines charts visualizing dynamically the data structures of the algorithm. This approach is suitable especially for small-scale animation, e.g. for course assignments in Computer Science.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=268829&ftid=34917&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:02>},
}

@inproceedings{Kikuchi:2014:PEB:2759989.2760059,
  author =	 {Kikuchi, Shinji},
  title =	 {Performance Estimation for Business Workflows on
                  Public Cloud Offerings Using Probabilistic Model
                  Checker},
  booktitle =	 {Proceedings of the 2014 IEEE/ACM 7th International
                  Conference on Utility and Cloud Computing},
  series =	 {UCC '14},
  year =	 2014,
  isbn =	 {978-1-4799-7881-6},
  pages =	 {317--326},
  numpages =	 10,
  url =		 {http://dx.doi.org/10.1109/UCC.2014.41},
  doi =		 {10.1109/UCC.2014.41},
  acmid =	 2760059,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  keywords =	 {cloud computing, business process, workflow engine,
                  Software as a Service, service-oriented
                  architecture, formal method, model checking},
  review = 	 {fbie: rejected <2016-01-15 13:53:08>},
}

@article{Ellis:2015:EBD:2737817.2737829,
  author =	 {Ellis, Jason and Fokoue, Achille and Hassanzadeh,
                  Oktie and Kementsietsidis, Anastasios and Srinivas,
                  Kavitha and Ward, Michael J.},
  title =	 {Exploring Big Data with Helix: Finding Needles in a
                  Big Haystack},
  journal =	 {SIGMOD Rec.},
  issue_date =	 {December 2014},
  volume =	 43,
  number =	 4,
  month =	 feb,
  year =	 2015,
  issn =	 {0163-5808},
  pages =	 {43--54},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2737817.2737829},
  doi =		 {10.1145/2737817.2737829},
  acmid =	 2737829,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {While much work has focused on efficient processing of Big Data, little work considers how to understand them. In this paper, we describe Helix, a system for guided exploration of Big Data. Helix provides a unified view of sources, ranging from spreadsheets and XML files with no schema, all the way to RDF graphs and relational data with well-defined schemas. Helix users explore these heterogeneous data sources through a combination of keyword searches and navigation of linked web pages that include information about the schemas, as well as data and semantic links within and across sources. At a technical level, the paper describes the research challenges involved in developing Helix, along with a set of real-world usage scenarios and the lessons learned.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2737829&ftid=1544764&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:16>},
}

@inproceedings{Lesh:2004:IDS:989863.989892,
  author =	 {Lesh, Neal and Mitzenmacher, Michael},
  title =	 {Interactive Data Summarization: An Example
                  Application},
  booktitle =	 {Proceedings of the Working Conference on Advanced
                  Visual Interfaces},
  series =	 {AVI '04},
  year =	 2004,
  isbn =	 {1-58113-867-9},
  location =	 {Gallipoli, Italy},
  pages =	 {183--187},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/989863.989892},
  doi =		 {10.1145/989863.989892},
  acmid =	 989892,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data mining, information visualization, interactive
                  data exploration},
  abstract = 	 {Summarizing large multidimensional datasets is a challenging task, often requiring extensive investigation by a user to identify overall trends and important exceptions to them. While many visualization tools help a user produce a single summary of the data at a time, they require the user to explore the dataset manually. Our idea is to have the computer perform an exhaustive search and inform the user about where further investigation is warranted. Our algorithm takes a large, multidimensional dataset as input, along with a specification of the user's goals, and produces a concise summary that can be clearly visualized in bar graphs or linegraphs. We demonstrate our techniques in a sample prototype for summarizing information stored in spreadsheet databases.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=989892&ftid=262113&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:26>},
}

@article{Yellin:1991:ILI:103135.103137,
  author =	 {Yellin, Daniel M. and Strom, Robert E.},
  title =	 {INC: A Language for Incremental Computations},
  journal =	 {ACM Trans. Program. Lang. Syst.},
  issue_date =	 {April 1991},
  volume =	 13,
  number =	 2,
  month =	 apr,
  year =	 1991,
  issn =	 {0164-0925},
  pages =	 {211--236},
  numpages =	 26,
  url =		 {http://doi.acm.org/10.1145/103135.103137},
  doi =		 {10.1145/103135.103137},
  acmid =	 103137,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {dynamic algorithms, finite differencing, incremental
                  complexity, incrementality, static complexity},
  abstract = 	 {An incremental computation is one that is performed repeatedly on nearly identical inputs. Incremental computations occur naturally in many environments, such as compilers, language-based editors, spreadsheets, and formatters. This article describes a proposed tool for making it easy to write incremental programs. The tool consists of a programming language, INC, and a set of compile-time transformations for the primitive elements of INC. A programmer defines an algorithm in INC without regard to efficient incremental execution. The transformations automatically convert this algorithm into an efficient incremental algorithm. INC is a functional language. The implementation of an INC program is a network of processes. Each INC function is transformed into a process that receives and transmits messages describing changes to its inputs and outputs. We give an overview to the language and illustrate the incremental techniques employed by INC. We present the static and incremental complexity bounds for the primitive INC functions. We also present some example programs illustrating INC's flexibility.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=103137&ftid=32614&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:30>},
}

@inproceedings{Peltonen:2010:FGT:1842752.1842804,
  author =	 {Peltonen, Jari and Felin, Marko and Vartiala, Mikko},
  title =	 {From a Freeform Graphics Tool to a Repository Based
                  Modeling Tool},
  booktitle =	 {Proceedings of the Fourth European Conference on
                  Software Architecture: Companion Volume},
  series =	 {ECSA '10},
  year =	 2010,
  isbn =	 {978-1-4503-0179-4},
  location =	 {Copenhagen, Denmark},
  pages =	 {277--284},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1842752.1842804},
  doi =		 {10.1145/1842752.1842804},
  acmid =	 1842804,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {flexible tool support, freeform graphics, modeling},
  abstract = 	 {Traditional software modeling tools are rigid and formal. There is no support for, e.g. freeform sketching that does not conform to the used meta-model, and hence, a lot of the actual modeling work gets done with other methods. Modeling tools are used merely for documenting the work later on, which is not economical. There is a need for flexible modeling tools that support the modeling in earlier phases of the work by allowing more freeform and informal descriptions as a part of the model. Tools like spreadsheets, word processing tools, and vector graphics tools are commonly used in software development. In this paper, we consider an approach where such a tool is enhanced with modeling support, in order to gain better support for the actual modeling work. We also show how we have created a graphical repository based case tool by using Microsoft Visio, and conclude the approach to be practical.},
  review = 	 {fbie: rejected <2016-01-15 13:53:34>},
}

@inproceedings{dePedroPuente:2007:NMU:1296951.1296961,
  author =	 {de Pedro Puente, Xavier},
  title =	 {New Method Using Wikis and Forums to Evaluate
                  Individual Contributions in Cooperative Work While
                  Promoting Experiential Learning:: Results from
                  Preliminary Experience},
  booktitle =	 {Proceedings of the 2007 International Symposium on
                  Wikis},
  series =	 {WikiSym '07},
  year =	 2007,
  isbn =	 {978-1-59593-861-9},
  location =	 {Montreal, Quebec, Canada},
  pages =	 {87--92},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1296951.1296961},
  doi =		 {10.1145/1296951.1296961},
  acmid =	 1296961,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Tikiwiki CMS/Groupware, action log, assessment,
                  computer supported cooperative learning (CSCL),
                  experiential-reflective learning, individual
                  contributions, knowledge building},
  abstract = 	 {This paper shows a new method for using Wikis, forums, and other web-based productivity tools in blended learning strategies [20][22] to promote the acquisition of competences in Higher education [4] while enhancing experiential learning of students [16] in social collaborative knowledge building scenarios. This methodology also facilitated the grading of student individual contributions in cooperative work, helping to detect any shortcomings that may prevent student active involvement in their learning process, allowing to conduct not only product evaluation but also process evaluation. Based upon previous successful experiences, the free, on-line software platform, TikiWiki CMS/Groupware, was selected to achieve this methodology. [5][6][10][11]. Students had to think about "What's the 'type of contribution' that I'm going to make right now?" before submitting new contributions in forums, comments, or document editions (either text or spreadsheet based). Each student's contribution type and size (in bytes) was stored in a log on the website, and could be queried, filtered, and exported for further analyses. The method was tested on an Environmental Sciences course, and its strengths and weaknesses are discussed in the paper. The method description includes a suggested process to convert student contributions (type and size) into numerical grades. However, the main potential of this method is not just final assessment for student accreditation, but serving data for tutorships with students along the process of the learning activities, in order to detect and revert whatever handicaps that prevented some students improving their contributions to the group work or cooperative learning in time"(much prior to assignment submission to teacher). This preliminary study resulted in a three-times greater time investment by teachers. Further data needs to be collected to better estimate the true costs of this new method.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1296961&ftid=452107&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:39>},
}

@inproceedings{Shen:2002:VIM:1556262.1556323,
  author =	 {Shen, Chia and Vernier, Frederic and Lesh, Neal},
  title =	 {A Visual Interface for Multi-person Exploration of
                  Personal Databases},
  booktitle =	 {Proceedings of the Working Conference on Advanced
                  Visual Interfaces},
  series =	 {AVI '02},
  year =	 2002,
  isbn =	 {1-58113-537-8},
  location =	 {Trento, Italy},
  pages =	 {363--364},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1556262.1556323},
  doi =		 {10.1145/1556262.1556323},
  acmid =	 1556323,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {multi-person interactive visual interface, tabletop
                  display},
  abstract = 	 {The Personal Digital Historian (PDH) is an ongoing research project aimed at allowing small groups of people co-present to casually browse, embellish, and explore large collections of their personal data, such as pictures, video, or more business-related items such as spreadsheets or PowerPoint slides. In this interactive poster, we demonstrate our initial prototype system which is designed for a tabletop display. The interface allows people to organize their images along the four questions essential to storytelling: who?, when?, where?, and what? Users are provided with a wide variety of flexible interaction methods, including region of interest query specification with in-place freeform stroke input, image-based book marking, suggestion generation via automatic query relaxation, and output summarization. With this interface, the users can enjoy their conversation while having the photos at their fingertips, rather than being distracted by the effort of formulating queries.},
  review = 	 {fbie: rejected <2016-01-15 13:53:44>},
}

@inproceedings{Aggarwal:2014:EVP:2630602.2630606,
  author =	 {Aggarwal, Dippy and Curry, Edward and Davis, Karen
                  C.},
  title =	 {Employing Virtual Power Analytics and Linked Data
                  for Enterprise IT Energy Informatics},
  booktitle =	 {Proceedings of Semantic Web Information Management
                  on Semantic Web Information Management},
  series =	 {SWIM'14},
  year =	 2014,
  isbn =	 {978-1-4503-2994-1},
  location =	 {Snowbird, UT, USA},
  pages =	 {3:1--3:4},
  articleno =	 3,
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2630602.2630606},
  doi =		 {10.1145/2630602.2630606},
  acmid =	 2630606,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Data Integration, Energy Informatics, Green IT,
                  Linked Data, Power Analytics, Semantic Web},
  abstract = 	 {The paper provides a solution to an organization's challenge for reducing its ecological footprint. We develop a framework for visualizing information concerning power consumption of IT devices in real-time using power metering approaches and leverage semantic web technologies to weave information that is dispersed across different data sources, ranging from an organization's asset databases to excel spreadsheets to the data available on manufacturer's websites. Visualizing the aforementioned information and bringing it together in one application can help organizations in understanding and adapting their energy consumption behavior in order to better support environmentally sustainable practices. The purpose of this project, from a power analytics standpoint, is twofold: (1) it aims to provide users with insight into their device's current power consumption without leaving a footprint on their machine, and (2) to analyze if one method gives more accurate results than others. We performed analysis using Microsoft Joulemeter and power estimation using software design methodologies (with numbers from smart meters as our benchmark).},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2630606&ftid=1547576&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:48>},
}

@inproceedings{Handel:2011:WAO:1958824.1958870,
  author =	 {Handel, Mark J. and Poltrock, Steven},
  title =	 {Working Around Official Applications: Experiences
                  from a Large Engineering Project},
  booktitle =	 {Proceedings of the ACM 2011 Conference on Computer
                  Supported Cooperative Work},
  series =	 {CSCW '11},
  year =	 2011,
  isbn =	 {978-1-4503-0556-3},
  location =	 {Hangzhou, China},
  pages =	 {309--312},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1958824.1958870},
  doi =		 {10.1145/1958824.1958870},
  acmid =	 1958870,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {mission critial applications, software
                  infrastructure, work-arounds},
  abstract = 	 {We describe facets of specialized software applications developed to support a large collaborative engineering program. Although many of the applications were bespoke efforts, designed to the requirements of users, virtually all major applications have an unofficial spreadsheet or database backing up the official application. These tools invariably play a critical but unofficial role in the day-to-day work, acting as more than just as a work-around, while the official applications are used primarily for mandated record keeping and auditing purposes. Surprisingly, there is often management approval for these unofficial applications, but at the same time, desire to elimination these applications and only use the official applications. We discuss the implications of this finding for future collaborative applications and long-term record keeping.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1958870&ftid=940227&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:53>},
}

@inproceedings{Doering:2011:VSR:2151054.2151094,
  author =	 {Doering, Andreas and Ineichen, Hanspeter},
  title =	 {Visualization of Simulation Results for the PERCS
                  Hub Chip Performance Verification},
  booktitle =	 {Proceedings of the 4th International ICST Conference
                  on Simulation Tools and Techniques},
  series =	 {SIMUTools '11},
  year =	 2011,
  isbn =	 {978-1-936968-00-8},
  location =	 {Barcelona, Spain},
  pages =	 {216--221},
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=2151054.2151094},
  acmid =	 2151094,
  publisher =	 {ICST (Institute for Computer Sciences,
                  Social-Informatics and Telecommunications
                  Engineering)},
  address =	 {ICST, Brussels, Belgium, Belgium},
  abstract = 	 {Performance verification ensures that an implementation of a given architecture will deliver the expected performance. The Productive, Easy-to-use, Reliable Computing System has particularly high performance goals measured at the progress of technology. Its Hub chip constitutes the main network and I/O component, and therefore strongly affects the system performance. Performance verification requires the rapid detection of performance deficits in tests with regular request patterns as well as the analysis of sophisticated problems in more complex test situations. In this paper, visualization methods and tools used in the performance verification of the PERCS Hub chip are presented. Not only existing tools, such as spreadsheets, were integrated, but also a new dedicated tool was developed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2151094&ftid=1152325&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:53:57>},
}

@inproceedings{Serrano:2010:LAF:2433508.2433542,
  author =	 {Serrano, Ramiro and Otal, Sara Helena},
  title =	 {Learning Accounting and Financial Consequences of
                  Decisions Under a Stochastic Approach},
  booktitle =	 {Proceedings of the Winter Simulation Conference},
  series =	 {WSC '10},
  year =	 2010,
  isbn =	 {978-1-4244-9864-2},
  location =	 {Baltimore, Maryland},
  pages =	 {305--316},
  numpages =	 12,
  url =		 {http://dl.acm.org/citation.cfm?id=2433508.2433542},
  acmid =	 2433542,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Using spreadsheets and add-ins facilitates learning new concepts and acquiring necessary skills for accounting professionals. This paper presents an educational experience related to accounting education and financial decision-making based on an accounting and finance comprehensive deterministic simulation model developed in Visual Basic for Applications and Excel that, used jointly with a Monte Carlo simulator, incorporates the possibility of adding stochastic behaviour for the input variables and the analysis of the outcome. The learning experience is based on active learning and employs several teaching methodologies (Problem-Based Learning, teamwork, conceptual maps) to promote student development of critical thinking and to get the advantages and disadvantages of adding uncertainty to the analysis of financial statements and posterior decisions made upon that basis.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2433542&ftid=1339416&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:01>},
}

@inproceedings{Macal:2007:AMS:1351542.1351564,
  author =	 {Macal, Charles M. and North, Michael J.},
  title =	 {Agent-based Modeling and Simulation: Desktop ABMS},
  booktitle =	 {Proceedings of the 39th Conference on Winter
                  Simulation: 40 Years! The Best is Yet to Come},
  series =	 {WSC '07},
  year =	 2007,
  isbn =	 {1-4244-1306-0},
  location =	 {Washington D.C.},
  pages =	 {95--106},
  numpages =	 12,
  url =		 {http://dl.acm.org/citation.cfm?id=1351542.1351564},
  acmid =	 1351564,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Agent-based modeling and simulation (ABMS) is a new approach to modeling systems comprised of autonomous, interacting agents. ABMS promises to have far-reaching effects on the way that businesses use computers to support decision-making and researchers use electronic laboratories to support their research. Some have gone so far as to contend that ABMS "is a third way of doing science," in addition to traditional deductive and inductive reasoning (Axelrod 1997b). Computational advances have made possible a growing number of agent-based models across a variety of application domains. Applications range from modeling agent behavior in the stock market, supply chains, and consumer markets, to predicting the spread of epidemics, the threat of bio-warfare, and the factors responsible for the fall of ancient civilizations. This tutorial describes the theoretical and practical foundations of ABMS, identifies toolkits and methods for developing agent models, and illustrates the development of a simple agent-based model of shopper behavior using spreadsheets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1351564&ftid=431893&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:04>},
}

@inproceedings{Morley:2013:USD:2676255.2676355,
  author =	 {Morley, David and Lu, Ming and AbouRizk, Simaan},
  title =	 {Utilizing Simulation Derived Quantitative Formulas
                  for Accurate Excavator Hauler Fleet Selection},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  location =	 {Washington, D.C.},
  pages =	 {3018--3029},
  numpages =	 12,
  url =		 {http://dl.acm.org/citation.cfm?id=2676255.2676355},
  acmid =	 2676355,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Discrete event simulation (DES) produces models of greater granularity and higher accuracy in analysis of heavy construction operations than classic quantitative techniques; specifically utilizing average production rates for determining the fleet required for and duration of earthmoving operations. Nonetheless, the application of DES is not readily applied beyond academic work for high level analysis in the heavy construction industry. Field level planners default to the use of average production rates, which can be easily applied with simple spreadsheet tools and allows quick recalculations to be performed when existing input data is changed or more data becomes available. To aid in fleet selection and determination of the duration of site grading earthworks operations where one fleet is applied, this research presents a new approach by developing quantitative formulas from DES analysis. The approach simplifies DES application and reduces the barrier to access simulation-generalized and field-applicable knowledge, while providing greater accuracy than simply relying on average production rates.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2676355&ftid=1504415&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:20>},
}

@inproceedings{Morley:2013:USD:2675983.2676355,
  author =	 {Morley, David and Lu, Ming and AbouRizk, Simaan},
  title =	 {Utilizing Simulation Derived Quantitative Formulas
                  for Accurate Excavator Hauler Fleet Selection},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  isbn =	 {978-1-4799-2077-8},
  location =	 {Washington, D.C.},
  pages =	 {3018--3029},
  numpages =	 12,
  url =		 {http://dl.acm.org/citation.cfm?id=2675983.2676355},
  acmid =	 2676355,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Discrete event simulation (DES) produces models of greater granularity and higher accuracy in analysis of heavy construction operations than classic quantitative techniques; specifically utilizing average production rates for determining the fleet required for and duration of earthmoving operations. Nonetheless, the application of DES is not readily applied beyond academic work for high level analysis in the heavy construction industry. Field level planners default to the use of average production rates, which can be easily applied with simple spreadsheet tools and allows quick recalculations to be performed when existing input data is changed or more data becomes available. To aid in fleet selection and determination of the duration of site grading earthworks operations where one fleet is applied, this research presents a new approach by developing quantitative formulas from DES analysis. The approach simplifies DES application and reduces the barrier to access simulation-generalized and field-applicable knowledge, while providing greater accuracy than simply relying on average production rates.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2676355&ftid=1504415&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:23>},
}

@inproceedings{Cheng:2011:SOP:2431518.2431802,
  author =	 {Cheng, Howe Chiat and Chan, David Yin Kai},
  title =	 {Simulation Optimization of Part Input Sequence in a
                  Flexible Manufacturing System},
  booktitle =	 {Proceedings of the Winter Simulation Conference},
  series =	 {WSC '11},
  year =	 2011,
  location =	 {Phoenix, Arizona},
  pages =	 {2374--2382},
  numpages =	 9,
  url =		 {http://dl.acm.org/citation.cfm?id=2431518.2431802},
  acmid =	 2431802,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {This paper describes the development of a simulation model for production planning personnel to carry out optimization of part input sequence. The model simulates a flexible manufacturing system for the production of machined components. Using a custom built user interface, the planner imports production and demand data from an Excel spreadsheet into the model. The model optimizes part input sequence by simulating different combinations of part input sequences and determining the combination with the highest total slack time. Simulation conducted by the authors using this model shows that even a short, partial optimization run yields a schedule with improved slack. Presented in the paper are the steps involved in the development of the model and the benefits of the simulation-optimization model to the planner.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2431802&ftid=1338455&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:26>},
}

@inproceedings{Huo:2008:KVQ:1385569.1385609,
  author =	 {Huo, Jiwen},
  title =	 {KMVQL: A Visual Query Interface Based on Karnaugh
                  Map},
  booktitle =	 {Proceedings of the Working Conference on Advanced
                  Visual Interfaces},
  series =	 {AVI '08},
  year =	 2008,
  isbn =	 {978-1-60558-141-5},
  location =	 {Napoli, Italy},
  pages =	 {243--250},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/1385569.1385609},
  doi =		 {10.1145/1385569.1385609},
  acmid =	 1385609,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Karnuagh map, direct manipulation, query
                  formulation, visual query, visualization},
  abstract = 	 {Extracting information from data is an interactive process. Visualization plays an important role, particularly during data inspection. Querying is also important, allowing the user to isolate promising portions of the data. As a result, data exploration environments normally include both, integrating them tightly. This paper presents KMVQL, the Karnaugh map based visual query language. It has been designed to support the interactive exploration of multidimensional datasets. KMVQL uses Karnaugh map as the visual representation for Boolean queries. It provides a visual query interface to help users formulate arbitrarily complex Boolean queries by direct manipulation operations. With KMVQL, users do not have to worry about the logic operators any more, which makes Boolean query specification much easier. The Karnaugh maps also function as visualization spreadsheets that provide seamless integration of queries with their results, which is helpful for users to better understand the data and refine their queries efficiently.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1385609&ftid=544771&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:30>},
}

@inproceedings{Liu:2006:VLE:1134285.1134465,
  author =	 {Liu, Na},
  title =	 {Visual Languages for Event Integration
                  Specification},
  booktitle =	 {Proceedings of the 28th International Conference on
                  Software Engineering},
  series =	 {ICSE '06},
  year =	 2006,
  isbn =	 {1-59593-375-1},
  location =	 {Shanghai, China},
  pages =	 {969--972},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1134285.1134465},
  doi =		 {10.1145/1134285.1134465},
  acmid =	 1134465,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {domain-specific visual language tools, event
                  handling, meta-CASE tools},
  abstract = 	 {We are exploring existing approaches and developing new techniques for visual event-based system integration. We are using domain-specific visual languages with different high-level visual metaphors (including Tool Abstraction, Event-Query-Filter-Action and Spreadsheet) to specify event-handling support and provide backend processing tool support for event integration specification and visualisation of event propagation. We aim to generalise from three exemplar visual event-driven system metaphors and develop a new, generic visual event handling metaphor. From this we will build a visual environment for specifying event-based system integration. The visual metaphor we are developing should adapt the event-based communication model to a wide range of application domains, and also should support complex and intelligent system design and implementation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1134465&ftid=355469&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:34>},
}

@inproceedings{Dunne:2012:CCC:2307729.2307795,
  author =	 {Dunne, Cody},
  title =	 {Charting Collections of Connections in Social Media:
                  Creating Visualizations with NodeXL},
  booktitle =	 {Proceedings of the 13th Annual International
                  Conference on Digital Government Research},
  series =	 {dg.o '12},
  year =	 2012,
  isbn =	 {978-1-4503-1403-9},
  location =	 {College Park, Maryland, USA},
  pages =	 {300--301},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2307729.2307795},
  doi =		 {10.1145/2307729.2307795},
  acmid =	 2307795,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {NodeXL, network analysis, network visualization},
  abstract = 	 {Networks are a data structure common found across all social media services that allow populations to author collections of connections. Analyzing these networks involves understanding the complex relationships between individuals, as well as any attributes, statistics, or groupings associated with them. The Social Media Research Foundation's NodeXL project makes network analysis accessible to most users of the Excel spreadsheet application. With NodeXL, network visualizations become as easy to create as pie charts. Applying the tool to a range of social media networks has already revealed the variations present in online social spaces. A NodeXL tutorial and visualizations of various networks will be presented, along with new techniques for text analysis and simplifying your network visualizations.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2307795&ftid=1257651&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:38>},
}

@inproceedings{Leopold:2002:WWV:511446.511476,
  author =	 {Leopold, Jennifer and Heimovics, Meg and Palmer,
                  Tyler},
  title =	 {Webformulate: A Web-based Visual Continual Query
                  System},
  booktitle =	 {Proceedings of the 11th International Conference on
                  World Wide Web},
  series =	 {WWW '02},
  year =	 2002,
  isbn =	 {1-58113-449-5},
  location =	 {Honolulu, Hawaii, USA},
  pages =	 {221--231},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/511446.511476},
  doi =		 {10.1145/511446.511476},
  acmid =	 511476,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {continual query, visual programming language, visual
                  query system},
  abstract = 	 {Today there is a plethora of data accessible via the Internet. The Web has greatly simplified the process of searching for, accessing, and sharing information. However, a considerable amount of Internet-distributed data still goes unnoticed and unutilized, particularly in the case of frequently-updated, Internet-distributed databases. In this paper we give an overview of WebFormulate, a Web-based visual continual query system that addresses the problems associated with formulating temporal ad hoc analyses over networks of heterogeneous, frequently-updated data sources. The main distinction between this system and existing Internet facilities to retrieve information and assimilate it into computations is that WebFormulate provides the necessary facilities to perform continual queries, developing and maintaining dynamic links such that Web-based computations and reports automatically maintain themselves. A further distinction is that this system is specifically designed for users of spreadsheet-level ability, rather than professional programmers.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=511476&ftid=70822&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:42>},
}

@inproceedings{Khan:2014:UJW:2661088.2661090,
  author =	 {Khan, Faiz and Foley-Bourgon, Vincent and Kathrotia,
                  Sujay and Lavoie, Erick and Hendren, Laurie},
  title =	 {Using JavaScript and WebCL for Numerical
                  Computations: A Comparative Study of Native and Web
                  Technologies},
  booktitle =	 {Proceedings of the 10th ACM Symposium on Dynamic
                  Languages},
  series =	 {DLS '14},
  year =	 2014,
  isbn =	 {978-1-4503-3211-8},
  location =	 {Portland, Oregon, USA},
  pages =	 {91--102},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2661088.2661090},
  doi =		 {10.1145/2661088.2661090},
  acmid =	 2661090,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {C, OpenCL, WebCL, benchmark, computational dwarfs,
                  javascript, numerical computation, parallelism, web
                  browser},
  abstract = 	 {From its modest beginnings as a tool to validate forms, JavaScript is now an industrial-strength language used to power online applications such as spreadsheets, IDEs, image editors and even 3D games. Since all modern web browsers support JavaScript, it provides a medium that is both easy to distribute for developers and easy to access for users. This paper provides empirical data to answer the question: Is JavaScript fast enough for numerical computations? By measuring and comparing the runtime performance of benchmarks representative of a wide variety of scientific applications, we show that sequential JavaScript is within a factor of 2 of native code. Parallel code using WebCL shows speed improvements of up to 2.28 over JavaScript for the majority of the benchmarks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2661090&ftid=1505290&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:45>},
}

@article{Khan:2014:UJW:2775052.2661090,
  author =	 {Khan, Faiz and Foley-Bourgon, Vincent and Kathrotia,
                  Sujay and Lavoie, Erick and Hendren, Laurie},
  title =	 {Using JavaScript and WebCL for Numerical
                  Computations: A Comparative Study of Native and Web
                  Technologies},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {February 2015},
  volume =	 50,
  number =	 2,
  month =	 oct,
  year =	 2014,
  issn =	 {0362-1340},
  pages =	 {91--102},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2775052.2661090},
  doi =		 {10.1145/2775052.2661090},
  acmid =	 2661090,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {C, OpenCL, WebCL, benchmark, computational dwarfs,
                  javascript, numerical computation, parallelism, web
                  browser},
  abstract = 	 {From its modest beginnings as a tool to validate forms, JavaScript is now an industrial-strength language used to power online applications such as spreadsheets, IDEs, image editors and even 3D games. Since all modern web browsers support JavaScript, it provides a medium that is both easy to distribute for developers and easy to access for users. This paper provides empirical data to answer the question: Is JavaScript fast enough for numerical computations? By measuring and comparing the runtime performance of benchmarks representative of a wide variety of scientific applications, we show that sequential JavaScript is within a factor of 2 of native code. Parallel code using WebCL shows speed improvements of up to 2.28 over JavaScript for the majority of the benchmarks.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2661090&ftid=1505290&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:49>},
}

@article{Jacob:1986:SLD:27623.27624,
  author =	 {Jacob, Robert J. K.},
  title =	 {A Specification Language for Direct-manipulation
                  User Interfaces},
  journal =	 {ACM Trans. Graph.},
  issue_date =	 {Oct. 1986},
  volume =	 5,
  number =	 4,
  month =	 oct,
  year =	 1986,
  issn =	 {0730-0301},
  pages =	 {283--317},
  numpages =	 35,
  url =		 {http://doi.acm.org/10.1145/27623.27624},
  doi =		 {10.1145/27623.27624},
  acmid =	 27624,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A direct-manipulation user interface presents a set of visual representations on a display and a repertoire of manipulations that can be performed on any of them. Such representations might include screen buttons, scroll bars, spreadsheet cells, or flowchart boxes. Interaction techniques of this kind were first seen in interactive graphics systems; they are now proving effective in user interfaces for applications that are not inherently graphical. Although they are often easy to learn and use, these interfaces are also typically difficult to specify and program clearly.
Examination of direct-manipulation interfaces reveals that they have a coroutine-like structure and, despite their surface appearance, a peculiar, highly moded dialogue. This paper introduces a specification technique for direct-manipulation interfaces based on these observations. In it, each locus of dialogue is described as a separate object with a single-thread state diagram, which can be suspended and resumed, but retains state. The objects are then combined to define the overall user interface as a set of coroutines, rather than inappropriately as a single highly regular state transition diagram. An inheritance mechanism for the interaction objects is provided to avoid repetitiveness in the specifications. A prototype implementation of a user-interface management system based on this approach is described, and example specifications are given.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=27624&ftid=7340&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:54:55>},
}

@inproceedings{Pirolli:1996:TLT:948449.948460,
  author =	 {Pirolli, Peter and Rao, Ramana},
  title =	 {Table Lens As a Tool for Making Sense of Data},
  booktitle =	 {Proceedings of the Workshop on Advanced Visual
                  Interfaces},
  series =	 {AVI '96},
  year =	 1996,
  isbn =	 {0-89791-834-7},
  location =	 {Gubbio, Italy},
  pages =	 {67--80},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/948449.948460},
  doi =		 {10.1145/948449.948460},
  acmid =	 948460,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {GOMS, database visualization, evaluation,
                  exploratory data analysis, information
                  visualization, multivariate visualization},
  abstract = 	 {The Table Lens is a visualization for searching for patterns and outliers in multivariate datasets. It supports a lightweight form of exploratory data analysis (EDA) by integrating a familiar organization, the table, with graphical representations and a small set of direct manipulation operators. We examine the EDA process as a special case of a generic process, which we call sensemaking. Using a GOMS methodology, we characterize a few central EDA tasks and compare performance of the Table Lens and one of the best of the more traditional graphical tools for EDA i.e. Splus. This analysis reveals that Table Lens is more or less on par with the power of Splus, while requiring the use of fewer specialized graphical representations. It essentially combines the graphical power of Splus with the direct manipulation and generic properties of spreadsheets and relational database front ends. We also propose a number of design refinements that are suggested by our task characterizations and analyses.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=948460&ftid=239312&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:01>},
}

@inproceedings{Faget:2005:ADE:1162708.1162954,
  author =	 {Faget, Patrick and Eriksson, Ulf and Herrmann,
                  Frank},
  title =	 {Applying Discrete Event Simulation and an Automated
                  Bottleneck Analysis As an Aid to Detect Running
                  Production Constraints},
  booktitle =	 {Proceedings of the 37th Conference on Winter
                  Simulation},
  series =	 {WSC '05},
  year =	 2005,
  isbn =	 {0-7803-9519-0},
  location =	 {Orlando, Florida},
  pages =	 {1401--1407},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=1162708.1162954},
  acmid =	 1162954,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Discrete event simulation is an important decision support tool to evaluate changes in manufacturing, distribution or process facilities. The challenge arises when it comes to the integration of simulation as an effective tool to detect manufacturing constraints and to suggest improvement alternatives. This paper describes the application of a method for detecting bottlenecks in discrete event models developed by Toyota Motor Company. The objective in this case is to automate the bottleneck analysis facilitating the understanding and adoption of simulation by decision makers without knowledge of simulation. The main results of this paper are the validation of the bottleneck detection method and its integration with MS Excel spreadsheets. Moreover system improvement alternatives are presented by the use of design of experiments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1162954&ftid=373175&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:05>},
}

@inproceedings{Shulman:2011:DST:2037556.2037632,
  author =	 {Shulman, Stuart},
  title =	 {DiscoverText: Software Training to Unlock the Power
                  of Text},
  booktitle =	 {Proceedings of the 12th Annual International Digital
                  Government Research Conference: Digital Government
                  Innovation in Challenging Times},
  series =	 {dg.o '11},
  year =	 2011,
  isbn =	 {978-1-4503-0762-8},
  location =	 {College Park, Maryland, USA},
  pages =	 {373--373},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2037556.2037632},
  doi =		 {10.1145/2037556.2037632},
  acmid =	 2037632,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {archiving, metadata, software, sorting, text
                  analysis},
  abstract = 	 {This tutorial provides software training in "DiscoverText," which is a powerful, text analytic software developed by Professor Shulman. His work advances text mining and natural language processing research. The software training will link these worlds via straightforward and easy to understand explanations of software features that can be tailored for all experience levels and industries. This tutorial introduces new users to the powerful tools for archiving, searching and sorting web-based text from sources, including social media and public comments from a wide range of sources. DiscoverText eases the collection, archiving and sorting of text collected via Twitter and the Facebook Graph APIs, or generic RSS feeds or uploaded in spreadsheets, archives and XML format.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2037632&ftid=1035817&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:10>},
}

@inproceedings{McKenna:2000:MCD:510378.510519,
  author =	 {McKenna, Iain H. and Little, Stephen},
  title =	 {Military Concept Development: Developing Tactics
                  Using Low Cost, Accessible Simulations},
  booktitle =	 {Proceedings of the 32Nd Conference on Winter
                  Simulation},
  series =	 {WSC '00},
  year =	 2000,
  isbn =	 {0-7803-6582-8},
  location =	 {Orlando, Florida},
  pages =	 {991--1000},
  numpages =	 10,
  url =		 {http://dl.acm.org/citation.cfm?id=510378.510519},
  acmid =	 510519,
  publisher =	 {Society for Computer Simulation International},
  address =	 {San Diego, CA, USA},
  abstract = 	 {The Royal Navy's Maritime Warfare Centre (MWC) is responsible to the UK Commander-in-Chief Fleet (CinCFleet) and was formed with the purpose of developing operational tactics and procedures to optimize the capability of the Fleet's platforms, sensors and weapon systems.Evaluating tactics at sea requires a considerable amount of forward planning and ties up valuable and expensive assets. It is therefore important that the candidate tactics must be developed to a sufficient level of maturity on-shore. This is done through a combination of individual brainpower, paper studies and computer simulation. The computer simulation must be inexpensive, totally flexible, sufficiently accurate, reliable and above all easily available to, and usable by, the individual tactical desk officers.Any simulations developed need to be easily adaptable. Tactical Development is not a formally structured process; software development is not easy when there are no formal requirements. The MWC have investigated using the Spreadsheet Excel to form the basis of such simulations. This paper discusses the advantages and disadvantages of this approach, in creating simulations that can be used for developing tactics that have the necessary degree of flexibility, integrity and usability. A specific example of an application to a particular problem will be illustrated.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=510519&ftid=69869&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:17>},
}

@inproceedings{Xhafa:2008:WIH:1497308.1497366,
  author =	 {Xhafa, Fatos and Barolli, Leonard and Martos, David},
  title =	 {A WEB Interface for HyperSim-G Grid Simulation
                  Package},
  booktitle =	 {Proceedings of the 10th International Conference on
                  Information Integration and Web-based Applications
                  \& Services},
  series =	 {iiWAS '08},
  year =	 2008,
  isbn =	 {978-1-60558-349-5},
  location =	 {Linz, Austria},
  pages =	 {312--317},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1497308.1497366},
  doi =		 {10.1145/1497308.1497366},
  acmid =	 1497366,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In this paper we present the design and implementation of a Web interface for HyperSim-G Grid simulation package. The Web interface aims to facilitate the work of users with the Grid simulator package. Thus, through the Web interface, users can remotely run their own simulations, trace the state of the simulations, export the simulation results as well as graphically represent them for a better understanding. Also, the interface facilitates the configuration of many parameters of the simulator as opposed to the straightway command line running of the simulator. Moreover, all the simulation results are stored at the server side and can be consulted and extracted at any time either in pdf or spreadsheet form. The Web application is based on Condor queueing system running on a cluster to allow a large number of users run the simulator simultaneously.},
  review = 	 {fbie: rejected <2016-01-15 13:55:23>},
}

@inproceedings{Crissey:1985:ICS:320599.322567,
  author =	 {Crissey, Brian and Sanders, Dean},
  title =	 {Introducing Computer Science in a Liberal Arts
                  College (Abstract Only)},
  booktitle =	 {Proceedings of the 1985 ACM Thirteenth Annual
                  Conference on Computer Science},
  series =	 {CSC '85},
  year =	 1985,
  isbn =	 {0-89791-150-4},
  location =	 {New Orleans, Louisiana, USA},
  pages =	 {431--},
  url =		 {http://doi.acm.org/10.1145/320599.322567},
  doi =		 {10.1145/320599.322567},
  acmid =	 322567,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The introductory computer science course often plays a dual role in the resource limited environment of a small liberal arts college. It must provide a firm foundation for the computer science major while providing a service function to the rest of the college. This paper describes such a course that is being developed at Linfield College. By emphasizing personal computers and introducing general purpose tools such as word processors, spreadsheets, database managers, and communications packages, the computer is shown to be a tool that can be used without learning the intricacies of programming. Hands-on experience with these packages provides a good basis for discussions of the breadth of computer science, of current trends, and of related social concerns. Program design and construction can be introduced with tools such as Warnier/Orr diagrams and Karel the Robot. Customized software can be constructed with an application generator.},
  review = 	 {fbie: rejected <2016-01-15 13:55:28>},
}

@inproceedings{Shankar:2012:SCS:2132176.2132269,
  author =	 {Shankar, Kalpana},
  title =	 {Self-archiving and Collaboration in Science 2.0: An
                  Exploratory Study},
  booktitle =	 {Proceedings of the 2012 iConference},
  series =	 {iConference '12},
  year =	 2012,
  isbn =	 {978-1-4503-0782-6},
  location =	 {Toronto, Ontario, Canada},
  pages =	 {513--514},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2132176.2132269},
  doi =		 {10.1145/2132176.2132269},
  acmid =	 2132269,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data sharing, open science, scientific work
                  practices},
  abstract = 	 {The use of information technologies (from formal electronic laboratory notebooks to informal word processing files and spreadsheets) for tracking research results, local and collaborative laboratory data management, and the teaching of basic scientific methodology are of increasing importance to the conduct of scientific research. While there has been a significant amount of research interest in large-scale collaboration and the use of cyberinfrastructure, there is still a great deal of work being done in "small science". This poster presents preliminary results from a comparative study of self-archiving and data management practices in two scientific portals, myexperiment.org and openwetware.org. Analysis of the sites to suggest how scientists choose these portals, how they use to collaborate, and how they are integrated into other information practices will be discussed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2132269&ftid=1127244&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:32>},
}

@inproceedings{Maas:2005:ASI:1162708.1162952,
  author =	 {Maas, Sara L. and Standridge, Charles R.},
  title =	 {Applying Simulation to Interative Manufacturing Cell
                  Design},
  booktitle =	 {Proceedings of the 37th Conference on Winter
                  Simulation},
  series =	 {WSC '05},
  year =	 2005,
  isbn =	 {0-7803-9519-0},
  location =	 {Orlando, Florida},
  pages =	 {1392--1400},
  numpages =	 9,
  url =		 {http://dl.acm.org/citation.cfm?id=1162708.1162952},
  acmid =	 1162952,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Launching a manufacturing cell to be efficient and lean, yet profitable, is a time-consuming process and is often based on many assumptions. The utilization of simulation models to help design the cell and the logistical structure to support it can expedite and streamline the development process. Assumptions and designs can be validated to help insure effective operations as soon as possible. We have developed a generic simulation model and associated capacity analysis, schedule planning, and target inventory setting software to support the computer based assessment of the operation of cells typical to the plastic manufacturing industry before capital investments are finalized. Model input describes a particular cell, the products it produces, and customer demand for these products. Results show the customer service level, product inventory levels, equipment utilization, and the daily production schedule. Spreadsheet software supports data entry and report examination. All software is integrated in a single simulation environment.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1162952&ftid=372924&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:36>},
}

@inproceedings{Gonzalez:2010:GFT:1807128.1807158,
  author =	 {Gonzalez, Hector and Halevy, Alon and Jensen,
                  Christian S. and Langen, Anno and Madhavan, Jayant
                  and Shapley, Rebecca and Shen, Warren},
  title =	 {Google Fusion Tables: Data Management, Integration
                  and Collaboration in the Cloud},
  booktitle =	 {Proceedings of the 1st ACM Symposium on Cloud
                  Computing},
  series =	 {SoCC '10},
  year =	 2010,
  isbn =	 {978-1-4503-0036-0},
  location =	 {Indianapolis, Indiana, USA},
  pages =	 {175--180},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1807128.1807158},
  doi =		 {10.1145/1807128.1807158},
  acmid =	 1807158,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {cloud-services, geo-spatial data, visualization},
  abstract = 	 {Google Fusion Tables is a cloud-based service for data management and integration. Fusion Tables enables users to upload tabular data files (spreadsheets, CSV, KML), currently of up to 100MB. The system provides several ways of visualizing the data (e.g., charts, maps, and timelines) and the ability to filter and aggregate the data. It supports the integration of data from multiple sources by performing joins across tables that may belong to different users. Users can keep the data private, share it with a select set of collaborators, or make it public and thus crawlable by search engines. The discussion feature of Fusion Tables allows collaborators to conduct detailed discussions of the data at the level of tables and individual rows, columns, and cells. This paper describes the inner workings of Fusion Tables, including the storage of data in the system and the tight integration with the Google Maps infrastructure.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1807158&ftid=809872&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:42>},
}

@inproceedings{Williams:2003:SCS:1030818.1030852,
  author =	 {Williams, Edward J. and Gunal, Ali},
  title =	 {Supply Chain Simulation Software I: Supply Chain
                  Simulation and Analysis with SimFlex\&Trade;},
  booktitle =	 {Proceedings of the 35th Conference on Winter
                  Simulation: Driving Innovation},
  series =	 {WSC '03},
  year =	 2003,
  isbn =	 {0-7803-8132-7},
  location =	 {New Orleans, Louisiana},
  pages =	 {231--237},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=1030818.1030852},
  acmid =	 1030852,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {As businesses and industries become steadily more global in their operational scope, and more intensely competitive, achievement of a lean, efficient, reliable supply chain increases in both importance and complexity. Recent research comprises many ideas to help engineers and managers construct and maintain such a supply chain. Additionally, numerous software vendors have endeavored to develop software packages specifically adapted to the modeling and analysis of supply chains. To earn regular value-added use within a business, such a package must offer high analytical power, ease of learning and use, and ability to interface with databases and spreadsheets for convenient import of data and export of results. This paper presents an overview and brief tutorial of SimFlex™, a supply-chain simulation software package offering these virtues.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1030852&ftid=293645&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:45>},
}

@inproceedings{Ito:2003:VED:900051.900092,
  author =	 {Ito, Kimihito and Tanaka, Yuzuru},
  title =	 {A Visual Environment for Dynamic Web Application
                  Composition},
  booktitle =	 {Proceedings of the Fourteenth ACM Conference on
                  Hypertext and Hypermedia},
  series =	 {HYPERTEXT '03},
  year =	 2003,
  isbn =	 {1-58113-704-4},
  location =	 {Nottingham, UK},
  pages =	 {184--193},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/900051.900092},
  doi =		 {10.1145/900051.900092},
  acmid =	 900092,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {hypermedia, intelligentPad, personalization, web
                  application linkage, web application wrapping},
  abstract = 	 {HTML-based interface technologies enable end-users to easily use various remote Web applications. However, it is difficult for end-users to compose new integrated tools of both existing Web applications and legacy local applications such as spreadsheets, chart tools and database. In this paper, the authors propose a new framework where end-users can wrap remote Web applications into visual components called pads, and functionally combine them together through drag & drop-paste operations. The authors use, as the basis, a meme media architecture IntelligentPad that was proposed by the second author. In the IntelligentPad architecture, each visual component called a pad has slots as data I/O ports. By pasting a pad onto another pad users can integrate their functionalities. The framework presented in this paper allows users to visually create a wrapper pad for any Web application by defining HTML nodes within the Web application to work as slots. Examples of such a node include input-forms and text strings on Web pages. Users can directly manipulate both wrapped Web applications and wrapped local legacy tools on their desktop screen to define application linkages among them. Since no programming expertise is required to wrap Web applications or to functionally combine them together, end-users can build new integrated tools of both wrapped Web applications and local legacy applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=900092&ftid=228529&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:55:52>},
}

@inproceedings{Brown:2000:IMS:570475.570483,
  author =	 {Brown, Richard L. W.},
  title =	 {Interest Made Simple with Arrays},
  booktitle =	 {Proceedings of the International Conference on
                  APL-Berlin-2000 Conference},
  series =	 {APL '00},
  year =	 2000,
  isbn =	 {1-58113-182-8},
  location =	 {Berlin, Germany},
  pages =	 {55--60},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/570475.570483},
  doi =		 {10.1145/570475.570483},
  acmid =	 570483,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A better financial calculatorStudents of the mathematics of finance seem to be comfortable using calculators to evaluate formulas or numerical expressions. They are typically much less comfortable writing programs in BASIC (or C or Java etc.) even in situations where the calculator solution is tedious and a short program would do the job efficiently. Spreadsheet models, with an emphasis on formulas as opposed to programs, are quite a reasonable and intuitive tool. But spreadsheet formulas seem to be about cells rather than money, time, and interest rates.The ideal tool would be a better calculator. APL and J can be used in calculator mode and therefore should be marketable to students as advanced calculators ideally suited to financial mathematics. This is especially true now that APL and J can be run on a variety of palm-sized computers.This paper presents a few ideas on how students might use J in the mathematics of finance. The emphasis is on using J as a calculator that has lots of memory and can store and compute with arrays. Therefore data will be entered and expressions evaluated but no programs will be presented in the classroom. (However, two utility programs and a few names for J primitives will be used as noted in the next subsection.)J Definitions used in what followsThe J examples below are presented in the plain Courier font. Certain definitions are assumed and these are displayed in Courier italics. The definitions of these italicized functions are given in the Appendix at the end of the paper. In particular, frequent use is made of a dollar format function Df to display numbers in dollar currency format. When dates are part of the input data, the dayno function can be used to compute a day number.All examples in this paper (except for Example 7, which uses the sparse arrays of J version 4.04) can be done with versions of J going back (at least) to J FreeWare, version 3.02.},
  review = 	 {fbie: rejected <2016-01-15 13:55:56>},
}

@article{Brown:2000:IMS:570440.570483,
  author =	 {Brown, Richard L. W.},
  title =	 {Interest Made Simple with Arrays},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {June 2000},
  volume =	 30,
  number =	 4,
  month =	 jun,
  year =	 2000,
  issn =	 {0163-6006},
  pages =	 {55--60},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/570440.570483},
  doi =		 {10.1145/570440.570483},
  acmid =	 570483,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A better financial calculatorStudents of the mathematics of finance seem to be comfortable using calculators to evaluate formulas or numerical expressions. They are typically much less comfortable writing programs in BASIC (or C or Java etc.) even in situations where the calculator solution is tedious and a short program would do the job efficiently. Spreadsheet models, with an emphasis on formulas as opposed to programs, are quite a reasonable and intuitive tool. But spreadsheet formulas seem to be about cells rather than money, time, and interest rates.The ideal tool would be a better calculator. APL and J can be used in calculator mode and therefore should be marketable to students as advanced calculators ideally suited to financial mathematics. This is especially true now that APL and J can be run on a variety of palm-sized computers.This paper presents a few ideas on how students might use J in the mathematics of finance. The emphasis is on using J as a calculator that has lots of memory and can store and compute with arrays. Therefore data will be entered and expressions evaluated but no programs will be presented in the classroom. (However, two utility programs and a few names for J primitives will be used as noted in the next subsection.)J Definitions used in what followsThe J examples below are presented in the plain Courier font. Certain definitions are assumed and these are displayed in Courier italics. The definitions of these italicized functions are given in the Appendix at the end of the paper. In particular, frequent use is made of a dollar format function Df to display numbers in dollar currency format. When dates are part of the input data, the dayno function can be used to compute a day number.All examples in this paper (except for Example 7, which uses the sparse arrays of J version 4.04) can be done with versions of J going back (at least) to J FreeWare, version 3.02.},
  review = 	 {fbie: rejected <2016-01-15 13:56:18>},
}

@article{Lapidot:2002:SPL:637610.544479,
  author =	 {Lapidot, Tami},
  title =	 {Self-assessment As a Powerful Learning Experience},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {September 2002},
  volume =	 34,
  number =	 3,
  month =	 jun,
  year =	 2002,
  issn =	 {0097-8418},
  pages =	 {198--198},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/637610.544479},
  doi =		 {10.1145/637610.544479},
  acmid =	 544479,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Every teacher would like to have students that are motivated towards autonomous learning with self-enthusiasm. This Tip presentation will offer one method for achieving such a goal.For three consequential years (1998-2000) I was teaching a "computing literacy teaching methods" course for CSE students in the Technion. The focus of the course was on computing teaching methods and learning processes.A major part of the course was devoted to a project the students had to develop. They had to collect data, analyze it, organize and represent it to their colleagues. They had to work in small teams and could choose their own topic as long as they were using different computing tools such as Internet, email, spreadsheet, and others.The projects ranged topics such as: Wine, women in Islam, Michelangelo, UFO, wedding traditions, Greek mythology, and Marathon history.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=544479&ftid=348008&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:56:23>},
}

@inproceedings{Lapidot:2002:SPL:544414.544479,
  author =	 {Lapidot, Tami},
  title =	 {Self-assessment As a Powerful Learning Experience},
  booktitle =	 {Proceedings of the 7th Annual Conference on
                  Innovation and Technology in Computer Science
                  Education},
  series =	 {ITiCSE '02},
  year =	 2002,
  isbn =	 {1-58113-499-1},
  location =	 {Aarhus, Denmark},
  pages =	 {198--198},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/544414.544479},
  doi =		 {10.1145/544414.544479},
  acmid =	 544479,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Every teacher would like to have students that are motivated towards autonomous learning with self-enthusiasm. This Tip presentation will offer one method for achieving such a goal.For three consequential years (1998-2000) I was teaching a "computing literacy teaching methods" course for CSE students in the Technion. The focus of the course was on computing teaching methods and learning processes.A major part of the course was devoted to a project the students had to develop. They had to collect data, analyze it, organize and represent it to their colleagues. They had to work in small teams and could choose their own topic as long as they were using different computing tools such as Internet, email, spreadsheet, and others.The projects ranged topics such as: Wine, women in Islam, Michelangelo, UFO, wedding traditions, Greek mythology, and Marathon history.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=544479&ftid=348008&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:56:27>},
}

@inproceedings{Scaffidi:2008:TRA:1368088.1368090,
  author =	 {Scaffidi, Christopher and Myers, Brad and Shaw,
                  Mary},
  title =	 {Topes: Reusable Abstractions for Validating Data},
  booktitle =	 {Proceedings of the 30th International Conference on
                  Software Engineering},
  series =	 {ICSE '08},
  year =	 2008,
  isbn =	 {978-1-60558-079-1},
  location =	 {Leipzig, Germany},
  pages =	 {1--10},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1368088.1368090},
  doi =		 {10.1145/1368088.1368090},
  acmid =	 1368090,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {abstraction, data, validation},
  abstract = 	 {Programmers often omit input validation when inputs can appear in many different formats or when validation criteria cannot be precisely specified. To enable validation in these situations, we present a new technique that puts valid inputs into a consistent format and that identifies "questionable" inputs which might be valid or invalid, so that these values can be double-checked by a person or a program. Our technique relies on the concept of a "tope", which is an application-independent abstraction describing how to recognize and transform values in a category of data. We present our definition of topes and describe a development environment that supports the implementation and use of topes. Experiments with web application and spreadsheet data indicate that using our technique improves the accuracy and reusability of validation code and also improves the effectiveness of subsequent data cleaning such as duplicate identification.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1368090&ftid=518055&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:56:32>},
}

@inproceedings{Kotanchek:2012:RFD:2330784.2330862,
  author =	 {Kotanchek, Mark},
  title =	 {Robust Function Discovery and Feature Selection for
                  Life Sciences and Engineering},
  booktitle =	 {Proceedings of the 14th Annual Conference Companion
                  on Genetic and Evolutionary Computation},
  series =	 {GECCO '12},
  year =	 2012,
  isbn =	 {978-1-4503-1178-6},
  location =	 {Philadelphia, Pennsylvania, USA},
  pages =	 {497--498},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2330784.2330862},
  doi =		 {10.1145/2330784.2330862},
  acmid =	 2330862,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data analysis, feature selection, genetic
                  programming},
  abstract = 	 {Industrial process and product optimization is impossible without meaningful models and insights on significant features controlling process or product performance. Real-world modeling and feature selection problems have many issues - high-dimensional, non-linear, with unbalanced measurements, correlated features, missing experiments, etc., which makes it difficult for most people to know what the right approach is in any given situation. We present a function discovery technology based on symbolic regression that routinely converts these problems into meaningful and insightful models with robust driver features identification. Without requiring a Ph.D. in Computer Science or Statistics, it is now possible to easily develop robust nonlinear models (complete with trust measures), identify data outliers and interactively explore the model dynamics and response sensitivities. Our presentation will illustrate the ease and power of automatic conversion of a spreadsheet of data into an interactive data story report using examples drawn from life sciences and engineering.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2330862&ftid=1262987&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:56:37>},
}

@inproceedings{Nykanen:2014:PCS:2676467.2676470,
  author =	 {Nyk\"{a}nen, Ossi A.},
  title =	 {Productification for Collaborative Semantic
                  Modeling},
  booktitle =	 {Proceedings of the 18th International Academic
                  MindTrek Conference: Media Business, Management,
                  Content \& Services},
  series =	 {AcademicMindTrek '14},
  year =	 2014,
  isbn =	 {978-1-4503-3006-0},
  location =	 {Tampere, Finland},
  pages =	 {78--84},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/2676467.2676470},
  doi =		 {10.1145/2676467.2676470},
  acmid =	 2676470,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {curriculum design, productification, semantic
                  modeling, structured documents},
  abstract = 	 {The lack of proper authoring tools provides a practical but a very significant challenge for adopting new technologies and applications concepts. In this article, we identify a development strategy called "productification", which suggests transforming some application-specific authoring tasks into tasks of using common-purpose authoring tools and systems. In brief, the objective is typically to transform and harness the power of the existing office and productivity applications for various authoring etc. tasks, while consuming the information in novel applications, also learning from experience. To demonstrate and discuss this approach, we present a case study of using spreadsheets in collaborative semantic modeling of a core curriculum. Besides pointing out an efficient approach for collaborative semantic modeling, we use the productified authoring system to analyze the related core curriculum development process, making observations that help designing machine-understandable, high-quality core curriculums.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2676470&ftid=1608856&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:18>},
}

@inproceedings{Alexopoulos:2001:HID:564124.564326,
  author =	 {Alexopoulos, Christos and Goldsman, David and
                  Fontanesi, John and Sawyer, Mark and De Guire,
                  Michelle and Kopald, David and Holcomb, Kathy},
  title =	 {Healthcare I: A Discrete-event Simulation
                  Application for Clinics Serving the Poor},
  booktitle =	 {Proceedings of the 33Nd Conference on Winter
                  Simulation},
  series =	 {WSC '01},
  year =	 2001,
  isbn =	 {0-7803-7309-X},
  location =	 {Arlington, Virginia},
  pages =	 {1386--1391},
  numpages =	 6,
  url =		 {http://dl.acm.org/citation.cfm?id=564124.564326},
  acmid =	 564326,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  abstract = 	 {Healthcare management operates in an environment of aggressive pricing, tough competition, and rapidly changing guidelines. Computer simulation models are increasingly used by large healthcare institutions to meet these challenges. However, small healthcare facilities serving the poor are equally in need of meeting these challenges but lack the finances and personnel required to develop and implement their own simulation solutions. An academic medical center, healthcare facilities that serve the poor, and the local public health department formed a unique partnership to create low-cost tools to meet these challenges. This article describes the creation of a low-cost, generic, discrete-event simulation model populated by a workflow observation Excel spreadsheet that can be completed by clinic staff themselves, thus "customizing" the simulation model for their own purposes. This initial model focuses on childhood immunization delivery services; the intent is to develop a tool flexible enough to serve other health services delivery needs as well.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=564326&ftid=85268&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:25>},
}

@inproceedings{Fylstra:2013:ISD:2675807.2675979,
  author =	 {Fylstra, Daniel H.},
  title =	 {Integrated Simulation, Data Mining, and Optimization
                  in Microsoft Excel},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  location =	 {Washington, D.C.},
  pages =	 {4105--4105},
  numpages =	 1,
  url =		 {http://dl.acm.org/citation.cfm?id=2675807.2675979},
  acmid =	 2675979,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Analytic Solver Platform is a powerful, integrated toolset for Monte Carlo simulation, forecasting, data mining, and conventional and stochastic optimization, with models expressed in Microsoft Excel spreadsheet form. Three of its unique features are (i) fast Monte Carlo simulation that approaches the speed of custom programs in C/C++, (ii) data visualization and data mining methods applied to Monte Carlo simulation results, and (iii) very rich optimization tools ranging from general-purpose simulation optimization (with multi-core and GPU support) to stochastic linear programming and robust optimization. Models built in Excel with Analytic Solver Platform can be deployed on Windows or Linux servers (without Excel) and can support multiple concurrent users. This session will demonstrate how you can use Analytic Solver Platform to build your own analytic expertise, teach others using leading textbooks, build industrial-scale models, and communicate business results.},
  review = 	 {fbie: rejected <2016-01-15 13:57:32>},
}

@inproceedings{Fylstra:2013:ISD:2675983.2675979,
  author =	 {Fylstra, Daniel H.},
  title =	 {Integrated Simulation, Data Mining, and Optimization
                  in Microsoft Excel},
  booktitle =	 {Proceedings of the 2013 Winter Simulation
                  Conference: Simulation: Making Decisions in a
                  Complex World},
  series =	 {WSC '13},
  year =	 2013,
  isbn =	 {978-1-4799-2077-8},
  location =	 {Washington, D.C.},
  pages =	 {4105--4105},
  numpages =	 1,
  url =		 {http://dl.acm.org/citation.cfm?id=2675983.2675979},
  acmid =	 2675979,
  publisher =	 {IEEE Press},
  address =	 {Piscataway, NJ, USA},
  abstract = 	 {Analytic Solver Platform is a powerful, integrated toolset for Monte Carlo simulation, forecasting, data mining, and conventional and stochastic optimization, with models expressed in Microsoft Excel spreadsheet form. Three of its unique features are (i) fast Monte Carlo simulation that approaches the speed of custom programs in C/C++, (ii) data visualization and data mining methods applied to Monte Carlo simulation results, and (iii) very rich optimization tools ranging from general-purpose simulation optimization (with multi-core and GPU support) to stochastic linear programming and robust optimization. Models built in Excel with Analytic Solver Platform can be deployed on Windows or Linux servers (without Excel) and can support multiple concurrent users. This session will demonstrate how you can use Analytic Solver Platform to build your own analytic expertise, teach others using leading textbooks, build industrial-scale models, and communicate business results.},
  review = 	 {fbie: rejected <2016-01-15 13:57:35>},
}

@inproceedings{Barrus:2014:IDM:2644866.2644891,
  author =	 {Barrus, John W. and Schwartz, Edward L.},
  title =	 {Image-based Document Management: Aggregating
                  Collections of Handwritten Forms},
  booktitle =	 {Proceedings of the 2014 ACM Symposium on Document
                  Engineering},
  series =	 {DocEng '14},
  year =	 2014,
  isbn =	 {978-1-4503-2949-1},
  location =	 {Fort Collins, Colorado, USA},
  pages =	 {117--120},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2644866.2644891},
  doi =		 {10.1145/2644866.2644891},
  acmid =	 2644891,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data capture, document management, forms,
                  handwriting, tables},
  abstract = 	 {Many companies still operate critical business processes using paper-based forms, including customer surveys, inspections, contracts and invoices. Converting those handwritten forms to symbolic data is expensive and complicated. This paper presents an overview of the Image-Based Document Management (IBDM) system for analyzing handwritten forms without requiring conversion to symbolic data. Strokes captured in a questionnaire on a tablet are separated into fields that are then displayed in a spreadsheet. Rows represent documents while columns represent corresponding fields across all documents. IBDM allows a process owner to capture and analyze large collections of documents with minimal IT support. IBDM supports the creation of filters and queries on the data. IBDM also allows the user to request symbolic conversion of individual columns of data and permits the user to create custom views by reordering and sorting the columns. In other words, IBDM provides a "writing on paper" experience for the data collector and a web-based database experience for the analyst.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2644891&ftid=1500117&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:40>},
}

@article{Wing:2013:FMI:2658982.2527291,
  author =	 {Wing, Jeannette M.},
  title =	 {Formal Methods: An Industrial Perspective},
  journal =	 {Ada Lett.},
  issue_date =	 {December 2013},
  volume =	 33,
  number =	 3,
  month =	 nov,
  year =	 2013,
  issn =	 {1094-3641},
  pages =	 {85--86},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2658982.2527291},
  doi =		 {10.1145/2658982.2527291},
  acmid =	 2527291,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {constraint satisfaction, formal methods, model
                  checking, program synthesis., satisfiability modulo
                  theories, specification, theorem proving,
                  verification},
  abstract = 	 {Formal methods research has made tremendous progress since the 1980s when a proof using a theorem prover was worthy of a Ph.D. thesis and a bug in a VLSI textbook was found using a model checker. Now, with advances in theorem proving, model checking, satisfiability modulo theories (SMT) solvers, and program analysis, the engines of formal methods are more sophisticated and are applicable and scalable: to a wide range of domains, from biology to mathematics; to a wide range of systems, from asynchronous systems to spreadsheets; and for a wide range of properties, from security to program termination. In this talk, I will present a few Microsoft Research stories of advances in formal methods and their application to Microsoft products and services. Formal methods use, however, is not routine?yet?in industrial practice. So, I will close with outstanding challenges and new directions for research in formal methods.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2527291&ftid=1412481&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:44>},
}

@inproceedings{Wing:2013:FMI:2527269.2527291,
  author =	 {Wing, Jeannette M.},
  title =	 {Formal Methods: An Industrial Perspective},
  booktitle =	 {Proceedings of the 2013 ACM SIGAda Annual Conference
                  on High Integrity Language Technology},
  series =	 {HILT '13},
  year =	 2013,
  isbn =	 {978-1-4503-2467-0},
  location =	 {Pittsburgh, Pennsylvania, USA},
  pages =	 {85--86},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2527269.2527291},
  doi =		 {10.1145/2527269.2527291},
  acmid =	 2527291,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {constraint satisfaction, formal methods, model
                  checking, program synthesis., satisfiability modulo
                  theories, specification, theorem proving,
                  verification},
  abstract = 	 {Formal methods research has made tremendous progress since the 1980s when a proof using a theorem prover was worthy of a Ph.D. thesis and a bug in a VLSI textbook was found using a model checker. Now, with advances in theorem proving, model checking, satisfiability modulo theories (SMT) solvers, and program analysis, the engines of formal methods are more sophisticated and are applicable and scalable: to a wide range of domains, from biology to mathematics; to a wide range of systems, from asynchronous systems to spreadsheets; and for a wide range of properties, from security to program termination. In this talk, I will present a few Microsoft Research stories of advances in formal methods and their application to Microsoft products and services. Formal methods use, however, is not routine?yet?in industrial practice. So, I will close with outstanding challenges and new directions for research in formal methods.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2527291&ftid=1412481&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:48>},
}

@inproceedings{Luce:2005:SOE:1162708.1163053,
  author =	 {Luce, Karl and Trepanier, Lucie and Ciochetto, Fred
                  and Goldman, Lawrence},
  title =	 {Simulation and Optimization As Effective DFSS Tools},
  booktitle =	 {Proceedings of the 37th Conference on Winter
                  Simulation},
  series =	 {WSC '05},
  year =	 2005,
  isbn =	 {0-7803-9519-0},
  location =	 {Orlando, Florida},
  pages =	 {1993--1999},
  numpages =	 7,
  url =		 {http://dl.acm.org/citation.cfm?id=1162708.1163053},
  acmid =	 1163053,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Simulation and optimization techniques can provide Design for Six Sigma (DFSS) practitioners with reduced reliance on physical prototypes, rapid time-to-market, minimal defects and post-design rework. These advantages lead to quantifiable benefits within the product development life-cycle, in terms of time and cost. Through one case study, this paper will provide Six Sigma, Process Excellence and Lean practitioners with the rationale for spreadsheet simulation and optimization in DFSS initiatives. Discussion topics include the role of simulation and optimization in the DMADV methodology, disadvantages of not quantifying uncertainty in DFSS projects, differences between deterministic and stochastic optimization, and tradeoff considerations when running optimizations. Practical techniques for efficiently identifying robust, high quality solutions are demonstrated through the use of Monte Carlo simulation and optimization.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1163053&ftid=373584&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:52>},
}

@article{Herrmann:1994:ISA:191033.191068,
  author =	 {Herrmann, Nira and Popyack, Jeffrey L.},
  title =	 {An Integrated, Software-based Approach to Teaching
                  Introductory Computer Programming},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {March 1994},
  volume =	 26,
  number =	 1,
  month =	 mar,
  year =	 1994,
  issn =	 {0097-8418},
  pages =	 {92--96},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/191033.191068},
  doi =		 {10.1145/191033.191068},
  acmid =	 191068,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We have developed a course in scientific and statistical programming consisting of an introduction to computer programming and data analysis concepts using a variety of software packages. This approach addresses the problems inherent in introducing programming to non-computer science majors, particularly those in engineering, the sciences, and the social sciences where computing and statistical data analysis techniques are essential professional tools, as well as to computer science majors with minimal or nonexistent programming backgrounds.Key programming concepts are introduced, including variables and identifiers, absolute versus relative addresses, assignment statements, IF/THEN/ELSE statements, nested and compound IF statements, truth tables, precedence of operations, use of built-in and user-defined functions, dummy variables, passing by value and reference, the importance of order in specifying input to functions, modular program design, subprograms, debugging and testing techniques, properties of good programs, and iterative loops. Elementary statistical concepts and data analyses are covered within a computing environment context that emphasizes data analysis and interpretation of results.Assignments and examples are developed in collaboration with the students' major departments to insure relevance and interest to the students.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=191068&ftid=37484&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:57:57>},
}

@inproceedings{Herrmann:1994:ISA:191029.191068,
  author =	 {Herrmann, Nira and Popyack, Jeffrey L.},
  title =	 {An Integrated, Software-based Approach to Teaching
                  Introductory Computer Programming},
  booktitle =	 {Proceedings of the Twenty-fifth SIGCSE Symposium on
                  Computer Science Education},
  series =	 {SIGCSE '94},
  year =	 1994,
  isbn =	 {0-89791-646-8},
  location =	 {Phoenix, Arizona, USA},
  pages =	 {92--96},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/191029.191068},
  doi =		 {10.1145/191029.191068},
  acmid =	 191068,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {We have developed a course in scientific and statistical programming consisting of an introduction to computer programming and data analysis concepts using a variety of software packages. This approach addresses the problems inherent in introducing programming to non-computer science majors, particularly those in engineering, the sciences, and the social sciences where computing and statistical data analysis techniques are essential professional tools, as well as to computer science majors with minimal or nonexistent programming backgrounds.Key programming concepts are introduced, including variables and identifiers, absolute versus relative addresses, assignment statements, IF/THEN/ELSE statements, nested and compound IF statements, truth tables, precedence of operations, use of built-in and user-defined functions, dummy variables, passing by value and reference, the importance of order in specifying input to functions, modular program design, subprograms, debugging and testing techniques, properties of good programs, and iterative loops. Elementary statistical concepts and data analyses are covered within a computing environment context that emphasizes data analysis and interpretation of results.Assignments and examples are developed in collaboration with the students' major departments to insure relevance and interest to the students.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=191068&ftid=37484&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:01>},
}

@inproceedings{Vasilakis:2004:DWE:1161734.1161862,
  author =	 {Vasilakis, Christos and El-Darzi, Elia and Chountas,
                  Panagiotis},
  title =	 {A Data Warehouse Environment for Storing and
                  Analyzing Simulation Output Data},
  booktitle =	 {Proceedings of the 36th Conference on Winter
                  Simulation},
  series =	 {WSC '04},
  year =	 2004,
  isbn =	 {0-7803-8786-4},
  location =	 {Washington, D.C.},
  pages =	 {703--710},
  numpages =	 8,
  url =		 {http://dl.acm.org/citation.cfm?id=1161734.1161862},
  acmid =	 1161862,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Discrete event simulation modelling has been extensively used in modelling complex systems. Although it offers great conceptual-modelling flexibility, it is both computationally expensive and data intensive. There are several examples of simulation models that generate millions of observations to achieve satisfactory point and confidence interval estimations for the model variables. In these cases, it is exceptionally cumbersome to conduct the required output and sensitivity analysis in a spreadsheet or statistical package. In this paper, we highlight the advantages of employing data warehousing techniques for storing and analyzing simulation output data. The proposed data warehouse environment is capable of providing the means for automating the necessary algorithms and procedures for estimating different parameters of the simulation. These include initial transient in steady-state simulations and point and confidence interval estimations. Previously developed models for evaluating patient flow through hospital departments are used to demonstrate the problem and the proposed solutions.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1161862&ftid=377130&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:06>},
}

@inproceedings{Standridge:1996:PMS:256562.256793,
  author =	 {Standridge, Charles R. and Kelly, James F. and
                  Kelley, Thomas and Walther, Jack},
  title =	 {Progress in Modular Simulation Environments},
  booktitle =	 {Proceedings of the 28th Conference on Winter
                  Simulation},
  series =	 {WSC '96},
  year =	 1996,
  isbn =	 {0-7803-3383-7},
  location =	 {Coronado, California, USA},
  pages =	 {714--720},
  numpages =	 7,
  url =		 {http://dx.doi.org/10.1145/256562.256793},
  doi =		 {10.1145/256562.256793},
  acmid =	 256793,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:58:08>},
}

@inproceedings{Grabis:2010:PSE:2433508.2433543,
  author =	 {Grabis, Janis and Chandra, Charu},
  title =	 {Process Simulation Environment for Case Studies},
  booktitle =	 {Proceedings of the Winter Simulation Conference},
  series =	 {WSC '10},
  year =	 2010,
  isbn =	 {978-1-4244-9864-2},
  location =	 {Baltimore, Maryland},
  pages =	 {317--326},
  numpages =	 10,
  url =		 {http://dl.acm.org/citation.cfm?id=2433508.2433543},
  acmid =	 2433543,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Using case studies helps learning and understanding complex issues in operations and supply chain management studies but preparing models for indepth exploration of case studies is time consuming and requires model-building skills. In order to address these issues, an environment for analyzing case studies is developed. The process-oriented approach is used as a basis for analyzing operations and supply chain management problems with emphasis on exploring relationships among different value chain processes such as manufacturing, logistics, marketing and finance. Process flow simulation is used to obtain quantitative process performance measures. Three main components of the environment are catalog of case studies, enterprise management dashboard and process modeling component. These components are implemented using commercially available spreadsheet and process modeling software. The environment can be used for implementation and exploration of different cases studies. Usage of the environment is demonstrated by analyzing a sample case study.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2433543&ftid=1339417&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:12>},
}

@inproceedings{Deb:2013:CTA:2512349.2514908,
  author =	 {Deb, Chayan Kumar},
  title =	 {Collaborative Task Assignment on Tabletop Computer},
  booktitle =	 {Proceedings of the 2013 ACM International Conference
                  on Interactive Tabletops and Surfaces},
  series =	 {ITS '13},
  year =	 2013,
  isbn =	 {978-1-4503-2271-3},
  location =	 {St. Andrews, Scotland, United Kingdom},
  pages =	 {453--456},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2512349.2514908},
  doi =		 {10.1145/2512349.2514908},
  acmid =	 2514908,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {direct manipulation, face-to-face collaboration,
                  tabletop (surface) computers, task assignment},
  abstract = 	 {his paper proposes the use of Tabletop Computers for use in Project Management activities like Task Assignment. Task Assignment is essentially collaborative, which ideally should be done at table discussion, now-a-days happens over network on personal devices even though there is no constraint on common time and space. Face-to-face collaboration is dwindling, even though it is faster in reaching consensus, richer in terms of quality of communication and tends to be more satisfying for the group (as compared to computer-mediated)[1]. Use of a tabletop computer, which combines the productivity benefit of a computer with the social benefits of around-the-table interaction, can potentially enhance the effectiveness of such collocated Task Assignment meeting without affecting the agility or disturbing the traditional settings.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2514908&ftid=1404269&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:15>},
}

@inproceedings{Carson:1996:AOS:256562.256726,
  author =	 {Carson,II, John S.},
  title =	 {AutoStat: Output Statistical Analysis for AutoMod
                  Users},
  booktitle =	 {Proceedings of the 28th Conference on Winter
                  Simulation},
  series =	 {WSC '96},
  year =	 1996,
  isbn =	 {0-7803-3383-7},
  location =	 {Coronado, California, USA},
  pages =	 {492--499},
  numpages =	 8,
  url =		 {http://dx.doi.org/10.1145/256562.256726},
  doi =		 {10.1145/256562.256726},
  acmid =	 256726,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 13:58:16>},
}

@inproceedings{Enns:2003:STB:1030818.1030974,
  author =	 {Enns, S. T. and Suwanruji, Pattita},
  title =	 {Simulation Test Bed for Manufacturing Analysis: A
                  Simulation Test Bed for Producton and Supply Chain
                  Modeling},
  booktitle =	 {Proceedings of the 35th Conference on Winter
                  Simulation: Driving Innovation},
  series =	 {WSC '03},
  year =	 2003,
  isbn =	 {0-7803-8132-7},
  location =	 {New Orleans, Louisiana},
  pages =	 {1174--1182},
  numpages =	 9,
  url =		 {http://dl.acm.org/citation.cfm?id=1030818.1030974},
  acmid =	 1030974,
  publisher =	 {Winter Simulation Conference},
  abstract = 	 {Production systems and supply chains are difficult to model at the level of detail required to understand factors affecting the behavior of material flow. This is particularly true when use of centralized planning systems, such as MRP or DRP, is of interest. Therefore a test bed, comprised of a planning module and a simulator module, has been developed. This test bed is designed to be simple, transparent and flexible. It supports research as well as training. The planning module uses a spreadsheet-based interface and logic embedded in extensive VBA macros. The simulator module is made up of a generic ARENA program that requires no direct modeling inputs when scenarios are changed. Dynamic communication between the modules is facilitated using VBA. Transient and steady-state behavior can be observed under diverse conditions. Production systems or supply chains using MRP/DRP, reorder points, or Kanban systems can be compared.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1030974&ftid=293329&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:21>},
}

@article{Obrenovic:2011:SIS:1959022.1959026,
  author =	 {Obrenovic, \v{Z}eljko and Martens, Jean-Bernard},
  title =	 {Sketching Interactive Systems with Sketchify},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {April 2011},
  volume =	 18,
  number =	 1,
  month =	 may,
  year =	 2011,
  issn =	 {1073-0516},
  pages =	 {4:1--4:38},
  articleno =	 4,
  numpages =	 38,
  url =		 {http://doi.acm.org/10.1145/1959022.1959026},
  doi =		 {10.1145/1959022.1959026},
  acmid =	 1959026,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Sketching, design process, interaction design, rapid
                  prototyping, user interface software tools},
  abstract = 	 {Recent discussions in the interaction design community have called attention to sketching as an omnipresent element of any disciplined activity of design, and have pointed out that sketching should be extended beyond the simple creation of a pencil trace on paper. More specifically, the need to deal with all attributes of a user experience, especially the timing, phrasing, and feel of the interaction, has been identified. In this article, we propose extending the concept of sketching with a pencil on paper to the more generic concept of fluent exploration of interactive materials. We define interactive materials as any piece of software or hardware that represents or simulates a part of the interactive user experience, such as input from sensors, output in the form of sound, video, or image, or interaction with Web services or specialized programs. We have implemented the proposed concept within Sketchify, a tool for sketching user interfaces. Sketchify gives designers the freedom to manipulate interactive materials by combining elements of traditional freehand sketching with functional extensions and end-user programming tools, such as spreadsheets and scripting. We have evaluated Sketchify in the education of interaction designers, identifying both successful aspects and aspects that need further improvements.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1959026&ftid=926525&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:25>},
}

@inproceedings{Werner:2005:RCL:1095714.1095738,
  author =	 {Werner, Laurie},
  title =	 {Redefining Computer Literacy in the Age of
                  Ubiquitous Computing},
  booktitle =	 {Proceedings of the 6th Conference on Information
                  Technology Education},
  series =	 {SIGITE '05},
  year =	 2005,
  isbn =	 {1-59593-252-6},
  location =	 {Newark, NJ, USA},
  pages =	 {95--99},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/1095714.1095738},
  doi =		 {10.1145/1095714.1095738},
  acmid =	 1095738,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {home computer security, laboratory activities,
                  pedagogy},
  abstract = 	 {Most computer literacy courses encountered by college students in a non-technical major encompass a foundation set of computing skills including efficient use of word processing, spreadsheet, database, and presentation software. Yet current college graduates are facing fresh challenges as end-users in a work force transformed by legislation that is revolutionizing digital data communication, by nearly boundary-less computer systems that include mobile and static devices, and by employer expectations for safeguarding critical data resources. For example, data privacy legislation affects all end-users of computer systems in the workplace. As employees, new graduates will have access to critical data to perform their jobs, yet they could be the weakest link in an otherwise effectively secure computer system, primarily because of inadequate education, negligence, and inexperience. Technical and mathematical computer security has progressed substantially in the last few years, but new graduates are typically lacking in the knowledge of computer security as a fundamental component of their workplace roles. This paper proposes a computer literacy course content and structure that incorporates substantial practice in end-user computer security.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1095738&ftid=332513&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:29>},
}

@inproceedings{Padilla:1988:GER:62548.62566,
  author =	 {Padilla, William and Rigg-Healy, Barbara},
  title =	 {Great Expectations and the Reality of University
                  Computing Resources},
  booktitle =	 {Proceedings of the 16th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '88},
  year =	 1988,
  isbn =	 {0-89791-286-1},
  location =	 {Long Beach, California, USA},
  pages =	 {65--69},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/62548.62566},
  doi =		 {10.1145/62548.62566},
  acmid =	 62566,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {“My boss wants this budget set up on the computer by Friday and I don't know anything about budgets, or Lotus, or computers!” A little over a year ago, these hysterics coming from a user were a common scene at the Information Resource Center (IRC), the end-user service branch of Computer and Information Resources and Technology (CIRT) at the University of New Mexico. Users would come in with unrealistic deadlines assigned by their bosses, who, in turn, had unrealistic expectations of both their employees' skills and computer technology in general. Often, we had the added problem of dealing with a user who was using unsupported hardware and/or software.
An IRC consultant, feeling sorry for the frantic employee, would then spend hours bailing out the employee by actually (in this case) designing the spreadsheet and meeting the employee's deadline. The end result of the consultant's effort was usually mediocre because of the time constraints and because the employee did not have the necessary skills, such a accounting in this case, to work with the consultant to make full use of the technology.
In the aftermath, everyone lost. The consultant wasted valuable time, the employee didn't learn anything and probably was alienated by the technology, and the boss most likely was not happy with the end product or the employee, and he/she blamed the IRC consultant for the poor results.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=62566&ftid=4231&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:33>},
}

@inproceedings{Mansell:2010:EFF:1900160.1900174,
  author =	 {Mansell, Howard},
  title =	 {Eden: An F\#/WPF Framework for Building GUI Tools},
  booktitle =	 {ACM SIGPLAN Commercial Users of Functional
                  Programming},
  series =	 {CUFP '10},
  year =	 2010,
  isbn =	 {978-1-4503-0516-7},
  location =	 {Baltimore, Maryland},
  pages =	 {12:1--12:1},
  articleno =	 12,
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1900160.1900174},
  doi =		 {10.1145/1900160.1900174},
  acmid =	 1900174,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Our group within Credit Suisse is responsible for developing quantitative models used to value financial products within the Securities Division of the bank. One aspect of this role is to deliver tools based on those models to trading and sales staff, which they can use to quickly price proposed transactions and perform other analysis of market conditions. Historically these tools have been delivered as Excel spreadsheets. WPF (Windows Presentation Foundation) is a GUI framework which encourages architectural separation between the layout of the user interface itself (the "View") and the underlying interactions and calculations (the "ViewModel" and "Model"). We have built a framework for developing tools in WPF that makes use of a graph-based calculation engine for implementing ViewModels and Models in F#. The engine is built on F# asynchronous workflows and provides a standard set of features to our tools. In this talk I'll discuss the implementation of this calculation engine, including various steps in its evolution that led up to our use of asynchronous workflows. I'll also talk about how well F# and asynchronous workflows have worked for us, and briefly discuss some of the challenges of integrating F# and WPF.},
  review = 	 {fbie: rejected <2016-01-15 13:58:37>},
}

@inproceedings{Qian:2012:SSM:2213836.2213846,
  author =	 {Qian, Li and Cafarella, Michael J. and Jagadish,
                  H. V.},
  title =	 {Sample-driven Schema Mapping},
  booktitle =	 {Proceedings of the 2012 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '12},
  year =	 2012,
  isbn =	 {978-1-4503-1247-9},
  location =	 {Scottsdale, Arizona, USA},
  pages =	 {73--84},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2213836.2213846},
  doi =		 {10.1145/2213836.2213846},
  acmid =	 2213846,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data integration, sample-driven, schema mapping,
                  usability},
  abstract = 	 {End-users increasingly find the need to perform light-weight, customized schema mapping. State-of-the-art tools provide powerful functions to generate schema mappings, but they usually require an in-depth understanding of the semantics of multiple schemas and their correspondences, and are thus not suitable for users who are technically unsophisticated or when a large number of mappings must be performed. We propose a system for sample-driven schema mapping. It automatically constructs schema mappings, in real time, from user-input sample target instances. Because the user does not have to provide any explicit attribute-level match information, she is isolated from the possibly complex structure and semantics of both the source schemas and the mappings. In addition, the user never has to master any operations specific to schema mappings: she simply types data values into a spreadsheet-style interface. As a result, the user can construct mappings with a much lower cognitive burden. In this paper we present Mweaver, a prototype sample-driven schema mapping system. It employs novel algorithms that enable the system to obtain desired mapping results while meeting interactive response performance requirements. We show the results of a user study that compares Mweaver with two state-of-the-art mapping tools across several mapping tasks, both real and synthetic. These suggest that the Mweaver system enables users to perform practical mapping tasks in about 1/5th the time needed by the state-of-the-art tools.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2213846&ftid=1221292&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:41>},
}

@inproceedings{Wright:2003:MML:2331829.2331834,
  author =	 {Wright, Tim and Cockburn, Andy},
  title =	 {Mulspren: A Multiple Language Programming
                  Environment for Children},
  booktitle =	 {Proceedings of the 4th Annual Conference of the ACM
                  Special Interest Group on Computer-Human
                  Interaction},
  series =	 {CHINZ '03},
  year =	 2003,
  isbn =	 {0-473-09553-X},
  location =	 {Dunedin, New Zealand},
  pages =	 {21--26},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2331829.2331834},
  doi =		 {10.1145/2331829.2331834},
  acmid =	 2331834,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Many end-users are starting to use computers for more than word processing and playing games. While it is still common to use a computer to send emails, surf the internet, and perform other non-programming tasks, computer-based tasks that involve programming skills are becoming more common. These tasks range from being very simple, such as specifying rules for a spam filter, to much more complex tasks, such as making a home budget using a spreadsheet, or reprogramming word processors using a macro language. Users can perform these tasks more efficiently if they have some programming skills. Many researchers have developed educational programming environments. These environments make programming accessible for learner programmers by using a wide variety of symbol types --- from textual to tangible program statements; iconic to graphical program constructs. Many of these environments use different symbols for different tasks. For example, a programming environment might force a user to read a program using set of symbols, but watch their program run using different symbols. Although using multiple different sets of symbols is common, there has been little research evaluating either how users interact with multiple languages or the effects of multiple languages on users. This paper presents a novel programming environment called Mulspren. Mulspren was designed to let children lever their knowledge of English to learn conventional programming constructs---knowledge that could help them when they are older and need programming skills. Mulspren uses dual languages that users interact with simultaneously and move between seamlessly---one language is very similar to English and the other is similar to C or Java code. In this paper we give a description of both languages and a fictitious example of a user writing a simple program in the environment. We intend this environment to be useful for anyone interested in building or evaluating multiple programming environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2331834&ftid=1263481&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:45>},
}

@article{Yamada:1995:DEH:212430.212435,
  author =	 {Yamada, Shoji and Hong, Jung-Kook and Sugita,
                  Shigeharu},
  title =	 {Development and Evaluation of Hypermedia for Museum
                  Education: Validation of Metrics},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {Dec. 1995},
  volume =	 2,
  number =	 4,
  month =	 dec,
  year =	 1995,
  issn =	 {1073-0516},
  pages =	 {284--307},
  numpages =	 24,
  url =		 {http://doi.acm.org/10.1145/212430.212435},
  doi =		 {10.1145/212430.212435},
  acmid =	 212435,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {field study, graph theory, metrics, museum,
                  structural analysis},
  abstract = 	 {To define a hypermedia system's ease of use from the user's point of view, we propose three evaluation metrics: an interface shallowness metric, a downward compactness metric, and a downward navigability metric. These express both the cognitive load on users and the structural complexity of the hypermedia contents. We conducted a field study at the National Museum of Ethnology (NME) in Osaka, Japan, to evaluate our hypermedia system and to assess the suitability of our hypermedia metrics from the viewpoint of visiting members of the public. After developing a spreadsheet-type authoring system named HyperEX, we built prototype systems for use by members of the public visiting a special exhibition held at the museum. Questionnaires, interviews, automatic recording of users' navigation operations, and statistical analysis of 449 tested users yielded the following results. First, the suitability of the metrics was found to be satisfactory, indicating that they are useful for developing hypermedia systems. Second, there is a strong relationship between a system's enjoyability and its usability. Transparency and the friendliness of the user interface are the key issues in enjoyability. Finally, the quality of the video strongly affects the overall system evaluation. Video quality is determined by optimum selection of scenes, the length of the video, and appropriate audio-visual expression of the content. This video quality may become the most important issue in developing hypermedia for museum education.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=212435&ftid=26833&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:49>},
}

@inproceedings{Morton:2012:DWD:2213836.2213961,
  author =	 {Morton, Kristi and Bunker, Ross and Mackinlay, Jock
                  and Morton, Robert and Stolte, Chris},
  title =	 {Dynamic Workload Driven Data Integration in Tableau},
  booktitle =	 {Proceedings of the 2012 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '12},
  year =	 2012,
  isbn =	 {978-1-4503-1247-9},
  location =	 {Scottsdale, Arizona, USA},
  pages =	 {807--816},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2213836.2213961},
  doi =		 {10.1145/2213836.2213961},
  acmid =	 2213961,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data integration, visualization},
  abstract = 	 {Tableau is a commercial business intelligence (BI) software tool that supports interactive, visual analysis of data. Armed with a visual interface to data and a focus on usability, Tableau enables a wide audience of end-users to gain insight into their datasets. The user experience is a fluid process of interaction in which exploring and visualizing data takes just a few simple drag-and-drop operations (no programming or DB experience necessary). In this context of exploratory, ad-hoc visual analysis, we describe a novel approach to integrating large, heterogeneous data sources. We present a new feature in Tableau called data blending, which gives users the ability to create data visualization mashups from structured, heterogeneous data sources dynamically without any upfront integration effort. Users can author visualizations that automatically integrate data from a variety of sources, including data warehouses, data marts, text files, spreadsheets, and data cubes. Because our data blending system is workload driven, we are able to bypass many of the pain-points and uncertainty in creating mediated schemas and schema-mappings in current pay-as-you-go integration systems.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2213961&ftid=1221384&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:58:53>},
}

@inproceedings{Ahnn:2008:ULD:1462735.1462743,
  author =	 {Ahnn, Jong Hoon and Birman, Ken and Ostrowski,
                  Krzysztof and Van Renesse, Robbert},
  title =	 {Using Live Distributed Objects for Office
                  Automation},
  booktitle =	 {Proceedings of the ACM/IFIP/USENIX Middleware '08
                  Conference Companion},
  series =	 {Companion '08},
  year =	 2008,
  isbn =	 {978-1-60558-369-3},
  location =	 {Leuven, Belgium},
  pages =	 {30--35},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1462735.1462743},
  doi =		 {10.1145/1462735.1462743},
  acmid =	 1462743,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SOA, distributed systems, live distributed objects,
                  middleware, office automation, office information
                  systems},
  abstract = 	 {Web services and platforms such as .NET make it easy to integrate interactive end-user applications with backend services. However, it remains hard to build collaborative applications in which information is shared within teams. This paper introduces a new drag-and-drop technology, in which standard office documents (spreadsheets, databases, etc.) are interconnected with event-driven middleware ("live distributed objects"), to create distributed applications in which changes to underlying data propagate quickly to downstream applications. Information is replicated in a consistent manner, making it easy for team members to share updates and to coordinate their actions. We present our middleware platform, and show that it offers good performance and scalability, with small resource footprint. Moreover, because the approach is highly automated, and the underlying middleware is highly configurable, we're in a position to automatically address security and reliability needs that might otherwise be onerous. In addition to reviewing our existing system, we list open issues, which include integration with external data sources, and updating stored, but inactive objects.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1462743&ftid=589679&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:07>},
}

@inproceedings{Al-Mutawa:2014:DPA:2642687.2642696,
  author =	 {Al-Mutawa, Mohammad and Mishra, Shivakant},
  title =	 {Data Partitioning: An Approach to Preserving Data
                  Privacy in Computation Offload in Pervasive
                  Computing Systems},
  booktitle =	 {Proceedings of the 10th ACM Symposium on QoS and
                  Security for Wireless and Mobile Networks},
  series =	 {Q2SWinet '14},
  year =	 2014,
  isbn =	 {978-1-4503-3027-5},
  location =	 {Montreal, QC, Canada},
  pages =	 {51--60},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2642687.2642696},
  doi =		 {10.1145/2642687.2642696},
  acmid =	 2642696,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {cloud computing, data partitioning, data privacy,
                  mobile computing, pervasive computing},
  abstract = 	 {Offloading computations to remote servers from small mobile devices such as smartphones is a popular technique used in pervasive computing. It addresses the computing and power constraints of small mobile devices. However, a key problem with this technique is a potential loss of data privacy. When a computation is offloaded, user data also needs to be shipped to the possibly untrusted remote nodes. This paper introduces the concept of data partitioning to address this potential loss of data privacy in computation offload to remote nodes. The data partitioning approach allows a user to identify the sensitive parts of her data, which is then prevented from being shipped to untrusted remote servers. The overall execution consists of identifying sensitive parts of user data, shipping code and non-private data for remote execution and getting the results back, and then combining the results from local and remote executions on the mobile device. Data partitioning can be used for a variety of personal digital files that the users create and modify using applications. These include videos, images, audios, and perhaps even textual documents and spreadsheets. It allows mobile users to enjoy a better computing experience by not only further improving the performance and saving power, but also preserving data privacy. The paper demonstrates the applicability of the data partitioning approach via prototypes of three different applications developed for Android devices.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2642696&ftid=1500539&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:13>},
}

@inproceedings{Stutz:1987:PSM:41866.41930,
  author =	 {Stutz, Al},
  title =	 {Process for Selecting Microcomputer-based
                  Statistical Software},
  booktitle =	 {Proceedings of the 15th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '87},
  year =	 1987,
  isbn =	 {0-89791-241-1},
  location =	 {Kansas City, Missouri, USA},
  pages =	 {355--360},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/41866.41930},
  doi =		 {10.1145/41866.41930},
  acmid =	 41930,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The proliferation of microcomputers in academic environments has increased interest in using them for statistical computations. In the past many of these computations were done with mainframe or minicomputers using a limited number of highly sophisticated and well supported packages. With the current influx of microcomputer based packages, faculty and researchers are moving their statistical applications from the larger systems to microcomputers. In addition, many faculty and researchers, unfamiliar with large computer systems, are rapidly discovering the use of microcomputer for statistical analysis.
The Instruction and Research Computer Center at The Ohio State University has over the last four to five years tried to take a leadership role in the selection of microcomputer software. Basically, the Center assessed the need for software and match that need with the best software for the University. Approximately one and a half years ago the Center began evaluating microcomputer statistical software. In the past, evaluation teams usually consisted ordinarily of the Director of the Center and our microcomputer experts. This approach worked extremely well for communications, basic wordprocessing, basic spreadsheets, and simple databases. The variety of available statistical software packages and the diverse needs of our faculty and researchers dictated a different approach. A statistical software review committee evolved. This committee consisted of faculty, researchers, the center's microcomputer experts, the associate director, and the director.
This document reviews the steps taken at The Ohio State University to select the software. We are only partially through the analysis and selection process. Hopefully by the time of the conference, we will able to report about the completed project.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=41930&ftid=13912&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:18>},
}

@inproceedings{Weber:2002:LDC:584955.584990,
  author =	 {Weber, Anke and Kienle, Holger M. and M\"{u}ller,
                  Hausi A.},
  title =	 {Live Documents with Contextual, Data-driven
                  Information Components},
  booktitle =	 {Proceedings of the 20th Annual International
                  Conference on Computer Documentation},
  series =	 {SIGDOC '02},
  year =	 2002,
  isbn =	 {1-58113-543-2},
  location =	 {Toronto, Ontario, Canada},
  pages =	 {236--247},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/584955.584990},
  doi =		 {10.1145/584955.584990},
  acmid =	 584990,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Microsoft Office, live documents, repurposing,
                  reverse engineering, scalable vector graphics,
                  single sourcing, software engineering, systems
                  documentation},
  abstract = 	 {We introduce the notion of a live document and we describe our concept of live documents with contextual, data driven information components. The dynamic and interactive features of live documents provide a consistent data source for multimedia presentations targeted to various audiences and multiple platforms. Therefore, they contribute to the solution of key challenges in single sourcing and repurposing. We motivate the use of live documents with sample scenarios from the field of systems documentation. We further discuss how live documents can benefit from an interdisciplinary research approach across the fields of technical communications, systems documentation, and software engineering. Finally, cit_af ref_bf(Greenberg, Saul 2001 ref_num129)ref_we describe our experiences with prototype implementations of live documents based on Scalable Vector Graphics (SVG) and Microsoft Office Automation, respectively.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=584990&ftid=91536&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:25>},
}

@article{Edwards:2005:SUS:1103845.1094851,
  author =	 {Edwards, Jonathan},
  title =	 {Subtext: Uncovering the Simplicity of Programming},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {October 2005},
  volume =	 40,
  number =	 10,
  month =	 oct,
  year =	 2005,
  issn =	 {0362-1340},
  pages =	 {505--518},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/1103845.1094851},
  doi =		 {10.1145/1103845.1094851},
  acmid =	 1094851,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {copying, non-textual programming, prototypes, visual
                  programming},
  abstract = 	 {Representing programs as text strings makes programming harder then it has to be. The source text of a program is far removed from its behavior. Bridging this conceptual gulf is what makes programming so inhumanly difficult -- we are not compilers. Subtext is a new medium in which the representation of a program is the same thing as its execution. Like a spreadsheet, a program is visible and alive, constantly executing even as it is edited. Program edits are coherent semantic transformations.The essence of this new medium is copying. Programs are constructed by copying and executed by copy flow: the projection of changes through copies. The simple idea of copying develops into a rich theory of higher-order continual copying of trees. Notably absent are symbolic names, the workhorse of textual notation, replaced by immediately-bound explicit relationships. Subtext unifies traditionally distinct programming tools and concepts, and enables some novel ones. Ancestral structures are a new primitive data type that combines the features of lists and records, along with unproblematic multiple inheritance. Adaptive conditionals use first-class program edits to dynamically adapt behavior.A prototype implementation shows promise, but calls for much further research. Subtext suggests that we can make programming radically easier, if we are willing to be radical.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1094851&ftid=329610&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:34>},
}

@inproceedings{Edwards:2005:SUS:1094811.1094851,
  author =	 {Edwards, Jonathan},
  title =	 {Subtext: Uncovering the Simplicity of Programming},
  booktitle =	 {Proceedings of the 20th Annual ACM SIGPLAN
                  Conference on Object-oriented Programming, Systems,
                  Languages, and Applications},
  series =	 {OOPSLA '05},
  year =	 2005,
  isbn =	 {1-59593-031-0},
  location =	 {San Diego, CA, USA},
  pages =	 {505--518},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/1094811.1094851},
  doi =		 {10.1145/1094811.1094851},
  acmid =	 1094851,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {copying, non-textual programming, prototypes, visual
                  programming},
  abstract = 	 {Representing programs as text strings makes programming harder then it has to be. The source text of a program is far removed from its behavior. Bridging this conceptual gulf is what makes programming so inhumanly difficult -- we are not compilers. Subtext is a new medium in which the representation of a program is the same thing as its execution. Like a spreadsheet, a program is visible and alive, constantly executing even as it is edited. Program edits are coherent semantic transformations.The essence of this new medium is copying. Programs are constructed by copying and executed by copy flow: the projection of changes through copies. The simple idea of copying develops into a rich theory of higher-order continual copying of trees. Notably absent are symbolic names, the workhorse of textual notation, replaced by immediately-bound explicit relationships. Subtext unifies traditionally distinct programming tools and concepts, and enables some novel ones. Ancestral structures are a new primitive data type that combines the features of lists and records, along with unproblematic multiple inheritance. Adaptive conditionals use first-class program edits to dynamically adapt behavior.A prototype implementation shows promise, but calls for much further research. Subtext suggests that we can make programming radically easier, if we are willing to be radical.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1094851&ftid=329610&dwn=1&CFID=745299778&CFTOKEN=60877949},
  review = 	 {fbie: rejected <2016-01-15 13:59:43>},
}

@inproceedings{Murthy:2004:QBI:1017074.1017078,
  author =	 {Murthy, Sudarshan and Maier, David and Delcambre,
                  Lois},
  title =	 {Querying Bi-level Information},
  booktitle =	 {Proceedings of the 7th International Workshop on the
                  Web and Databases: Colocated with ACM SIGMOD/PODS
                  2004},
  series =	 {WebDB '04},
  year =	 2004,
  location =	 {Paris, France},
  pages =	 {7--12},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1017074.1017078},
  doi =		 {10.1145/1017074.1017078},
  acmid =	 1017078,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SPARCE, bi-level queries, information integration,
                  superimposed information management},
  review = 	 {fbie: rejected <2016-01-15 13:59:47>},
  abstract = 	 {In our research on superimposed information management, we have developed applications where information elements in the superimposed layer serve to annotate, comment, restructure, and combine selections from one or more existing documents in the base layer. Base documents tend to be unstructured or semi-structured (HTML pages, Excel spreadsheets, and so on) with marks delimiting selections. Selections in the base layer can be programmatically accessed via marks to retrieve content and context. The applications we have built to date allow creation of new marks and new superimposed elements (that use marks), but they have been browse-oriented and tend to expose the line between superimposed and base layers. Here, we present a new access capability, called bi-level queries, that allows an application or user to query over both layers as a whole. Bi-level queries provide an alternative style of data integration where only relevant portions of a base document are mediated (not the whole document) and the superimposed layer can add information not present in the base layer. We discuss our framework for superimposed information management, an initial implementation of a bi-level query system with an XML Query interface, and suggest mechanisms to improve scalability and performance.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1017078&ftid=275239&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Batterman:2013:ADA:2513383.2513397,
  author =	 {Batterman, Jared M. and Schuett, Jonathan H. and
                  Walker, Bruce N.},
  title =	 {Auditory Displays for Accessible Fantasy Sports},
  booktitle =	 {Proceedings of the 15th International ACM SIGACCESS
                  Conference on Computers and Accessibility},
  series =	 {ASSETS '13},
  year =	 2013,
  isbn =	 {978-1-4503-2405-2},
  location =	 {Bellevue, Washington},
  pages =	 {38:1--38:2},
  articleno =	 38,
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2513383.2513397},
  doi =		 {10.1145/2513383.2513397},
  acmid =	 2513397,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {accessibility, auditory displays, fantasy football,
                  sonification, sports data},
  review = 	 {fbie: rejected <2016-01-15 13:59:49>},
  abstract = 	 {In this paper we address the lack of accessibility in fantasy sports for visually impaired users and discuss the accessible fantasy sports system that we have designed using auditory displays. Fantasy sports are a fun and social activity requiring users to make decisions about their fantasy teams, which use real athletes' weekly performance to gain points and compete against other users' fantasy teams. Fantasy players manage their teams by making informed decisions using statistics about real sports related data. These statistics are usually presented online in a spreadsheet layout, however online fantasy sports are usually inaccessible to screen readers due to the use of Flash on most sites. Our current system, described in this paper, utilizes auditory display techniques such as auditory alerts, earcons, spearcons, general text-to-speech, and auditory graphs to present sports statistics to visually impaired fantasy users. The current version of our system was designed based on feedback from current fantasy sports users during a series of think-aloud walkthroughs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2513397&ftid=1405555&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Fujima:2004:CCC:1013367.1013517,
  author =	 {Fujima, Jun and Lunzer, Aran and Hornb{\ae}k, Kasper
                  and Tanaka, Yuzuru},
  title =	 {C3W: Clipping, Connecting and Cloning for the Web},
  booktitle =	 {Proceedings of the 13th International World Wide Web
                  Conference on Alternate Track Papers \&Amp; Posters},
  series =	 {WWW Alt. '04},
  year =	 2004,
  isbn =	 {1-58113-912-8},
  location =	 {New York, NY, USA},
  pages =	 {444--445},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1013367.1013517},
  doi =		 {10.1145/1013367.1013517},
  acmid =	 1013517,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Web application linkage, Web navigation,
                  intelligentPad, interfaces, subjunctive},
  review = 	 {fbie: rejected <2016-01-15 13:59:51>},
  abstract = 	 {Many of today's Web applications support just simple trial-and error retrievals: supply one set of parameters, obtain one set of results. For a user who wants to examine a number of alternative retrievals, this form of interaction is inconvenient and frustrating. It can be hard work to keep finding and adjusting the parameter specification widgets buried in a Web page, and to remember or record each result set. Moreover, when using diverse Web applicationsin combination - transferring result data from one into the parameters for another - the lack of an easy way to automate that transfer merely increases the frustration. Our solution is to integrate techniques for each of three key activities: clipping elements from Web pages to wrap an application; connecting wrapped applications using spreadsheet-like formulas; and cloning the interfaceelements so that several sets of parameters and results may behandled in parallel. We describe a prototype that implements this solution, showing how it enables rapid and flexible exploration ofthe resources accessible through user-chosen combinations of Web applications. Our aim in this work is to contribute to research on making optimal use of the wealth of information on the Web, by providing interaction techniques that address very practical needs.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1013517&ftid=278320&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Liu:2006:IBD:1149993.1150015,
  author =	 {Liu, Yan and Vincent, Sorna and Murphy, Marguerite
                  C.},
  title =	 {Integrating Bioinformatic Data Sources over the SFSU
                  ER Design Tools XML Databus},
  booktitle =	 {Workshop Proceedings of the Sixth International
                  Conference on Web Engineering},
  series =	 {ICWE '06},
  year =	 2006,
  isbn =	 {1-59593-435-9},
  location =	 {Palo Alto, California, USA},
  articleno =	 19,
  url =		 {http://doi.acm.org/10.1145/1149993.1150015},
  doi =		 {10.1145/1149993.1150015},
  acmid =	 1150015,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Web services data integration, distributed query
                  processing, join processing, schema integration},
  review = 	 {fbie: rejected <2016-01-15 13:59:53>},
  abstract = 	 {The SFSU ER Design Tools were developed to support database design and data integration over multiple implementation data models. These tools allow users to enter and view Entity Relationship (ER) schemas and to translate ER schemas into a variety of equivalent implementation schemas, including Relational (ANSI SQL2), Object Oriented (ODMG 3.0), Spreadsheet (Universal Relation with associated functional dependencies) and W3C XML DTD. In addition, for each implementation data model, the Tools generate DDL statements to create a database, as well as simple JDBC/ODBC based code to dump stored data into an XML file and to load data from an XML file into a database. Data can be transferred from one data store to another over an HTTP based XML Databus. In this paper we describe the design and implementation of our XML Databus using Web Services, as well as a new strategy to support integration of bioinformatics data sets. We first manually identify semantically equivalent attributes in both schemas, then automatically join the corresponding data sets into a single integrated collection of XML formatted data. Our software is operational, and preliminary performance measurements over DTD and data downloaded from the NIH-NCBI Web site show that our strategy is feasible for moderately sized data sets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1150015&ftid=369244&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Chen:2014:SAC:2665936.2665938,
  author =	 {Chen, Ping and Nikiforakis, Nick and Desmet, Lieven
                  and Huygens, Christophe},
  title =	 {Security Analysis of the Chinese Web: How Well is It
                  Protected?},
  booktitle =	 {Proceedings of the 2014 Workshop on Cyber Security
                  Analytics, Intelligence and Automation},
  series =	 {SafeConfig '14},
  year =	 2014,
  isbn =	 {978-1-4503-3147-0},
  location =	 {Scottsdale, Arizona, USA},
  pages =	 {3--9},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/2665936.2665938},
  doi =		 {10.1145/2665936.2665938},
  acmid =	 2665938,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {chinese websites, security metrics, security
                  policies, web security},
  review = 	 {fbie: rejected <2016-01-15 13:59:56>},
  abstract = 	 {As the web rapidly expands and gets integrated into the daily lives of more and more people, so does the number of cyber attacks against it. To defend against attackers, website operators can utilize a wide range of defense mechanisms, both at the server-side, as well as the client-side of their web applications. From a security-metrics standpoint, the presence or absence of these mechanisms can be used as a security indicator of any given website. In this paper, through a large-scale analysis of the 10,000 most popular Chinese websites, we analyze the security of the Chinese web by investigating the usage of client-side security policies, and evaluating the discovered HTTPS implementations. We show that, when compared to popular websites of the rest of the world, a significant fraction of Chinese websites lag behind on the adoption of good security practices. Among other findings, we report on the fact that 6\% of websites inadvertently leak private user information, such as Chinese identity numbers, by placing spreadsheet files with sensitive content in directories indexed by search engines.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2665938&ftid=1511623&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@article{Bhavnani:2008:SIL:1352782.1352784,
  author =	 {Bhavnani, Suresh K. and Peck, Frederick A. and Reif,
                  Frederick},
  title =	 {Strategy-Based Instruction: Lessons Learned in
                  Teaching the Effective and Efficient Use of Computer
                  Applications},
  journal =	 {ACM Trans. Comput.-Hum. Interact.},
  issue_date =	 {May 2008},
  volume =	 15,
  number =	 1,
  month =	 may,
  year =	 2008,
  issn =	 {1073-0516},
  pages =	 {2:1--2:43},
  articleno =	 2,
  numpages =	 43,
  url =		 {http://doi.acm.org/10.1145/1352782.1352784},
  doi =		 {10.1145/1352782.1352784},
  acmid =	 1352784,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Strategies, strategy-based instruction, teaching,
                  training},
  review = 	 {fbie: rejected <2016-01-15 13:59:58>},
  abstract = 	 {Numerous studies have shown that many users do not acquire the knowledge necessary for the effective and efficient use of computer applications such as spreadsheets and Web-authoring tools. While many cognitive, cultural, and social reasons have been offered to explain this phenomenon, there have been few systematic attempts to address it. This article describes how we identified a framework to organize effective and efficient strategies to use computer applications and used an approach called strategy-based instruction to teach those strategies over five years to almost 400 students. Controlled experiments demonstrated that the instructional approach (1) enables students to learn strategies without harming command knowledge, (2) benefits students from technical and nontechnical majors, and (3) is robust across different instructional contexts and new applications. Real-world classroom experience of teaching strategy-based instruction over several instantiations has enabled the approach to be disseminated to other universities. The lessons learned throughout the process of design, implementation, evaluation, and dissemination should allow teaching a large number of users in many organizations to rapidly acquire the strategic knowledge to make more effective and efficient use of computer applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1352784&ftid=497337&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Triplet:2013:BGF:2480362.2480612,
  author =	 {Triplet, Thomas and Butler, Gregory},
  title =	 {BenchDW: A Generic Framework for Biological Data
                  Warehouse Benchmarking},
  booktitle =	 {Proceedings of the 28th Annual ACM Symposium on
                  Applied Computing},
  series =	 {SAC '13},
  year =	 2013,
  isbn =	 {978-1-4503-1656-9},
  location =	 {Coimbra, Portugal},
  pages =	 {1328--1334},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/2480362.2480612},
  doi =		 {10.1145/2480362.2480612},
  acmid =	 2480612,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {benchmark, data integration, data warehousing,
                  genomics, systems biology},
  review = 	 {fbie: rejected <2016-01-15 14:00:00>},
  abstract = 	 {The rapid development of -omics techniques have provided an unprecedented amount of data, enabling system-wide biological research. However, the success of systems biology is contingent on the ability to integrate a wide variety of types of biological data to automatically predict, assign functional annotations of proteins and perform comparative analyses. Although each biological data integration system presents to some extent a number of desirable features, none of them meets all the requirements for effective integration of system-wide data. In this paper, we present BenchDW, a generic and flexible benchmark framework that aims at facilitating the evaluation and quantification of the capabilities of those biological data warehouses. It currently comprises 22 different metrics ranging from documentation quality to accuracy and response times, which may be recorded for different hardware configurations. Each metric can be weighted to better suit the user's specific needs and compared to the gold standard. BenchDW was designed to be flexible, easy to use and offers many benefits over spreadsheets, thus presenting the characteristics required to facilitate acceptance by the scientific community. We demonstrate the utility of BenchDW by briefly reviewing three data warehouses (BioMart, BioXRT and InterMine) and by showcasing how it can be leveraged to identify the specificities of the systems of interest. BenchDW is available online at http://warehousebenchmark.fungalgenomics.ca/benchmark/benchdw/index.html under the GNU GPLv3 license.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2480612&ftid=1368206&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Suri:1989:RMA:76738.76748,
  author =	 {Suri, R.},
  title =	 {Rapid Modeling: How It Assists Manufacturing
                  Competitiveness},
  booktitle =	 {Proceedings of the 21st Conference on Winter
                  Simulation},
  series =	 {WSC '89},
  year =	 1989,
  isbn =	 {0-911801-58-8},
  location =	 {Washington, D.C., USA},
  pages =	 {80--83},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/76738.76748},
  doi =		 {10.1145/76738.76748},
  acmid =	 76748,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 14:00:02>},
  abstract = 	 {The Rapid Modeling Technique (RMT) allows manufacturing analysts to quickly build new models for various manufacturing scenarios, as well as to rapidly explore a large number of "what-ifs" for each scenario. A set of integrated tools further extends RMT to allow the efficient investigation of decisions in virtually all stages of the design and operation of manufacturing systems. The use of these tools leads to cost-effective and timely analysis of manufacturing decisions, and hence to greater productivity and competitive position of the manufacturing enterprise. We present a set of five compatible tools for rapid modeling and analysis of manufacturing systems. Spreadsheets form the basic tool for simple calculations. RMT tools allow the user to study the dynamics of manufacturing systems using efficient mathematics: whole models can be built in hours and each "what-if" is analyzed in minutes. Translators allow almost instantaneous conversion of the analytical model into simulation code. Simulation Languages provide very detailed modeling abilities. Finally, Animation gives analysts the ability to present their results to co-workers and management in a convincing manner. We describe instances of these tools as well as the way in which they are integrated to form a compatible toolkit.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=76748&ftid=375236&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Balinsky:2010:DAP:1860559.1860584,
  author =	 {Balinsky, Helen Y. and Simske, Steven J.},
  title =	 {Differential Access for Publicly-posted Composite
                  Documents with Multiple Workflow Participants},
  booktitle =	 {Proceedings of the 10th ACM Symposium on Document
                  Engineering},
  series =	 {DocEng '10},
  year =	 2010,
  isbn =	 {978-1-4503-0231-9},
  location =	 {Manchester, United Kingdom},
  pages =	 {115--124},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/1860559.1860584},
  doi =		 {10.1145/1860559.1860584},
  acmid =	 1860584,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {access control, composite document, document
                  security, policy},
  review = 	 {fbie: rejected <2016-01-15 14:00:04>},
  abstract = 	 {A novel mechanism for providing and enforcing differential access control for publicly-posted composite documents is proposed. The concept of a document is rapidly changing: individual file-based, traditional formats can no longer accommodate the required mixture of differently formatted parts: individual images, video/audio clips, PowerPoint presentations, html-pages, Word documents, Excel spreadsheets, pdf files, etc. Multi-part composite documents are created and managed in complex workflows, with participants including external consultants, partners and customers distributed across the globe, with many no longer contained within one monolithic secure environment. Distributed over non-secure channels, these documents carry different types of sensitive information: examples include (a) an enterprise pricing strategy for new products, (b) employees' personal records, (c) government intelligence, and (d) individual medical records. A central server solution is often hard or impossible to create and maintain for ad-hoc workflows. Thus, the documents are often circulated between workflow participants over traditional, low security e-mails, placed on shared drives, or exchanged using CD/DVD or USB. The situation is more complicated when multiple workflow participants need to contribute to various parts of such a document with different access levels: for example, full editing rights, read-only, reading of some parts only, etc., for different users. We propose a full scale differential access control approach, enabling public posting of composite documents, to address these concerns.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1860584&ftid=847067&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@article{Karinthi:1987:IRP:960114.29654,
  author =	 {Karinthi, R. R. and Weiser, M.},
  title =	 {Incremental Re-execution of Programs},
  journal =	 {SIGPLAN Not.},
  issue_date =	 {July 1987},
  volume =	 22,
  number =	 7,
  month =	 jul,
  year =	 1987,
  issn =	 {0362-1340},
  pages =	 {38--44},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/960114.29654},
  doi =		 {10.1145/960114.29654},
  acmid =	 29654,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  notes = 	 {This might be relevant in terms of recomputation.},
  review = 	 {fbie: accepted <2016-01-15 14:00:25>},
  abstract = 	 {Interpreters replace the edit/compile/run cyle with edit/run. Dynamic computing environments, like spreadsheets, shorten this still more to just edit. So-called "Visiprog" environments, such as Maryland's XED, permit developing normal imperative programs in a dynamic computing environment, XED and similar environments, because they show the results of executing a program after every (reasonable) editing step, raise the issue of efficient incremental execution. Incremental execution optimizations are also applicable to any programming situation, including batch/cards, in which nearly the same program is run many times on nearly the same data. However, the requirement of remembering large amounts of internal state between runs make incremental exectution most natural for interpreted languages. This paper examines some algorithms for incremental execution. Based on the frequency of typical program editing changes, we predict the importance of optimizing certain kinds of incremental execution. We also examine actual speedups obtained in executing programs after subjecting them to these simulated incremental edits under these optimizations. The speedups range from factors of 1.1 to near 10. Finally, we discuss the feasibility of including these optimizations in an actual dynamic computing environment like XED, and in more traditional programming environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=29654&ftid=262412&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Karinthi:1987:IRP:29650.29654,
  author =	 {Karinthi, R. R. and Weiser, M.},
  title =	 {Incremental Re-execution of Programs},
  booktitle =	 {Papers of the Symposium on Interpreters and
                  Interpretive Techniques},
  series =	 {SIGPLAN '87},
  year =	 1987,
  isbn =	 {0-89791-235-7},
  location =	 {St. Paul, Minnesota, USA},
  pages =	 {38--44},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/29650.29654},
  doi =		 {10.1145/29650.29654},
  acmid =	 29654,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: accepted <2016-01-15 14:00:27>},
  abstract = 	 {Interpreters replace the edit/compile/run cyle with edit/run. Dynamic computing environments, like spreadsheets, shorten this still more to just edit. So-called "Visiprog" environments, such as Maryland's XED, permit developing normal imperative programs in a dynamic computing environment, XED and similar environments, because they show the results of executing a program after every (reasonable) editing step, raise the issue of efficient incremental execution. Incremental execution optimizations are also applicable to any programming situation, including batch/cards, in which nearly the same program is run many times on nearly the same data. However, the requirement of remembering large amounts of internal state between runs make incremental exectution most natural for interpreted languages. This paper examines some algorithms for incremental execution. Based on the frequency of typical program editing changes, we predict the importance of optimizing certain kinds of incremental execution. We also examine actual speedups obtained in executing programs after subjecting them to these simulated incremental edits under these optimizations. The speedups range from factors of 1.1 to near 10. Finally, we discuss the feasibility of including these optimizations in an actual dynamic computing environment like XED, and in more traditional programming environments.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=29654&ftid=262412&dwn=1&CFID=575549397&CFTOKEN=15758644},
}

@inproceedings{Sly:1995:MFA:224401.224749,
  author =	 {Sly, David P.},
  title =	 {Material Flow Analysis of Automotive Assembly Plants
                  Using FactoryFlow},
  booktitle =	 {Proceedings of the 27th Conference on Winter
                  Simulation},
  series =	 {WSC '95},
  year =	 1995,
  isbn =	 {0-7803-3018-8},
  location =	 {Arlington, Virginia, USA},
  pages =	 {902--908},
  numpages =	 7,
  url =		 {http://dx.doi.org/10.1145/224401.224749},
  doi =		 {10.1145/224401.224749},
  acmid =	 224749,
  publisher =	 {IEEE Computer Society},
  address =	 {Washington, DC, USA},
  review = 	 {fbie: rejected <2016-01-15 14:07:39>},
}

@inproceedings{Weaver:1985:LM:17701.255659,
  author =	 {Weaver, Kevin R.},
  title =	 {Lotus 1-2-3 for Mainframes (Bringing a Product to
                  Market)},
  booktitle =	 {Proceedings of the International Conference on APL:
                  APL and the Future},
  series =	 {APL '85},
  year =	 1985,
  isbn =	 {0-897-91157-1},
  location =	 {Seattle, Washington, USA},
  pages =	 {207--214},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/17701.255659},
  doi =		 {10.1145/17701.255659},
  acmid =	 255659,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The number of widely-used, business oriented APL applications is few. It's difficult to pinpoint why — other than to reflect on the complexities of conceiving a marketable product and executing the development, release, sale and promotion, distribution, and ongoing support for a product. Although many companies provide APL services, and many custom applications have been developed for specific needs, the ability to bring a mainframe APL product to market and have it succeed seems cornered by IBM (e.g., ADRS, FPS, GRAPHPAK, APL DI). Parallax Systems is one of the few companies to be successful in this arena. The product is called ExecuCalctm, and has been licensed to approximately 200 sites since January 1983.
What are the elements that contribute to the success of this product in such a short period of time? Can these be applied to other APL product ideas to insure the developer is at least on the right road to producing a winner?
First, there was market awareness. The buying market (corporate data processing managers and senior decision makers) should have a mental picture of the concept being explored. ExecuCalc is an electronic spreadsheet product. In the early 1980's, VisiCalc was almost a household word. The concept was clear, accepted, and in practice in the micro computer market. Missionary work (often a key process in promoting APL and APL-based applications) for spreadsheets was already done, and the masses were going to the altar.
Second was market need. VisiCalc satisfied a need. Since this audience accepted the spreadsheet concept long ago, the market need does not have to be detailed. At the same time, VisiCalc lacked both obvious features (e.g., variable column width) and features which resulted from widespread use creating a demand (e.g., file combine for consolidation). ExecuCalc initially contained all of the VisiCalc features, including identical commands and their syntax as well as file formats (“.VC” and “.DIF”), plus a few of the obvious needs (determined by limited market research and personal experience, harnessed by the desire to release the product in a timely fashion). ExecuCalc paralleled the need for a VisiCalc, and added a new dimension: it ran on a mainframe using 3270 terminals. The needs satisfied included: (a) spreadsheet, (b) a widely accepted approach, (c) use of existing hardware (mainframe and 3270s), (d) a product requiring little training and support for information center users, yet (e) enabled users to be immediately productive, and (f) enabled users to process corporate data resident on their mainframe rather than down-load and proliferate segments of the corporate databases.
Third, boundaries were established on the features in each release, especially release 1. By concentrating on a well-defined end of development, Parallax was able to bring ExecuCalc to the market in three man-months. The boundaries were set by VisiCalc's features and the few “obvious” add-ons. Subsequent releases over the next year were timed and delivered as maintenance releases. The subsequent releases always were bounded by a finite set of new features.
Fourth, development was focused and uninterrupted. As a two-person company, Parallax had no alternative other than to focus on a timely completion of the product. We had financial incentives (the desire for income and the need to minimize expenses) as well as the concern that a competitive product would be released and substantially reduce our potential. There is an undisputed edge in being first in the market. As a result, one person spent long hours at the terminal keyboard (implementing, testing, and polishing the product) and one person spent long hours at the typewriter keyboard and telephone (developing press releases, promotional letters, prospect literature, etc.). The argument might be made that this is easy or easier (as well as a necessity) for a small, start-up firm; but a larger firm should keep in mind that fewer interruptions during product development and market planning result in a net gain in productivity.
Fifth, the product was priced to sell. As a product increases in cost and complexity, so does the evaluation time and corporate authority level to sign for the purchase. ExecuCalc was (and still is) priced at $5000 per CPU license. Considerations in arriving at this price included: (a) most middle level managers and up (information center manager, DP manager, etc.) could sign-off on the purchase; (b) the product was approximately the price of one micro running VisiCalc or Lotus, yet offered access to everyone with a 3270; and (c) the price was substantially lower than most mainframe products being purchased by data processing, consequently reducing the decision process to buy.
Sixth, there was a plan for the future. Once Lotus 1-2-3 overpowered VisiCalc. ExecuCalc was enhanced to include most of the popular features of Lotus. Again, we implemented these features in the same (or as close as possible) syntax as that used by Lotus. Also, a high-resolution, color business graphics product, ExecuPlottm, was released. ExecuPlot was a look-alike for VisiPlot — meeting all of the criteria noted above. Parallax also provided customer training in ExecuCalc, ExecuPlot, VisiCalc, and Lotus 1-2-3, so that a full service could be offered to a company as the user base grew and requirements for ongoing support and service rapidly increased.
Seventh, we realized sales, marketing and promotion can make or break a product. Although a traditional sales approach and marketing strategy are essential, especially for a newly formed company — and in fact we spent heavily on large frequent advertising in Computerworld — there are many variations on the standard theme which greatly helped the success of Parallax with ExecuCalc. Our sales brochure was printed on a ledger sheet (i.e., a spreadsheet) to draw attention to the nature of the product. When we exhibited the product in a trade show, we used promotional gimmicks generally affordable by larger companies (e.g., free T-shirts with our name attached to a newly-popular phrase: The Best Has Always Been Good Enough — Parallax). We also gave a T-shirt to each of our customers who responded to a product questionnaire. We pursued every opportunity with the press to gain recognition for the company and/or the product. This meant writing editors and following up with telephone or personal contact, using every contact we knew in the trades, never turning down an opportunity to be mentioned no matter how insignificant the mention or the publication seemed. We also joined ADAPSO to work with others in support of our industry and to make contacts with other executives in the industry. We always gave the appearance of being a large company with a highly successful product.
Since product margins would greatly decline if we were required to make sales calls to sell every copy, we shipped the product to prospective customers for a thirty-day evaluation. In the cases where a demonstration was critical to make the sale, we would demonstrate the product (a two-hour demo) to the prospect at their site only if they would provide us with a two-hour period during which we could demo the product to a group of other companies in the local area. We also offered the product under a monthly lease plan ($500/month) with lease credits toward the perpetual license fee.
The above material could relate to almost any new product launch, not necessarily an APL product. What were the advantages and disadvantages of using APL?
APL was the chosen language in which to write ExecuCalc and ExecuPlot because it was the language in which we had the most expertise. At the same time it afforded us several advantages:
First, we were able to bring the first version of the product to market in a relatively brief period of time. One of our main competitors with a similar product written in assembler took 18 man-months to bring the first release to market.
Second, we were able to develop enhancements in a timely fashion, keeping the same order of magnitude of time difference as noted above for the initial release of the product.
Third, we were able to respond to and fix problems easily. In some cases we could apply a fix over the telephone with a customer on-line with the product. If the product were in assembler we'd have to apply the fix to a master copy and distribute it en mass (although we ultimately did this after fixing any collection of bugs found in the product).
Fourth, with a minor amount of guidance (and proper authorization) from us, a client may enhance the product with formulas specifically related to the company's needs or industry specialization (e.g., actuarial formulas, banking calculations, etc.). This is not possible with other mainframes products, nor is it with Lotus, VisiCalc, or other spreadsheet micro products. Naturally, the company needs an APL terminal and an APL programmer. Beyond that, the process is very easy.
Fifth, IBM “promotes” APL and APL products in the information center. As a result, we fit in nicely with this environment.
Sixth, we were able to use existing software in APL needed to accomplish some of the tasks required of the product. For example, we used AP124X (the full screen manager) or AP126 (part of GDDM) for ExecuCalc; we used GDDM and GRAPHPAK for ExecuPlot.
APL was also a disadvantage.
First, our market place was limited to those running VS APL or those willing to install VS APL to run our product.
Second, the market place continues to have a negative attitude about APL being a resource drain and a product which is difficult to deal with from the standpoint of (a) receiving help from IBM about the product, (b) learning the language, and (c) providing support to both the user community and technical support for the system.
Third, APL is not available from IBM in a form which is helpful to companies marketing APL-based products. Most companies we market to would prefer to license software (and VS APL) in terms of a perpetual license fee, paid once. VS APL is leased by IBM on a monthly basis, without a paid-up plan.
Furthermore, a software developer is not able to provide VS APL source code with the application product on the distribution tape. This means that a firm contracting for a product such as ExecuCalc must also contract with IBM for APL, wait for APL to be delivered, figure out how to install it, install it, then order our product for evaluation and licensing. This is inconvenient and discouraging to all concerned, to say nothing about the additional time needed and expense.
It is difficult to draw a conclusion from this experience which would conclusively determine if we were to write another application software product, would we do it in APL. There are many factors to consider as noted above. This time it worked for Parallax, resulting in one of the largest selling APL-based mainframe software products on the market.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=255659&ftid=11878&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:07:46>},
}

@article{Weaver:1985:LM:255315.255659,
  author =	 {Weaver, Kevin R.},
  title =	 {Lotus 1-2-3 for Mainframes (Bringing a Product to
                  Market)},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {May 12, 1985},
  volume =	 15,
  number =	 4,
  month =	 may,
  year =	 1985,
  issn =	 {0163-6006},
  pages =	 {207--214},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/255315.255659},
  doi =		 {10.1145/255315.255659},
  acmid =	 255659,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The number of widely-used, business oriented APL applications is few. It's difficult to pinpoint why — other than to reflect on the complexities of conceiving a marketable product and executing the development, release, sale and promotion, distribution, and ongoing support for a product. Although many companies provide APL services, and many custom applications have been developed for specific needs, the ability to bring a mainframe APL product to market and have it succeed seems cornered by IBM (e.g., ADRS, FPS, GRAPHPAK, APL DI). Parallax Systems is one of the few companies to be successful in this arena. The product is called ExecuCalctm, and has been licensed to approximately 200 sites since January 1983.
What are the elements that contribute to the success of this product in such a short period of time? Can these be applied to other APL product ideas to insure the developer is at least on the right road to producing a winner?
First, there was market awareness. The buying market (corporate data processing managers and senior decision makers) should have a mental picture of the concept being explored. ExecuCalc is an electronic spreadsheet product. In the early 1980's, VisiCalc was almost a household word. The concept was clear, accepted, and in practice in the micro computer market. Missionary work (often a key process in promoting APL and APL-based applications) for spreadsheets was already done, and the masses were going to the altar.
Second was market need. VisiCalc satisfied a need. Since this audience accepted the spreadsheet concept long ago, the market need does not have to be detailed. At the same time, VisiCalc lacked both obvious features (e.g., variable column width) and features which resulted from widespread use creating a demand (e.g., file combine for consolidation). ExecuCalc initially contained all of the VisiCalc features, including identical commands and their syntax as well as file formats (“.VC” and “.DIF”), plus a few of the obvious needs (determined by limited market research and personal experience, harnessed by the desire to release the product in a timely fashion). ExecuCalc paralleled the need for a VisiCalc, and added a new dimension: it ran on a mainframe using 3270 terminals. The needs satisfied included: (a) spreadsheet, (b) a widely accepted approach, (c) use of existing hardware (mainframe and 3270s), (d) a product requiring little training and support for information center users, yet (e) enabled users to be immediately productive, and (f) enabled users to process corporate data resident on their mainframe rather than down-load and proliferate segments of the corporate databases.
Third, boundaries were established on the features in each release, especially release 1. By concentrating on a well-defined end of development, Parallax was able to bring ExecuCalc to the market in three man-months. The boundaries were set by VisiCalc's features and the few “obvious” add-ons. Subsequent releases over the next year were timed and delivered as maintenance releases. The subsequent releases always were bounded by a finite set of new features.
Fourth, development was focused and uninterrupted. As a two-person company, Parallax had no alternative other than to focus on a timely completion of the product. We had financial incentives (the desire for income and the need to minimize expenses) as well as the concern that a competitive product would be released and substantially reduce our potential. There is an undisputed edge in being first in the market. As a result, one person spent long hours at the terminal keyboard (implementing, testing, and polishing the product) and one person spent long hours at the typewriter keyboard and telephone (developing press releases, promotional letters, prospect literature, etc.). The argument might be made that this is easy or easier (as well as a necessity) for a small, start-up firm; but a larger firm should keep in mind that fewer interruptions during product development and market planning result in a net gain in productivity.
Fifth, the product was priced to sell. As a product increases in cost and complexity, so does the evaluation time and corporate authority level to sign for the purchase. ExecuCalc was (and still is) priced at $5000 per CPU license. Considerations in arriving at this price included: (a) most middle level managers and up (information center manager, DP manager, etc.) could sign-off on the purchase; (b) the product was approximately the price of one micro running VisiCalc or Lotus, yet offered access to everyone with a 3270; and (c) the price was substantially lower than most mainframe products being purchased by data processing, consequently reducing the decision process to buy.
Sixth, there was a plan for the future. Once Lotus 1-2-3 overpowered VisiCalc. ExecuCalc was enhanced to include most of the popular features of Lotus. Again, we implemented these features in the same (or as close as possible) syntax as that used by Lotus. Also, a high-resolution, color business graphics product, ExecuPlottm, was released. ExecuPlot was a look-alike for VisiPlot — meeting all of the criteria noted above. Parallax also provided customer training in ExecuCalc, ExecuPlot, VisiCalc, and Lotus 1-2-3, so that a full service could be offered to a company as the user base grew and requirements for ongoing support and service rapidly increased.
Seventh, we realized sales, marketing and promotion can make or break a product. Although a traditional sales approach and marketing strategy are essential, especially for a newly formed company — and in fact we spent heavily on large frequent advertising in Computerworld — there are many variations on the standard theme which greatly helped the success of Parallax with ExecuCalc. Our sales brochure was printed on a ledger sheet (i.e., a spreadsheet) to draw attention to the nature of the product. When we exhibited the product in a trade show, we used promotional gimmicks generally affordable by larger companies (e.g., free T-shirts with our name attached to a newly-popular phrase: The Best Has Always Been Good Enough — Parallax). We also gave a T-shirt to each of our customers who responded to a product questionnaire. We pursued every opportunity with the press to gain recognition for the company and/or the product. This meant writing editors and following up with telephone or personal contact, using every contact we knew in the trades, never turning down an opportunity to be mentioned no matter how insignificant the mention or the publication seemed. We also joined ADAPSO to work with others in support of our industry and to make contacts with other executives in the industry. We always gave the appearance of being a large company with a highly successful product.
Since product margins would greatly decline if we were required to make sales calls to sell every copy, we shipped the product to prospective customers for a thirty-day evaluation. In the cases where a demonstration was critical to make the sale, we would demonstrate the product (a two-hour demo) to the prospect at their site only if they would provide us with a two-hour period during which we could demo the product to a group of other companies in the local area. We also offered the product under a monthly lease plan ($500/month) with lease credits toward the perpetual license fee.
The above material could relate to almost any new product launch, not necessarily an APL product. What were the advantages and disadvantages of using APL?
APL was the chosen language in which to write ExecuCalc and ExecuPlot because it was the language in which we had the most expertise. At the same time it afforded us several advantages:
First, we were able to bring the first version of the product to market in a relatively brief period of time. One of our main competitors with a similar product written in assembler took 18 man-months to bring the first release to market.
Second, we were able to develop enhancements in a timely fashion, keeping the same order of magnitude of time difference as noted above for the initial release of the product.
Third, we were able to respond to and fix problems easily. In some cases we could apply a fix over the telephone with a customer on-line with the product. If the product were in assembler we'd have to apply the fix to a master copy and distribute it en mass (although we ultimately did this after fixing any collection of bugs found in the product).
Fourth, with a minor amount of guidance (and proper authorization) from us, a client may enhance the product with formulas specifically related to the company's needs or industry specialization (e.g., actuarial formulas, banking calculations, etc.). This is not possible with other mainframes products, nor is it with Lotus, VisiCalc, or other spreadsheet micro products. Naturally, the company needs an APL terminal and an APL programmer. Beyond that, the process is very easy.
Fifth, IBM “promotes” APL and APL products in the information center. As a result, we fit in nicely with this environment.
Sixth, we were able to use existing software in APL needed to accomplish some of the tasks required of the product. For example, we used AP124X (the full screen manager) or AP126 (part of GDDM) for ExecuCalc; we used GDDM and GRAPHPAK for ExecuPlot.
APL was also a disadvantage.
First, our market place was limited to those running VS APL or those willing to install VS APL to run our product.
Second, the market place continues to have a negative attitude about APL being a resource drain and a product which is difficult to deal with from the standpoint of (a) receiving help from IBM about the product, (b) learning the language, and (c) providing support to both the user community and technical support for the system.
Third, APL is not available from IBM in a form which is helpful to companies marketing APL-based products. Most companies we market to would prefer to license software (and VS APL) in terms of a perpetual license fee, paid once. VS APL is leased by IBM on a monthly basis, without a paid-up plan.
Furthermore, a software developer is not able to provide VS APL source code with the application product on the distribution tape. This means that a firm contracting for a product such as ExecuCalc must also contract with IBM for APL, wait for APL to be delivered, figure out how to install it, install it, then order our product for evaluation and licensing. This is inconvenient and discouraging to all concerned, to say nothing about the additional time needed and expense.
It is difficult to draw a conclusion from this experience which would conclusively determine if we were to write another application software product, would we do it in APL. There are many factors to consider as noted above. This time it worked for Parallax, resulting in one of the largest selling APL-based mainframe software products on the market.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=255659&ftid=11878&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:07:50>},
}

@inproceedings{Andrews:2015:BOD:2809563.2809596,
  author =	 {Andrews, Keith and Traunm\"{u}ller, Thomas and
                  Wolkinger, Thomas and Gutounig, Robert and
                  Ausserhofer, Julian},
  title =	 {Building an Open Data Visualisation Web App Using a
                  Data Server: The Styrian Diversity Visualisation
                  Project},
  booktitle =	 {Proceedings of the 15th International Conference on
                  Knowledge Technologies and Data-driven Business},
  series =	 {i-KNOW '15},
  year =	 2015,
  isbn =	 {978-1-4503-3721-2},
  location =	 {Graz, Austria},
  pages =	 {48:1--48:4},
  articleno =	 48,
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2809563.2809596},
  doi =		 {10.1145/2809563.2809596},
  acmid =	 2809596,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {HTML5, SPARQL, data server, geovis, information
                  visualisation, leaflet-js, open data, responsive,
                  triple store, web app},
  abstract = 	 {Statistical open data is usually provided only in the form of spreadsheets or CSV files, which can sometimes be very large. The writer of an open data app is confronted with two choices: restrict themselves to managable bite-sized chunks of data, which can be consumed (read, parsed, and held in memory) in one go, or install and maintain their own data server which the app can query on demand. The Styrian Diversity Visualisation project was conceived to visualise the diversity of inhabitants of the Austrian Province of Styria (Land Steiermark) using open data served from a data server (triple store). The corresponding web app queries the data server at run rime with a SPARQL query to obtain exactly the data required at that particular time, greatly simplifying its internal logic. There is no need to parse and store entire data sets in memory. The data server is an instance of a Virtuoso Open Source server. The web app (client) is written in HTML5 and uses the leafletjs JavaScript library to provide mobile-friendly interactive maps. The user interface was designed as a set of three stories, each guiding users through a scenario with accompanying interactive visualisations based on corresponding open data sets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2809596&ftid=1645366&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:07:56>},
}

@inproceedings{Buur:2012:PDB:2348144.2348193,
  author =	 {Buur, Jacob},
  title =	 {Participatory Design of Business Models},
  booktitle =	 {Proceedings of the 12th Participatory Design
                  Conference: Exploratory Papers, Workshop
                  Descriptions, Industry Cases - Volume 2},
  series =	 {PDC '12},
  year =	 2012,
  isbn =	 {978-1-4503-1296-7},
  location =	 {Roskilde, Denmark},
  pages =	 {147--148},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/2348144.2348193},
  doi =		 {10.1145/2348144.2348193},
  acmid =	 2348193,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {business, facilitation, innovation},
  abstract = 	 {The recent focus on user-driven innovation and open innovation signals a shift of concerns beyond the new product or service it self. The very model of how to make business is at play in most innovation projects today, in particular with the advent of Internet commerce. There are already examples of participatory design methods being applied to open up the process of business modeling to a wider circle of actors than those marketing managers that typically devise new business schemes. Traditional manufacturing companies with conventional product sales are challenged to consider alternative business models. Public organizations are under increasing pressure to consider themselves a business, with all that this entails in terms of new terminology. To allow people without formal business education to take part in business model discussions means moving beyond text and spreadsheets. Designers can play a crucial role here. But participatory design of business models could sound like a contradiction in terms: Do the designers side with the exploiting rather than the exploited? This workshop invites participants to bring experience from projects where business issues were part of the participatory negotiation, and to hone their position on the larger question of the role of PD in innovation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2348193&ftid=1273956&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:04>},
}

@inproceedings{Cafarella:2011:WDM:1989323.1989452,
  author =	 {Cafarella, Michael J. and Halevy, Alon Y.},
  title =	 {Web Data Management},
  booktitle =	 {Proceedings of the 2011 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '11},
  year =	 2011,
  isbn =	 {978-1-4503-0661-4},
  location =	 {Athens, Greece},
  pages =	 {1199--1200},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/1989323.1989452},
  doi =		 {10.1145/1989323.1989452},
  acmid =	 1989452,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {web data management information extraction},
  abstract = 	 {Web Data Management (or WDM) refers to a body of work concerned with leveraging the large collections of structured data that can be extracted from the Web. Over the past few years, several research and commercial efforts have explored these collections of data with the goal of improving Web search and developing mechanisms for surfacing different kinds of search answers. This work has leveraged (1) collections of structured data such as HTML tables, lists and forms, (2) recent ontologies and knowledge bases created by crowd-sourcing, such as Wikipedia and its derivatives, DBPedia, YAGO and Freebase, and (3) the collection of text documents from the Web, from which facts could be extracted in a domain-independent fashion. The promise of this line of work is based on the observation that new kinds of results can be obtained by leveraging a huge collection of independently created fragments of data, and typically in ways that are wholly unrelated to the authors' original intent. For example, we might use many database schemas to compute a schema thesaurus. Or we might examine many spreadsheets of scientific data that reveal the aggregate practice of an entire scientific field. As such, WDM is tightly linked to Web-enabled collaboration, even (or especially) if the collaborators are unwitting ones. We will cover the key techniques, principles and insights obtained so far in the area of Web Data Management.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1989452&ftid=985946&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:08>},
}

@inproceedings{Pruitt:2012:HRC:2361354.2361387,
  author =	 {Pruitt, Steve and Wiley, Anthony},
  title =	 {HP Relate: A Customer Communication System for the
                  SMB Market},
  booktitle =	 {Proceedings of the 2012 ACM Symposium on Document
                  Engineering},
  series =	 {DocEng '12},
  year =	 2012,
  isbn =	 {978-1-4503-1116-8},
  location =	 {Paris, France},
  pages =	 {141--144},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2361354.2361387},
  doi =		 {10.1145/2361354.2361387},
  acmid =	 2361387,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {interactive},
  abstract = 	 {Enterprise businesses rely on variable data publishing solutions to produce customer communications, such as letters, statements, and financial reports, which are tailored to individual recipients. Until now, however, such customer communications systems were out of the reach of the small and medium business (SMB) market for several reasons. In order to produce enterprise-quality documents, businesses needed employees with advanced skills in document design and automated document composition. In addition, customized documents typically require scripted business logic and complicated data integration. To achieve this level of document composition and delivery would require the SMB user to have access to IT systems and staffing that would be prohibitively expensive. HP Relate is an innovative document design system that delivers enterprise-quality documents for a next-generation customer communication system for the SMB market. HP Relate features easy-to-use document design tools that require no more than self-assisted training. Document business logic and data integration is accessible to SMB users through common office tools, such as dragging and dropping and spreadsheets. Instead of requiring software installed on the user's system, HP Relate is provisioned on a cloud-based platform using a software as a service (SaaS) subscription-based model. In addition, the HP Relate platform enables SMBs to deliver documents in the format of a customer's choosing, including traditional print forms, web-based deployment, and mobile devices.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2361387&ftid=1279905&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:12>},
}

@inproceedings{Grillenberger:2012:ENW:2481449.2481474,
  author =	 {Grillenberger, Andreas and Brinda, Torsten},
  title =	 {eledSQL: A New Web-based Learning Environment for
                  Teaching Databases and SQL at Secondary School
                  Level},
  booktitle =	 {Proceedings of the 7th Workshop in Primary and
                  Secondary Computing Education},
  series =	 {WiPSCE '12},
  year =	 2012,
  isbn =	 {978-1-4503-1787-0},
  location =	 {Hamburg, Germany},
  pages =	 {101--104},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2481449.2481474},
  doi =		 {10.1145/2481449.2481474},
  acmid =	 2481474,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {SQL, databases, learning environment, mobile
                  learning, secondary education, tools, web-based
                  learning},
  abstract = 	 {Data modeling using databases and SQL is a fundamental part of the curriculum of secondary computing education in Germany. Professional database tools like HeidiSQL, phpMyAdmin or Microsoft Access are often used in class as a "learning software", although these tools have been developed for managing complex databases, often for companies, and not for educational purposes. Such tools offer a wide range of functions of which only a small part is required by secondary computing education. At the beginning of such instruction, students can hardly work independently with these programs, as they do not know the database language SQL by then. This often leads to theory-loaded introductory phases of such classes or alternatively to a usage of such tools like spreadsheet programs. To address this problem, a new web-based learning environment for databases and SQL (named eledSQL), also suitable for mobile devices and only with the functionality needed for secondary computing education, was developed. The basic idea was to initially allow students to make database queries using natural language and then gradually introduce them to the use of SQL. Starting with a problem analysis and a discussion of related work in the field of teaching databases and SQL, in this paper the conception of eledSQL, its implementation and first experiences with its practical use are described.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2481474&ftid=1371857&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:17>},
}

@inproceedings{Hacigumus:2002:ESO:564691.564717,
  author =	 {Hacig\"{u}m\"{u}\c{s}, Hakan and Iyer, Bala and Li,
                  Chen and Mehrotra, Sharad},
  title =	 {Executing SQL over Encrypted Data in the
                  Database-service-provider Model},
  booktitle =	 {Proceedings of the 2002 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '02},
  year =	 2002,
  isbn =	 {1-58113-497-5},
  location =	 {Madison, Wisconsin},
  pages =	 {216--227},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/564691.564717},
  doi =		 {10.1145/564691.564717},
  acmid =	 564717,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Rapid advances in networking and Internet technologies have fueled the emergence of the "software as a service" model for enterprise computing. Successful examples of commercially viable software services include rent-a-spreadsheet, electronic mail services, general storage services, disaster protection services. "Database as a Service" model provides users power to create, store, modify, and retrieve data from anywhere in the world, as long as they have access to the Internet. It introduces several challenges, an important issue being data privacy. It is in this context that we specifically address the issue of data privacy.There are two main privacy issues. First, the owner of the data needs to be assured that the data stored on the service-provider site is protected against data thefts from outsiders. Second, data needs to be protected even from the service providers, if the providers themselves cannot be trusted. In this paper, we focus on the second challenge. Specifically, we explore techniques to execute SQL queries over encrypted data. Our strategy is to process as much of the query as possible at the service providers' site, without having to decrypt the data. Decryption and the remainder of the query processing are performed at the client site. The paper explores an algebraic framework to split the query to minimize the computation at the client site. Results of experiments validating our approach are also presented.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=564717&ftid=86277&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:21>},
}

@inproceedings{Shimizu:1988:AFF:318123.318295,
  author =	 {Shimizu, Masami and Van Zoest, David},
  title =	 {Analysis of a Factory of the Future Using an
                  Integrated Set of Software for Manufacturing Systems
                  Modeling},
  booktitle =	 {Proceedings of the 20th Conference on Winter
                  Simulation},
  series =	 {WSC '88},
  year =	 1988,
  isbn =	 {0-911801-42-1},
  location =	 {San Diego, California, USA},
  pages =	 {671--677},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/318123.318295},
  doi =		 {10.1145/318123.318295},
  acmid =	 318295,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Design of a green-field factory, termed a 'factory of the future', proposed by an electrical equipment manufacturer was analyzed using an integrated set of software for manufacturing systems modeling.
The analysis involved the following four stages. First, a large data base containing part dimensions and processing conditions was analyzed using a spreadsheet software (Lotus 1-2-3) to generate a modeling data base. Second, a rough-cut analysis of each manufacturing line in the factory was performed utilizing queuing models (MANUPLAN II) to yield information regarding bottleneck stations, work-in-process levels, and part flow times. Third, detailed analysis for the entire factory with emphasis on the effects of job release dates and job scheduling rules was conducted by applying simulation models (SIMAN) which were rapidly created by a code-generation software (SimStarter). Finally, graphical animation of the entire factory was created (CINEMA) providing the company's design project team with a visual aid in understanding the factory they were designing.
The analysis procedure, from data base manipulation to graphical animation, was integrated by software linkages. This integration enabled the analysis team to complete their work in a short time frame, and provided valuable feedback to the factory design team. Thus, utilizing this integrated approach is expected to be beneficial to similar manufacturing design and analysis projects.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318295&ftid=9433&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:25>},
}

@inproceedings{Lloyd:1987:SSS:41866.41921,
  author =	 {Lloyd, Les},
  title =	 {Starting and Supporting a Software Library},
  booktitle =	 {Proceedings of the 15th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '87},
  year =	 1987,
  isbn =	 {0-89791-241-1},
  location =	 {Kansas City, Missouri, USA},
  pages =	 {305--308},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/41866.41921},
  doi =		 {10.1145/41866.41921},
  acmid =	 41921,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Drew is a private, liberal arts institution located in Madison, New Jersey. Originally founded as a Methodist seminary in the mid-1800's, the College of Liberal Arts was founded in 1929. The College of Liberal Arts, Theological School and Graduate School comprise Drew University today with combined enrollments of about 2200 students.
The College of Liberal Arts offers 27 degree programs. There are about 100 full-time faculty members, 1600 students and 300 staff and administration in the College.
In 1983, the faculty of the College of Liberal Arts initiated and overwhelmingly voted to support the Computer Initiative. The effort gained national attention, as Drew became the nation's first major liberal arts college to issue computers to incoming freshmen as part of their regular education package. Through this initiative, beginning in fall 1984, every Drew freshman was issued a personal computer for the course of undergraduate studies and to keep upon graduation. At the same time, every faculty member was issued a personal computer, and faculty voluntarily embraced a massive and continuing education program themselves to be able to adapt the computer into the college curriculum.
Staff offices also received computers as they were requested and faculty requests for additional computers to take home are considered on an individual basis.
When a freshman arrives at Drew, his or her computer and printer is set-up in his room and ready for use. A crew of students supervised by a staff member installs each computer and tests it during the two weeks before classes begin in the fall. This period of time is necessary to work around the physical plant's painting and cleaning schedule and dorm use by summer programs. In addition to the hardware, freshmen have received one or two word processors, along with graphics, spreadsheets and database software.
The Computer Initiative budget includes a line for software expense. The general guidelines on this fund is that the first copy of a package will be purchased by the Computer Initiative. If a department or course requires additional copies, we will do the price negotiation and acquisition of the software, but try to get them to fund it or charge the students depending on the use of the package. If the department's budget cannot handle the purchase, the Computer Initiative and/or the Dean of the College will assist in finding funds.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=41921&ftid=13903&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:30>},
}

@inproceedings{Adelfio:2011:SWD:2093973.2094056,
  author =	 {Adelfio, Marco D. and Nutanong, Sarana and Samet,
                  Hanan},
  title =	 {Searching Web Documents As Location Sets},
  booktitle =	 {Proceedings of the 19th ACM SIGSPATIAL International
                  Conference on Advances in Geographic Information
                  Systems},
  series =	 {GIS '11},
  year =	 2011,
  isbn =	 {978-1-4503-1031-4},
  location =	 {Chicago, Illinois},
  pages =	 {489--492},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2093973.2094056},
  doi =		 {10.1145/2093973.2094056},
  acmid =	 2094056,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {query processing, similarity search, spatial
                  databases},
  abstract = 	 {A geographic search system named GeoXLS is presented, which enables users to submit a set of locations as a query object Q and to find documents containing locations similar to those in Q. Search results come from a collection of geotagged web documents, specifically a vast collection of spreadsheets obtained from the Web. The results are ranked according to their similarity to Q, using one of several user-selected similarity measures related to the Hausdorff distance. GeoXLS allows users to answer queries such as "I know the locations of n entities of type X. What sets of data contain points similar to my query points?" For example, given a set Q of known impact craters, find documents that contain locations similar to those in Q and beyond. In essence, this allows someone to "complete the set" by identifying sets containing similar locations. GeoXLS provides capabilities analogous to a standard keyword search engine, but with keywords specified geographically. In contrast to a search engine that handles only text queries, our geographic search system is capable of returning search result documents that are not exact matches to the query. For example, searching with query points in "Washington, DC", "Denver, Colorado", and "Chicago, Illinois" could return documents related to colleges with actual locations in "College Park, Maryland", "Boulder, Colorado", and "Evanston, Illinois", which are similar spatially, but not textually. GeoXLS can be useful in a wide variety of knowledge domains where the data can be represented as a collection of point sets.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2094056&ftid=1081892&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:36>},
}

@article{Dickinson:2007:BID:1269900.1268904,
  author =	 {Dickinson, Anne},
  title =	 {'But I Don'T Read Text Printed in Braille Font'...:
                  Parables from a Business and Information Technology
                  Student},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {September 2007},
  volume =	 39,
  number =	 3,
  month =	 jun,
  year =	 2007,
  issn =	 {0097-8418},
  pages =	 {336--336},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1269900.1268904},
  doi =		 {10.1145/1269900.1268904},
  acmid =	 1268904,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {braille, disabilities, e-learning, information
                  technology, keyboard shortcuts, online learning,
                  stories, university student},
  abstract = 	 {The author works in Coventry University and has been engaged in tutoring a student with disabilities who had enrolled for a degree in Business and IT at Coventry University. To do this, the author drew upon previous experiences in the Further Education (FE) sector at a College in the Midlands, where she taught Information Technology (IT) to diverse groups of students who had varied abilities. The ages of the FE students ranged from pre-16, visiting the College from a local special school to attend "taster" sessions, to adults, some of whom were seniors, attending a day centre for disabled adults that had a special arrangement for College tutors to give classes. The degree student was a white cane user, read Braille and navigated the computer with screen reader software. During her time at University, she took on an ambassadorial role: she gave guided tours to prospective students around the University campus during open days! From time to time she would recount stories that she described as amusing but which clearly showed ignorance on the part of her tutors. The title of this presentation is taken from one of her anecdotes. The Degree course in Business and IT had several workshops in Computing including statistics where spreadsheets and specialist software were used. The author was asked to tutor the student for the IT workshops of a year-long module. This included translating the instructional handouts from mouse-based to keyboard-based, being aware of potential problems with specialist software and the quirks of the online learning system (WebCT) [1] and finding ways of working around them all. This poster shows some of the issues related to the student's stories, the creating and translating of instructions for keyboard use and navigating the keyboard using JAWS.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1268904&ftid=431030&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:42>},
}

@inproceedings{Dickinson:2007:BID:1268784.1268904,
  author =	 {Dickinson, Anne},
  title =	 {'But I Don'T Read Text Printed in Braille Font'...:
                  Parables from a Business and Information Technology
                  Student},
  booktitle =	 {Proceedings of the 12th Annual SIGCSE Conference on
                  Innovation and Technology in Computer Science
                  Education},
  series =	 {ITiCSE '07},
  year =	 2007,
  isbn =	 {978-1-59593-610-3},
  location =	 {Dundee, Scotland},
  pages =	 {336--336},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1268784.1268904},
  doi =		 {10.1145/1268784.1268904},
  acmid =	 1268904,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {braille, disabilities, e-learning, information
                  technology, keyboard shortcuts, online learning,
                  stories, university student},
  abstract = 	 {The author works in Coventry University and has been engaged in tutoring a student with disabilities who had enrolled for a degree in Business and IT at Coventry University. To do this, the author drew upon previous experiences in the Further Education (FE) sector at a College in the Midlands, where she taught Information Technology (IT) to diverse groups of students who had varied abilities. The ages of the FE students ranged from pre-16, visiting the College from a local special school to attend "taster" sessions, to adults, some of whom were seniors, attending a day centre for disabled adults that had a special arrangement for College tutors to give classes. The degree student was a white cane user, read Braille and navigated the computer with screen reader software. During her time at University, she took on an ambassadorial role: she gave guided tours to prospective students around the University campus during open days! From time to time she would recount stories that she described as amusing but which clearly showed ignorance on the part of her tutors. The title of this presentation is taken from one of her anecdotes. The Degree course in Business and IT had several workshops in Computing including statistics where spreadsheets and specialist software were used. The author was asked to tutor the student for the IT workshops of a year-long module. This included translating the instructional handouts from mouse-based to keyboard-based, being aware of potential problems with specialist software and the quirks of the online learning system (WebCT) [1] and finding ways of working around them all. This poster shows some of the issues related to the student's stories, the creating and translating of instructions for keyboard use and navigating the keyboard using JAWS.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1268904&ftid=431030&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:46>},
}

@inproceedings{Quercini:2013:EDA:2452376.2452457,
  author =	 {Quercini, Gianluca and Reynaud, Chantal},
  title =	 {Entity Discovery and Annotation in Tables},
  booktitle =	 {Proceedings of the 16th International Conference on
                  Extending Database Technology},
  series =	 {EDBT '13},
  year =	 2013,
  isbn =	 {978-1-4503-1597-5},
  location =	 {Genoa, Italy},
  pages =	 {693--704},
  numpages =	 12,
  url =		 {http://doi.acm.org/10.1145/2452376.2452457},
  doi =		 {10.1145/2452376.2452457},
  acmid =	 2452457,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {Google fusion tables, entity annotation in tables,
                  entity discovery in tables},
  abstract = 	 {The Web is rich of tables (e.g., HTML tables, spreadsheets, Google Fusion Tables) that host a considerable wealth of high-quality relational data. Unlike unstructured texts, tables usually favour the automatic extraction of data because of their regular structure and properties. The data extraction is usually complemented by the annotation of the table, which determines its semantics by identifying a type for each column, the relations between columns, if any, and the entities that occur in each cell. In this paper, we focus on the problem of discovering and annotating entities in tables. More specifically, we describe an algorithm that identifies the rows of a table that contain information on entities of specific types (e.g., restaurant, museum, theatre) derived from an ontology and determines the cells in which the names of those entities occur. We implemented this algorithm while developing a faceted browser over a repository of RDF data on points of interest of cities that we extracted from Google Fusion Tables. We claim that our algorithm complements the existing approaches, which annotate entities in a table based on a pre-compiled reference catalogue that lists the types of a finite set of entities; as a result, they are unable to discover and annotate entities that do not belong to the reference catalogue. Instead, we train our algorithm to look for information on previously unseen entities on the Web so as to annotate them with the correct type.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2452457&ftid=1356031&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:50>},
}

@inproceedings{Chamanara:2012:SQL:2389686.2389690,
  author =	 {Chamanara, Javad and K\"{o}nig-Ries, Birgitta},
  title =	 {SciQL: A Query Language for Unified Scientific Data
                  Processing and Management},
  booktitle =	 {Proceedings of the 5th Ph.D. Workshop on Information
                  and Knowledge},
  series =	 {PIKM '12},
  year =	 2012,
  isbn =	 {978-1-4503-1719-1},
  location =	 {Maui, Hawaii, USA},
  pages =	 {17--24},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/2389686.2389690},
  doi =		 {10.1145/2389686.2389690},
  acmid =	 2389690,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {data lifecycle management, scientific data
                  processing, scientific query language},
  abstract = 	 {Science is more and more data-driven. This means, that a significant part of a scientist's work is dedicated to accessing, visualizing, integrating and analyzing data from a possibly wide range of heterogeneous sources. In this paper we propose SciQL, a query language that supports scientists in this task and allows them to focus on their main purpose, i.e., on doing research. SciQL sits between scientists or data processing tools on the one hand and different data sources on the other hand in order to decouple users from technical aspects of accessing data. It allows users to express their data management, refinement, transformation, processing procedures and visualizations in SciQL regardless of the syntax and capabilities of the underlying physical data source sources. This way scientists and client tools deal with only one language to interact with different data sources, e.g., text files, spreadsheets, relational DBMSs, or MapReduce systems. To achieve this, SciQL provides various constructs among them Schema Definition, (e.g., schema design and Data transformation), Data Retrieval (connecting to various data sources and formats, filtering, joining, grouping), Data Manipulation (e.g. Updating, deleting, versioning and provenance) and Visualization commands and data structures can be named. In this paper, we will discuss the general idea why we believe SciQL is needed, and explain the goals and the steps we intend to take in order to achieve these aims.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2389690&ftid=1303539&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:08:53>},
}

@article{Pirolli:1987:CMC:28189.1044816,
  author =	 {Pirolli, Peter},
  title =	 {A Cognitive Model and Computer Tutor for Programming
                  Recursion},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {July 1987},
  volume =	 19,
  number =	 1,
  month =	 jul,
  year =	 1987,
  issn =	 {0736-6906},
  pages =	 {75--},
  url =		 {http://dl.acm.org/citation.cfm?id=28189.1044816},
  acmid =	 1044816,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper aims at finding the optimal combination of written instruction and on-line practice for learning a new computer application. Experimental subjects learned commands for an electronic spreadsheet by reading brief user-manual descriptions and working training problems on-line. The form of the training problems was varied within subjects in order to control how much independent problem solving subjects engaged in while learning any given command. There were three forms of practice: (1) Pure Guided Practice, in which subjects were told exactly what keystrokes to type to solve the problems; (2) Pure Problem Solving Practice, in which subjects solved problems without guidance; and (3) Mixed Practice, in which the first problem for a command was presented in Guided Practice form and two others in Problem Solving form. The spacing of the training problems was also manipulated; the problems pertaining to a given command were either Massed (i.e., presented consecutively), or Distributed (i.e., separated by other instructional material). After a 2-day delay, subjects solved new problems on the computer without referring to the instructional materials. The results indicate that problem solving was a more difficult form of training than guided practice, but it produced the best performance at test. Distributing the spacing of training problems during training also improved performance at test. The results have clear pragmatic implications for the design of interactive tutorial manuals as well as implications for cognitive models of skill acquisition.},
  review = 	 {fbie: rejected <2016-01-15 14:08:59>},
}

@inproceedings{Chatziantoniou:2014:IDC:2627770.2627773,
  author =	 {Chatziantoniou, Damianos and Tselai, Florents},
  title =	 {Introducing Data Connectivity in a Big Data Web},
  booktitle =	 {Proceedings of Workshop on Data Analytics in the
                  Cloud},
  series =	 {DanaC'14},
  year =	 2014,
  isbn =	 {978-1-4503-2997-2},
  location =	 {Snowbird, UT, USA},
  pages =	 {7:1--7:4},
  articleno =	 7,
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/2627770.2627773},
  doi =		 {10.1145/2627770.2627773},
  acmid =	 2627773,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ODMC, big data integration, big data
                  interoperability, big data web, data connectivity,
                  open data management connectivity},
  abstract = 	 {Until recently, when relational systems was the main data management option and SQL the de facto language for querying/analyzing data, ODBC was an excellent API for applications to interact with the data provider. Standardization of data retrieval has helped innovation and productivity, allowing application developers to focus on the core of their ideas. However, the big data era added variety to all aspects of data facilitation: variety in data management options, variety in data formats, variety in querying/analyzing tasks. In this chaotic situation, standardizing data connectivity is more important than ever. What should be the replacement of ODBC? In this paper, we propose ODMC (Open Data Management Connectivity), a client-server protocol between data management entities (DMEs). A DME is anything that manages/manipulates data. In that respect, spreadsheets, java programs, Hadoop, RDBMs, stream engines, NoSQL, etc., all act as DMEs. In addition, there is no distinction between applications and data management servers, as in ODBC. A DME can be a data consumer in an ODMC instance and a data producer in another. This composability principle allows for the definition of analysis workflows. We present a preliminary implementation of ODMC for python-based DMEs. We argue that ODMC is simple, intuitive, scalable and suitable for both persistent and stream data.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2627773&ftid=1493860&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:03>},
}

@article{Schiettecatte:1991:PN:126729.1056087,
  author =	 {Schiettecatte},
  title =	 {Publication Notes},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {Oct. 1991},
  volume =	 23,
  number =	 4,
  month =	 oct,
  year =	 1991,
  issn =	 {0736-6906},
  pages =	 {90--91},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/126729.1056087},
  doi =		 {10.1145/126729.1056087},
  acmid =	 1056087,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This book comes as a reminder that HCI does not only occur when users interact with a word-processor to produce a document, or use a spreadsheet to produce a financial model, but also when they control and manage complex dynamic systems (complex dynamic systems in this case include such things as chemical plants or nuclear power stations). This book consists of a collection of papers (each paper making up a chapter, there are 12 chapters in the book) brought together to illustrate the problems involved in designing computer interfaces to manage complex dynamic systems. An interesting thing to point out about these papers is that all but one of them were written by Europeans. The book in itself is a very good example of international collaboration, with authors from two different continents and eight different countries. This book also gives us a look into the kind of research that is going on in Europe in terms of Human-Computer Interaction and complex dynamic systems.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1056087&ftid=310128&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:07>},
}

@article{Dickinson:2007:SQW:1269900.1268930,
  author =	 {Dickinson, Anne},
  title =	 {Is the Shortcut the Quickest Way to Go?: Translating
                  Instructions for Keyboard Navigation and Other
                  Stories},
  journal =	 {SIGCSE Bull.},
  issue_date =	 {September 2007},
  volume =	 39,
  number =	 3,
  month =	 jun,
  year =	 2007,
  issn =	 {0097-8418},
  pages =	 {358--358},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1269900.1268930},
  doi =		 {10.1145/1269900.1268930},
  acmid =	 1268930,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {braille, disabilities, e-learning, information
                  technology, keyboard shortcuts, online learning,
                  stories, university student},
  abstract = 	 {The author works in Coventry University and has been engaged in tutoring a student with disabilities who had enrolled for a degree in Business and IT at Coventry University. To do this, the author drew upon previous experiences in the Further Education (FE) sector at a College in the Midlands, where she taught Information Technology (IT) to diverse groups of students who had varied abilities. The ages of the FE students ranged from pre-16, visiting the College from a local special school to attend "taster" sessions, to adults, some of whom were seniors, attending a day centre for disabled adults that had a special arrangement for College tutors to give classes. The degree student was a white cane user, read Braille and navigated the computer with screen reader software. During her time at University, she took on an ambassadorial role: she gave guided tours to prospective students around the University campus during open days! From time to time she would recount stories that she described as amusing but which clearly showed ignorance on the part of her tutors. The Degree course in Business and IT had several workshops in Computing including statistics where spreadsheets and specialist software were used. The author was asked to tutor the student for the IT workshops of a year-long module. This included translating the instructional handouts from mouse-based to keyboard-based, being aware of potential problems with specialist software and the quirks of the online learning system (WebCT) [1] and finding ways of working around them all. This "tips and techniques" session gives an account of some of these issues around the student's stories, creating and translating instructions for keyboard use navigating the keyboard using JAWS, and includes proposed solutions.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1268930&ftid=431335&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:13>},
}

@inproceedings{Dickinson:2007:SQW:1268784.1268930,
  author =	 {Dickinson, Anne},
  title =	 {Is the Shortcut the Quickest Way to Go?: Translating
                  Instructions for Keyboard Navigation and Other
                  Stories},
  booktitle =	 {Proceedings of the 12th Annual SIGCSE Conference on
                  Innovation and Technology in Computer Science
                  Education},
  series =	 {ITiCSE '07},
  year =	 2007,
  isbn =	 {978-1-59593-610-3},
  location =	 {Dundee, Scotland},
  pages =	 {358--358},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1268784.1268930},
  doi =		 {10.1145/1268784.1268930},
  acmid =	 1268930,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {braille, disabilities, e-learning, information
                  technology, keyboard shortcuts, online learning,
                  stories, university student},
  abstract = 	 {The author works in Coventry University and has been engaged in tutoring a student with disabilities who had enrolled for a degree in Business and IT at Coventry University. To do this, the author drew upon previous experiences in the Further Education (FE) sector at a College in the Midlands, where she taught Information Technology (IT) to diverse groups of students who had varied abilities. The ages of the FE students ranged from pre-16, visiting the College from a local special school to attend "taster" sessions, to adults, some of whom were seniors, attending a day centre for disabled adults that had a special arrangement for College tutors to give classes. The degree student was a white cane user, read Braille and navigated the computer with screen reader software. During her time at University, she took on an ambassadorial role: she gave guided tours to prospective students around the University campus during open days! From time to time she would recount stories that she described as amusing but which clearly showed ignorance on the part of her tutors. The Degree course in Business and IT had several workshops in Computing including statistics where spreadsheets and specialist software were used. The author was asked to tutor the student for the IT workshops of a year-long module. This included translating the instructional handouts from mouse-based to keyboard-based, being aware of potential problems with specialist software and the quirks of the online learning system (WebCT) [1] and finding ways of working around them all. This "tips and techniques" session gives an account of some of these issues around the student's stories, creating and translating instructions for keyboard use navigating the keyboard using JAWS, and includes proposed solutions.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1268930&ftid=431335&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:16>},
}

@inproceedings{Aji:2011:BEP:2016604.2016637,
  author =	 {Aji, Ashwin M. and Daga, Mayank and Feng, Wu-chun},
  title =	 {Bounding the Effect of Partition Camping in GPU
                  Kernels},
  booktitle =	 {Proceedings of the 8th ACM International Conference
                  on Computing Frontiers},
  series =	 {CF '11},
  year =	 2011,
  isbn =	 {978-1-4503-0698-0},
  location =	 {Ischia, Italy},
  pages =	 {27:1--27:10},
  articleno =	 27,
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/2016604.2016637},
  doi =		 {10.1145/2016604.2016637},
  acmid =	 2016637,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {GPGPU, micro-benchmarks, multiple linear regression,
                  partition camping, performance modeling},
  abstract = 	 {Current GPU tools and performance models provide some common architectural insights that guide the programmers to write optimal code. We challenge and complement these performance models and tools, by modeling and analyzing a lesser known, but very severe performance pitfall, called Partition Camping, in NVIDIA GPUs. Partition Camping is caused by memory accesses that are skewed towards a subset of the available memory partitions, which may degrade the performance of GPU kernels by up to seven-fold. There is no existing tool that can detect the partition camping effect in GPU kernels. Unlike the traditional performance modeling approaches, we predict a performance range that bounds the partition camping effect in the GPU kernel. Our idea of predicting a performance range, instead of the exact performance, is more realistic due to the large performance variations induced by partition camping. We design and develop the prediction model by first characterizing the effects of partition camping with an indigenous suite of micro-benchmarks. We then apply rigorous statistical regression techniques over the micro-benchmark data to predict the performance bounds of real GPU kernels, with and without the partition camping effect. We test the accuracy of our performance model by analyzing three real applications with known memory access patterns and partition camping effects. Our results show that the geometric mean of errors in our performance range prediction model is within 12\% of the actual execution times. We also develop and present a very easy-to-use spreadsheet based tool called CampProf, which is a visual front-end to our performance range prediction model and can be used to gain insights into the degree of partition camping in GPU kernels. Lastly, we demonstrate how CampProf can be used to visually monitor the performance improvements in the kernels, as the partition camping effect is being removed.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2016637&ftid=1009966&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:21>},
}

@article{Dufresne:1990:EBD:101288.101296,
  author =	 {Dufresne, Aude and Tremblay, Isabelle and Turcotte,
                  Sylvie},
  title =	 {Exploratory Behaviors and the Design of Computer
                  Instruction Manuals in Hypertext},
  journal =	 {SIGCHI Bull.},
  issue_date =	 {Jul. 1990},
  volume =	 22,
  number =	 1,
  month =	 jun,
  year =	 1990,
  issn =	 {0736-6906},
  pages =	 {40--41},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/101288.101296},
  doi =		 {10.1145/101288.101296},
  acmid =	 101296,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This study explores the problem of designing an environment for the learning of procedures using an hypertext environment. It presents an HYPERCARD interface for the learning of database procedures for the EXCEL spreadsheet. Direct manipulation interfaces (Shneiderman, 1982) encourage exploration and learning, but are not very effective for complex and abstract applications, which require planning and the coordination of many operations. For these interfaces, written documentation and help features are generally too fragmented and static. As for rigid tutorials they prove ineffective for the learning of complex procedures, as they leave no room for inferences. We will discuss the design of a learning environment to encourage and support exploration in this context. The system is based on a protocol analysis of users reading the written documentation and trying the system. Semantic, syntactic and process analyses have shown how users build their representations of the procedures to be learned (lexical ambiguities, inversion of sequences, search for illustrations, etc.). Based on this user model and drawing from studies on learning, a new environment was developed in Hypercard which put forward an interactional structure for the learning of direct manipulation procedures. Inspired both by the G.O.M.S. model (Card, Newell and Moran, 1983) and by "planning interfaces" (Miller, 1982), it first presents the hierarchy of goals, then outlines methods with accessible definitions, examples, exercises and various tests. Only there after these are alternative methods and selection rules explained. As in "planning interfaces", the system offers explanation both at the general level of goals and methods and at the concrete level of their integration into concrete examples. The user is free to explore this "training wheel" environment, where aspects of the Excel environment are simulated and gradually made accessible, with appropriate guidance and feedback.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=101296&ftid=298802&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:24>},
}

@inproceedings{Federman:1988:SPM:62548.62651,
  author =	 {Federman, Alan},
  title =	 {A Self-service PC-LAN-or-how Many Ways Are There to
                  Insert a Diskette in a Drive?},
  booktitle =	 {Proceedings of the 16th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '88},
  year =	 1988,
  isbn =	 {0-89791-286-1},
  location =	 {Long Beach, California, USA},
  pages =	 {313--322},
  numpages =	 10,
  url =		 {http://doi.acm.org/10.1145/62548.62651},
  doi =		 {10.1145/62548.62651},
  acmid =	 62651,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Indiana University - Purdue University at Fort Wayne has established a self-service PC-LAN for use by faculty, students, and staff. The cluster consists of 15 IBM PS/2 Model 30's, 6 IBM XT's, and two IBM Proprinters. The machines all have IBM token ring cards with auto-boot ROMs from Novell. As in most public institutions, it is much easier to get funding for equipment than it is for personnel. We simply do not have the staff to check-out diskettes. The PC's are connected to a AT type server running Novell Netware. The auto-boot feature eliminates the need to supply boot disks. A student can come in at anytime to do a class assignment or word processing. The server truly is just that; it dishes out the software to the user via a menu. Students who wish to save data must use their own diskettes.
Currently, all software selection is accomplished through Novell's “point and shoot” menuing system. A rich variety of software is available, including commercial applications, shareware, instructor developed programs, tutorials, demonstrations, and packages developed by various academic consortia. Our commercial applications include Lotus, WordPerfect and WordStar. Shareware programs include PC-Write, Express-Calc, File-Express and Express-Graph.
The difficulties with hardware and software have been minor. Some programs, which run well in a stand-alone mode, do not work well on a network. This is especially true of programs which load their own DOS shell. Other programs, some advertised as network versions, were less than satisfactory. The hardware has been relatively trouble free. Two power supplies and one cable were replaced. The most significant problems concerned inadequate training. The cluster is designed to be self-documenting and easy to use. There are on-line tutorials that cover DOS, word processing, spreadsheets, etc. Manuals for all the popular software are located in racks in the room. Despite this, many people come into to the cluster (having been given a class assignment by an instructor) without the faintest idea how to proceed. Very few instructors have visited the cluster or discussed its use before unleashing their students. We underestimated the amount of hand-holding that this group would need. We also badly underestimated the volume of printing produced.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=62651&ftid=12729&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:30>},
}

@inproceedings{Whisnant:2010:ESC:1878335.1878403,
  author =	 {Whisnant, Austin and Childress, Jean},
  title =	 {Empowering Students to Create Work Schedules That
                  Work},
  booktitle =	 {Proceedings of the 38th Annual ACM SIGUCCS Fall
                  Conference: Navigation and Discovery},
  series =	 {SIGUCCS '10},
  year =	 2010,
  isbn =	 {978-1-4503-0003-2},
  location =	 {Norfolk, Virginia, USA},
  pages =	 {273--276},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1878335.1878403},
  doi =		 {10.1145/1878335.1878403},
  acmid =	 1878403,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {management, scheduling, student employees},
  abstract = 	 {Furman employs student staff as a major component in our organization. We recognize the intrinsic value of students who need part time work and who are often savvier than the general user population. However, there are major challenges in scheduling around the demanding academic and social commitments of the student staff. We need ways to simplify scheduling while retaining flexibility, which honors academics as a primary consideration. Like other help desks, Furman has used many scheduling strategies such as calendars, spreadsheets, color-coded databases. All have fallen short. We have returned to a largely manual process each term. To make the process more automated, we have created ShiftWhiz. ShiftWhiz, a scheduling and management application, was designed for university help desks to solve the problem of scheduling in a complex environment where multiple student employees can only work short shifts at specific times. ShiftWhiz is a web app (PHP with a MySQL database) for the purposes of flexibility and simplicity. Although initially an effort was made to keep features minimal and keep the program simple for both users and developers, a testing phase called for more functionality than was originally envisioned. The resulting web application incorporates multiple management functions in one convenient place. Managers save time by avoiding constantly manipulating schedules, searching for employee information, and updating email lists. ShiftWhiz lets managers shift some of the burden of creating and revising schedules to student workers while maintaining control and privacy. As a bonus, ShiftWhiz also facilitates communication in the workplace with certain email functionality, bulletins, and contact information.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1878403&ftid=852545&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:35>},
}

@inproceedings{Chu:2015:TTE:2723372.2723725,
  author =	 {Chu, Xu and He, Yeye and Chakrabarti, Kaushik and
                  Ganjam, Kris},
  title =	 {TEGRA: Table Extraction by Global Record Alignment},
  booktitle =	 {Proceedings of the 2015 ACM SIGMOD International
                  Conference on Management of Data},
  series =	 {SIGMOD '15},
  year =	 2015,
  isbn =	 {978-1-4503-2758-9},
  location =	 {Melbourne, Victoria, Australia},
  pages =	 {1713--1728},
  numpages =	 16,
  url =		 {http://doi.acm.org/10.1145/2723372.2723725},
  doi =		 {10.1145/2723372.2723725},
  acmid =	 2723725,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {html lists, information extraction, table
                  extraction, web tables},
  abstract = 	 {It is well known today that pages on the Web contain a large number of content-rich relational tables. Such tables have been systematically extracted in a number of efforts to empower important applications such as table search and schema discovery. However, a significant fraction of relational tables are not embedded in the standard HTML table tags, and are thus difficult to extract. In particular, a large number of relational tables are known to be in a ``list'' form, which contains a list of clearly separated rows that are not separated into columns. In this work, we address the important problem of automatically extracting multi-column relational tables from such lists. Our key intuition lies in the simple observation that in correctly-extracted tables, values in the same column are coherent, both at a syntactic and at a semantic level. Using a background corpus of over 100 million tables crawled from the Web, we quantify semantic coherence based on a statistical measure of value co-occurrence in the same column from the corpus. We then model table extraction as a principled optimization problem -- we allocate tokens in each row sequentially to a fixed number of columns, such that the sum of coherence across all pairs of values in the same column is maximized. Borrowing ideas from $A^\star$ search and metric distance, we develop an efficient 2-approximation algorithm. We conduct large-scale table extraction experiments using both real Web data and proprietary enterprise spreadsheet data. Our approach considerably outperforms the state-of-the-art approaches in terms of quality, achieving over 90\% F-measure across many cases.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2723725&ftid=1586878&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:39>},
}

@inproceedings{Simpson:1989:UID:74311.74322,
  author =	 {Simpson, M.},
  title =	 {Users Invoked: How Documents Help Readers Assume
                  User Roles},
  booktitle =	 {Proceedings of the 7th Annual International
                  Conference on Systems Documentation},
  series =	 {SIGDOC '89},
  year =	 1989,
  isbn =	 {0-89791-337-X},
  location =	 {Pittsburg, Pennsylvania, USA},
  pages =	 {85--92},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/74311.74322},
  doi =		 {10.1145/74311.74322},
  acmid =	 74322,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A typical and often productive response to writing for documentation audiences is to think in terms of types or genres of documentation—reference manuals, tutorials, “using” manuals, quick reference books and cards, and so on. These categories can help writers think about readers, at least the general purposes for which readers consult documentation.
Unfortunately these forms of documentation say little about the many local decisions computer users make as they read documentation. Sticht (1985), Diehl and Mikulecky (1981) and others have described how readers may read to do specific tasks or read to learn material. Sullivan and Flower (1986) show that users may not read a manual or section of a manual in its entirety, and that when they do read, they read to answer questions that arise during a task. The implication of this research is that users' purposes for reading are likely to vary and that these purposes may be determined by work-related tasks or problems which occur during the tasks.
A question arises, however, about the role of texts in influencing how readers read computer manuals. If readers' purposes for reading come from outside text—a task or problem stemming from a task—do the text themselves influence the readers? Rhetorical theory suggests one answer: that cues in texts invoke reader roles which readers take on as they read.
The theory comes to rhetoric by way of literary criticism and rhetoric. Gibson (1949-50), for instance, argues that tests imply a “mock reader,” an entity distinct from the real reader, by marshaling semantic and syntactic cues in a text. The rhetorician Walter Ong (1977) develops this idea further; he explains that the mock or fictionalized reader is actually a role created in the text and that the notion of reader roles is relevant to all writing, not just fictional writing: The “historian, the scholar or scientist, and the simple letter writer all fictionalize their audiences, casting them in a make-up role and calling on them to play the role assigned” (p. 74). Ede and Lunsford (1984) apply the concept of reader roles to composition theory and acknowledge that it is applicable to such nonfictional forms of writing as academic journal articles, business letters, and student academic writing.
Although the concept of reader roles has been applied to several kinds of writing, the concept's relevance to computer documentation is largely unexplored. If computer documentation does invoke reader roles, then the notion of roles needs to be considered by writers as they plan and write documentation. Writers would have to be certain that their documents invoke a role consistent with their intended uses. To explore this issue, I decided to re-examine the results of user protocols made during a test of the Microsoft Works V2.0 documentation at the Microsoft Corporation. Microsoft Works is an integrated PC applications program that contains a word processor, spreadsheet, database, and communications program.
A major goal of the original documentation test was to determine how well users could navigate in and use the Works V2.0 alphabetic reference.1 The reference combined the features of a typical reference—for example, an alphabetic arrangement of key topics and commands—with features of user's guide, such as conceptual explanations of topics as well as step-by-step guides to commands and tasks. My re-examination of the data from the Works test was prompted by two questions:
What kinds of roles might computer documentation invoke, and what cues might invoke them?
When users read computer documentation containing role cues, how do users respond to them?
In this paper I will answer these questions and explain how the answers can affect the writing of computer documentation.},
  review = 	 {fbie: rejected <2016-01-15 14:09:44>},
}

@article{Linton:1996:POL:242206.242329,
  author =	 {Linton, Frank},
  title =	 {Promoting the Organization-wide Learning of
                  Application Software},
  journal =	 {SIGOIS Bull.},
  issue_date =	 {Dec. 1996},
  volume =	 17,
  number =	 3,
  month =	 dec,
  year =	 1996,
  issn =	 {0894-0819},
  pages =	 {70--72},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/242206.242329},
  doi =		 {10.1145/242206.242329},
  acmid =	 242329,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This paper describes the characteristics of a system designed to promote one sort of organizational learning (Senge, 1990), in particular, to enhance the organization-wide learning of application software (note 1). The system presented here will (1) capture evolving expertise from a community of practice (Lave &amp;amp; Wenger 1991), (2) support less-skilled members of the community in acquiring that expertise, and (3) serve as an organizational memory for the expertise it captures. One version of the system has been partially implemented for a software engineering environment (Linton, 1990).In many workplaces &amp;hellip; mastery is in short supply and what is required is a kind of collaborative bootstrapping of expertise. (Eales &amp;amp; Welch, 1995, p. 100)The main goal of the design is to continuously improve the performance of application users by providing individualized coaching based on the automated comparison of user logs to expert models. The system discussed here would be suitable for situations in which the following assumptions are true:(1) People who hold similar jobs and perform similar tasks have similar software usage patterns, e.g., managers use spreadsheet financial functions when preparing budgets, researchers use multiple views of the text when preparing journal articles, and salespeople use standard request forms when making travel arrangements.(2) Some people systematically make better use of their applications than others.(3) Everyone benefits when employees become optimal users of their application software (note 2).The fundamental requirement of the envisioned system is the capability to log the software usage patterns of a large number of individuals. Networked PC computing has recently made this logging requirement practical.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=242329&ftid=109382&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:49>},
}

@article{L'Ecuyer:1990:RNS:84537.84555,
  author =	 {L'Ecuyer, Pierre},
  title =	 {Random Numbers for Simulation},
  journal =	 {Commun. ACM},
  issue_date =	 {Oct. 1990},
  volume =	 33,
  number =	 10,
  month =	 oct,
  year =	 1990,
  issn =	 {0001-0782},
  pages =	 {85--97},
  numpages =	 13,
  url =		 {http://doi.acm.org/10.1145/84537.84555},
  doi =		 {10.1145/84537.84555},
  acmid =	 84555,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In the mind of the average computer user, the problem of generating uniform variates by computer has been solved long ago. After all, every computer :system offers one or more function(s) to do so. Many software products, like compilers, spreadsheets, statistical or numerical packages, etc. also offer their own. These functions supposedly return numbers that could be used, for all practical purposes, as if they were the values taken by independent random variables, with a uniform distribution between 0 and 1. Many people use them with faith and feel happy with the results. So, why bother?
Other (less naive) people do not feel happy with the results and with good reasons. Despite renewed crusades, blatantly bad generators still abound, especially on microcomputers [55, 69, 85, 90, 100]. Other generators widely used on medium-sized computers are perhaps not so spectacularly bad, but still fail some theoretical and/or empirical statistical tests, and/or generate easily detectable regular patterns [56, 65].
Fortunately, many applications appear quite robust to these defects. But with the rapid increase in desktop computing power, increasingly sophisticated simulation studies are being performed that require more and more “random” numbers and whose results are more sensitive to the quality of the underlying generator [28, 40, 65, 90]. Sometimes, using a not-so-good generator can give totally misleading results. Perhaps this happens rarely, but can be disastrous in some cases. For that reason, researchers are still actively investigating ways of building generators. The main goal is to design more robust generators without having to pay too much in terms of portability, flexibility, and efficiency. In the following sections, we give a quick overview of the ongoing research. We focus mainly on efficient and recently proposed techniques for generating uniform pseudorandom numbers. Stochastic simulations typically transform such numbers to generate variates according to more complex distributions [13, 25]. Here, “uniform pseudorandom” means that the numbers behave from the outside as if they were the values of i.i.d. random variables, uniformly distributed over some finite set of symbols. This set of symbols is often a set of integers of the form {0, . . . , m - 1} and the symbols are usually transformed by some function into values between 0 and 1, to approximate the U(0, 1) distribution. Other tutorial-like references on uniform variate generation include [13, 23, 52, 54, 65, 84, 89].},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=84555&ftid=11574&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:09:53>},
}

@inproceedings{Boyer:2003:BBP:968559.968576,
  author =	 {Boyer, John M.},
  title =	 {Bulletproof Business Process Automation: Securing
                  XML Forms with Document Subset Signatures},
  booktitle =	 {Proceedings of the 2003 ACM Workshop on XML
                  Security},
  series =	 {XMLSEC '03},
  year =	 2003,
  isbn =	 {1-58113-777-X},
  location =	 {Fairfax, Virginia},
  pages =	 {104--111},
  numpages =	 8,
  url =		 {http://doi.acm.org/10.1145/968559.968576},
  doi =		 {10.1145/968559.968576},
  acmid =	 968576,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {XFDL, XForms, XML signature transforms, secure XML
                  forms},
  abstract = 	 {The standard unit of work in the business process is the electronic form, which includes complex user interface designs, data gathering and validation, wizard-like behaviors and spreadsheet computations. This paper reports state-of-the-art digital signature methods used to help provide security, non-repudiation and auditability within complex electronic forms applications. Both for financial reasons and for compliance with government regulations such as the Government Paper Elimination Act (GPEA), an ever-increasing number of intricate electronic forms applications are being created. Yet, there are aspects of paper-based systems that can only be modelled if digital signatures are able to omit carefully specified portions of a document so that certain restricted changes can be made after a signature is affixed. These scenarios occur frequently with electronic forms that are multiply signed and possibly involved in a non-trivial workflow process.Due to the importance of securing electronic forms and the complexities that can arise in signing them, the W3C XForms working group has placed integration with XML signatures among the highest priorities of its new standardization charter. However, there are security issues that must be addressed but which are beyond the core cryptographic capabilities of the W3C XML Signature Recommendation. This paper presents our research into and solutions for these issues. The purpose of this paper is to let successful industry experience and academic analysis provide guidance to future secure document standardization efforts (such as XForms) so that, even in the most demanding signature scenarios, the standards are still able to meet the fundamental requirement of digital signatures: What you see is what you sign.},
  review = 	 {fbie: rejected <2016-01-15 14:09:59>},
}

@inproceedings{Derksen:2013:DDU:2493102.2493115,
  author =	 {Derksen, Gerry and Ruecker, Stan and Causer, Tim and
                  Terras, Melissa},
  title =	 {Demonstrating Data Using Storyboard Visualization
                  Tool},
  booktitle =	 {Proceedings of the 6th International Symposium on
                  Visual Information Communication and Interaction},
  series =	 {VINCI '13},
  year =	 2013,
  isbn =	 {978-1-4503-1988-1},
  location =	 {Tianjin, China},
  pages =	 {117--117},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/2493102.2493115},
  doi =		 {10.1145/2493102.2493115},
  acmid =	 2493115,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {BigData, latent dirichlet allocation, narrative,
                  storyboard},
  abstract = 	 {With the growing importance of big data, and perhaps more significantly, the application of big data to the quantified self, it is more useful than ever for designers to be conversant with the wide range of measurements that can be obtained from various forms of instrumentation. When chairs can record and communicate details about sitting, sidewalks make suggestions about walking, and shavers monitor diet, interesting opportunities will arise for designers to generate new affordances based on the data. However, for many designers, the process of understanding the numbers available in the spreadsheets and databases may prove prohibitive, unless new methods are developed for showing relevance while not losing track of the underlying information. In this presentation, I propose a new genre of "data stories," where the goal is to create narratives that are anchored in big data, but provide a form of shared experience that can be used to both shape design ideas and communicate their potential significance. More generally, Data Stories might take the form of shared narratives, concept maps, conversational models, or corporate missions that have the best chance to be adopted by listeners of stories if they have data anchoring points of fact. Data Stories are important because they can help to provide context for information and thereby create a shared framework for understanding. They can also help to make information compelling and memorable. In addition, they provide a starting point for others to contribute, modify, and personalize. From the designer's perspective, they are a way to establish authority, show practical approaches that are anchored in the data, and clarify details in memorable descriptions.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2493115&ftid=1387029&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:04>},
}

@article{Samuelson:1990:LSI:92755.92784,
  author =	 {Samuelson, Pamela},
  title =	 {Legally Speaking: How to Interpret the Lotus
                  Decision (and How Not to)},
  journal =	 {Commun. ACM},
  issue_date =	 {Nov. 1990},
  volume =	 33,
  number =	 11,
  month =	 nov,
  year =	 1990,
  issn =	 {0001-0782},
  pages =	 {27--33},
  numpages =	 7,
  url =		 {http://doi.acm.org/10.1145/92755.92784},
  doi =		 {10.1145/92755.92784},
  acmid =	 92784,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {On June 28, 1990, a federal court judge in Boston made public his decision in favor of Lotus Development Corporation in its software copyright lawsuit against Paperback Software. People in the software industry had been waiting for this decision since the lawsuit was first filed in January 1987, certain that it would be a landmark case and would resolve many vexing questions about copyright protection for user interfaces.The trade press has abounded with varying interpretations of Judge Keeton's opinion in the Lotus case: Some have said the decision is a narrow one, making illegal only the direct copying of another firm's interface [9]; Some have seen it has a much broader ruling—one that will have a chilling effect on development of competitive software products [5]; Others have asserted the case draws a reasonable line, and will have a positive effect overall [4]; Several have argued the ruling will be harmful because it ignores the interests of users of software, and will make standardization of user interfaces impossible to achieve. [3] Still others perceive the opinion as only setting the stage for a new confrontation over the issues in the appellate courts. [1] Lotus has given some indication of how broadly it interprets the Paperback decision by filing a new round of user interface copyright lawsuits against two of its other spreadsheet competitors.his column, rather than just adding one more interpretation of the Lotus decision to the bin of those already expressed, will give the reader a glimpse of the nature of the legal process and of judicial opinions so he or she can see why people can interpret the Lotus opinion differently. The following three factors make it difficult to know what the Lotus decision means: 1) The legal process is not yet over, and the meaning of the case will depend in part on the outcome of this further process. 2) While Judge Keeton makes some statements that seem to suggest his ruling is a narrow one, some of his other statements could be interpreted much more broadly. 3) Even from unambiguous statements Judge Keeton makes, different people can draw reasonable but nonetheless differing inferences about what the judge would do in similar (though somewhat different) cases. For these reasons, it is impossible to know with any certainty what the law concerning copyright protection for user interfaces is in the aftermath of the Lotus decision.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=92784&ftid=10659&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:10>},
}

@inproceedings{Krumova:2012:TTW:2463728.2463786,
  author =	 {Krumova, Milena},
  title =	 {Technologies, Tools and Web 2.0 in Support of Public
                  Administration Workplace Communications},
  booktitle =	 {Proceedings of the 6th International Conference on
                  Theory and Practice of Electronic Governance},
  series =	 {ICEGOV '12},
  year =	 2012,
  isbn =	 {978-1-4503-1200-4},
  location =	 {Albany, New York, USA},
  pages =	 {301--309},
  numpages =	 9,
  url =		 {http://doi.acm.org/10.1145/2463728.2463786},
  doi =		 {10.1145/2463728.2463786},
  acmid =	 2463786,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ICT, communications, public administration, web 2.0},
  abstract = 	 {The aim of this paper is to investigate which are the technologies, tools and web 2.0 applications that support public administration workplace communications. The paper begins with e-Administration and web 2.0 uses in the context of public administration 2.0. Then the attention is focused on workplace communications review and technologies, and tools, which influence their efficiency and effectiveness. For the purpose of detailing the used public administration technologies and tools, O*NET database is investigated in terms of the governance and public management and administration occupations. In order to determine, to what extent the identified technologies, tools and web 2.0 applications are used in practice, an empirical survey is developed and carried out in "Information services and technologies" Directorate at Sofia Municipality. The paper concludes with a proposed PA 2.0 workplace communications model.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2463786&ftid=1363847&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:14>},
}

@article{Thomas:2007:MKW:1297797.1297802,
  author =	 {Thomas, Dominic M. and Bostrom, Robert P. and Gouge,
                  Marianne},
  title =	 {Making Knowledge Work in Virtual Teams},
  journal =	 {Commun. ACM},
  issue_date =	 {November 2007},
  volume =	 50,
  number =	 11,
  month =	 nov,
  year =	 2007,
  issn =	 {0001-0782},
  pages =	 {85--90},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/1297797.1297802},
  doi =		 {10.1145/1297797.1297802},
  acmid =	 1297802,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {"I've been working in computers for years, and only the simplest stuff works 90\% of the time."---A virtual team leader reflecting on technology facilitation.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1297802&ftid=457912&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:19>},
}

@inproceedings{Ashworth:1992:SMA:1125021.1125032,
  author =	 {Ashworth, Catherine A.},
  title =	 {Specialized Methods Do Not Always Increase
                  Efficiency},
  booktitle =	 {Posters and Short Talks of the 1992 SIGCHI
                  Conference on Human Factors in Computing Systems},
  series =	 {CHI '92},
  year =	 1992,
  location =	 {Monterey, California},
  pages =	 {12--12},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1125021.1125032},
  doi =		 {10.1145/1125021.1125032},
  acmid =	 1125032,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The current research is a complex, 5 day, training experiment
investigating several questions about the learning and use of
software methods. Central issues concern the situation in which a
software user knows more than one obvious method for accomplishing
a task at hand. We call this situation "multiple methods". Multiple
methods seem to arise most often from the creation of commands or
functions specialized for a subclass of tasks. For example, in a
word processing application there are often several ways to move
the cursor, with arrow keys, by word, by line, by page, to end of
line, to start of line, to top of document, and to bottom, to name
some common methods. Designers and users typically assume that the
existence and use of multiple methods in an application increases
user efficiency. We tested that assumption directly. In this
experiment we investigated the effects of multiple methods during
learning and performance measuring task time, planning time, and
error rates and types. In addition, we also investigated strategies
subjects employed when choosing between their methods.

In a rigorous training regime using the spreadsheet software
Lotus 123, subjects learned one or two ways to move the cursor and
one or two ways to sum the contents in a section of cells. During
the 5 day experiment, subjects repeatedly moved the cursor to an
indicated location and entered a formula summing an adjacent group
of numbers. Cursor movements were of varying distances and sums
involved various numbers of addends.

On the first day, subjects were taught their method set which
they practiced to a criterion of 24 consecutive correct
repetitions. On days 2 and 3 (practice), subjects performed tasks
comprised of 128 repetitions of their method set. On every task,
the best method was assigned in the instructions and used by the
subjects. The best method was determined by constructing
theoretical keystroke models of the methods (see Olson &amp;amp;
Nilsen, 1988) and assigning the most rapid method. During practice,
the order in which the methods were used was counter-balanced.

On days 4 and 5 (testing), subjects performed 338 similar tasks
but selected the method themselves on every task. These 338 tasks
were comprised of thirteen different cursor task distances and
thirteen sizes of sums sampled thirteen times each. During both
practice and testing, subjects used the &amp;lt;enter&amp;gt; key
to toggle between task instructions and the spreadsheet on which
the tasks were performed. During a cursor task, the target cell was
not indicated until the subject removed the instruction screen
stating: "move the cursor to the target cell using the X method".
Similarly, during a summation task, the addends were apparent only
after the instruction screen was removed. This allowed partitioning
of the total task time into planning time and typing times.

During both practice and testing, and on both cursor and
summation tasks, subjects who knew two methods for a task made more
errors on that task type (matched tasks) only. That is, knowing two
sum methods increased the number of sum task errors, but did not
increase the number of cursor task errors. Similarly, knowing two
cursor movement methods increased the number of cursor task errors,
but not summation task errors. In addition, two method subjects
were no faster on matched tasks than were one method subjects,
despite their specialized methods. In fact, the two method subjects
had <u>longer</u> planning times on matched tasks than
did one method subjects. Once again, these effects of knowing two
methods were segregated to matched tasks.

It is interesting to compare the two groups of subjects that
each knew three methods as a way of controlling for effects of
workload imposed purely by the number of methods known. The
subjects with two cursor methods and one sum method (2-1 subjects)
were compared to those with one cursor method and two sum methods
(1-2 subjects). Consonant with the results above, 2-1 subjects made
more cursor task errors than did the 1-2 subjects who made more sum
task errors. Increases in planning time at the start of the task
followed this same pattern.

Although error rates were low and task time differences modest
---between 500 to 3000 msec---in a population of "real users" who
know more commands and do not undergo such rigorous practice the
differences are expected to be much larger. These results
contradict the common assumption that specialized methods for
subclasses of tasks increase a user's efficiency. In addition,
these results demonstrate the costs of multiple methods even in an
impoverished repertoire of only four commands.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1125032&ftid=353547&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:24>},
}

@proceedings{Levialdi:1998:948496,
  editor =	 {Catarci, Tiziana and Costabile, Maria Francesca and
                  Santucci, Giuseppe and Taranfino, Laura},
  title =	 {AVI '98: Proceedings of the Working Conference on
                  Advanced Visual Interfaces},
  year =	 1998,
  location =	 {L'Aquila, Italy},
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 14:10:27>},
}

@inproceedings{Nowak:2008:HPV:1391469.1391620,
  author =	 {Nowak, Matt and Corleto, Jose and Chun, Christopher
                  and Radojcic, Riko},
  title =	 {Holistic Pathfinding: Virtual Wireless Chip Design
                  for Advanced Technology and Design Exploration},
  booktitle =	 {Proceedings of the 45th Annual Design Automation
                  Conference},
  series =	 {DAC '08},
  year =	 2008,
  isbn =	 {978-1-60558-115-6},
  location =	 {Anaheim, California},
  pages =	 {593--593},
  numpages =	 1,
  url =		 {http://doi.acm.org/10.1145/1391469.1391620},
  doi =		 {10.1145/1391469.1391620},
  acmid =	 1391620,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {design exploration, design technology integration,
                  pathfinding},
  abstract = 	 {As CMOS technology is scaled beyond 45nm, SOC/SiP design for wireless chips is increasingly constrained by fundamental technology limits, resulting in challenges including parametric variability, leakage, active power, signal integrity, and diminished performance improvement. New materials and innovative device structures are needed to extend CMOS scaling and integrate disruptive "More than Moore" functionality, but these can have adverse impact on manufacturing cost and risk. Hence, tradeoff analysis spanning process, device, circuit, memory, package, architecture, software, and business disciplines is required during the advanced technology development cycle to explore and co-optimize technology and design choices. Such methodology, in conjunction with judicious use of test chips, also provides for a bridge from innovative technology solutions to mainstream product adoption. Several approaches are currently in use for ad-hoc exploration of advanced technology and design - typically based on spreadsheet analysis, guru consultation, and/or full trial designs. With the exploding complexity of the optimization space, subject matter knowledge and expert experience needs to be complemented with a structured methodology and tools. A "Holistic Pathfinding" methodology is proposed for addressing technology and design tradeoffs early in the development cycle to allow co-optimization all the way up to the system architecture level. A virtual design flow that allows rapid estimation of performance, power and cost attributes of a potential product, as a function of a given set of process or design assumptions is described as shown in Figure 1. Key target features of such a virtual flow and a summary of the attributes of several candidate point tools is presented. Requirements for the tools and methodologies to be used for Pathfinding across the span of disciplines are outlined. In order to enable system cost and performance/power analyses, the requirements for predictive models that describe variability, leakage, devices, interconnect, and DFM attributes are identified. Examples of Pathfinding application for co-optimization of memory technology and architecture, reduced parametric variability using restricted physical design rules, and exploration of 3D chip stacking are presented to highlight the requirements and gaps in the existing EDA tool solutions. The vision is for a design exploration platform that outputs performance, active and standby power, and cost estimates in reasonable response time, and with physical and variation awareness at the architectural level.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1391620&ftid=529216&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:33>},
}

@inproceedings{Wang:2002:SDM:513338.513377,
  author =	 {Wang, Weigang and Haake, Joerg M.},
  title =	 {Supporting Distributed Meetings Using Cooperative,
                  Visual, Process-enabled Hypermedia},
  booktitle =	 {Proceedings of the Thirteenth ACM Conference on
                  Hypertext and Hypermedia},
  series =	 {HYPERTEXT '02},
  year =	 2002,
  isbn =	 {1-58113-477-0},
  location =	 {College Park, Maryland, USA},
  pages =	 {147--148},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/513338.513377},
  doi =		 {10.1145/513338.513377},
  acmid =	 513377,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {This work tries to bring hypermedia out of our multiple research-oriented cooperative hypermedia systems into the kinds of systems people in the real world can use. Meeting support for distributed teams is one of these and process support is another. The practical challenges include how to develop a (whiteboard-like) structure-rich visual hypermedia space that is accessible from the Web, how to integrate Microsoft office applications into the system for managing documents in a (visual hypermedia represented) meeting process, and how to set up A/V and application sharing connections easily for all the meeting participants. The system described in this paper has been used in three use cases and initial feedback indicates that it has successfully addressed several such practical challenges.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=513377&ftid=71473&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:40>},
}

@inproceedings{Liebrock:2005:ESA:1095242.1095257,
  author =	 {Liebrock, Lorie M.},
  title =	 {Empirical Sensitivity Analysis for Computational
                  Procedures},
  booktitle =	 {Proceedings of the 2005 Conference on Diversity in
                  Computing},
  series =	 {TAPIA '05},
  year =	 2005,
  isbn =	 {1-59593-257-7},
  location =	 {Albuquerque, New Mexico, USA},
  pages =	 {32--35},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/1095242.1095257},
  doi =		 {10.1145/1095242.1095257},
  acmid =	 1095257,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {computational sensitivity analysis, stability
                  analysis},
  abstract = 	 {Sensitivity analysis in computer science aims to improve stability in computer applications by considering uncertainty due to small perturbations in parameters. Mathematical and computational methods of sensitivity analysis are discussed. Advantages and disadvantages of both methods are addressed. A tool is developed to compute computational sensitivities. This tool was validated using three simple, well understood problems. The tool was then applied to a dynamic power grid system and an agent-based criminal computation. In the case of the power grid system, computational sensitivity analysis agrees with mathematical analysis in reporting stability and no excessive sensitivity. In the case of the criminal computation, the code is found to be unstable.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1095257&ftid=332136&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:45>},
}

@inproceedings{Gush:2010:AUU:1899503.1899514,
  author =	 {Gush, Kim and de Villiers, Ruth},
  title =	 {Application Usage of Unsupervised Digital Doorway
                  Computer Kiosks in Remote Locations in South Africa},
  booktitle =	 {Proceedings of the 2010 Annual Research Conference
                  of the South African Institute of Computer
                  Scientists and Information Technologists},
  series =	 {SAICSIT '10},
  year =	 2010,
  isbn =	 {978-1-60558-950-3},
  location =	 {Bela Bela, South Africa},
  pages =	 {93--103},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/1899503.1899514},
  doi =		 {10.1145/1899503.1899514},
  acmid =	 1899514,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  keywords =	 {ICT for development, ICT in education, community
                  informatics, computer literacy, digital doorway,
                  unassisted learning},
  abstract = 	 {Digital Doorways are rugged computer terminals that offer unassisted learning and peer-assisted learning of basic computer skills, as well as a range of computing activities from entertainment, through education, to independent research. Sites are located in impoverished areas of South Africa at schools, colleges and public community facilities. Usage is free of charge and available to the entire community. This paper poses research questions relating to application usage data and how it relates to user demographics, in order to better understand both the user base and the nature and extent of interaction with a selected set of terminals. This study thus addresses significant issues with respect to ICT for Education and Development in the Digital Doorway context. Analysis of the data indicates notable trends and patterns, and raises certain concerns.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=1899514&ftid=870534&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:52>},
}

@article{Myers:1994:CHD:174800.174808,
  author =	 {Myers, Brad},
  title =	 {Challenges of HCI Design and Implementation},
  journal =	 {interactions},
  issue_date =	 {Jan. 1994},
  volume =	 1,
  number =	 1,
  month =	 jan,
  year =	 1994,
  issn =	 {1072-5520},
  pages =	 {73--83},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/174800.174808},
  doi =		 {10.1145/174800.174808},
  acmid =	 174808,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=174808&ftid=41495&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:10:56>},
}

@inproceedings{Downing:1985:ACS:318741.318743,
  author =	 {Downing, Linda and Jacobson, Ellen and Chambers,
                  Doug},
  title =	 {The ABC's of Customer Support Academic and Business
                  Aspects of Customer Support: A Perspective on
                  Marketing Our Services},
  booktitle =	 {Proceedings of the 13th Annual ACM SIGUCCS
                  Conference on User Services: Pulling It All
                  Together},
  series =	 {SIGUCCS '85},
  year =	 1985,
  isbn =	 {0-89791-167-9},
  location =	 {Toledo, Ohio, USA},
  pages =	 {9--12},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/318741.318743},
  doi =		 {10.1145/318741.318743},
  acmid =	 318743,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {“Are we doing what we ought to be doing for our users?” “Are we in fact providing services for the campus and other service communities that we think we should be providing?” “Are we serving the people we should be serving?” “Is User Services dying or just beginning?”
User Services staffs all too often are faced with hard choices about which services to support, or which users to assist. We are expected to address user needs in a timely and effective manner. In many instances we do, but at a high internal cost to the User Services staff or in a lower quality service to the user. There must be some steps found to decrease the internal costs and increase the quality of the services provided. Possibly, if User Services could change its role from one of a “reactionary” force to one of providing direction, and support for that direction, much of the “frenzy” within User Services could be removed along with providing a stabilizing affect on the user community. By applying basic marketing principles to the User Services environment, the appropriate service needs can be delineated, costed and provided.
The profile of a general user base (or user community) may be categorized as follows:

need for tools required to accomplish tasks, geared toward specific support for teaching, specialized research, and administrative functions (growing, but mature in scope),
need for education and training support (changing as computer literacy increases and computing resources become more available), and
resource information for hardware, software, or systems acquisitions (infancy/growing).

User Services staffs can adapt functions of strategic planning from marketing techniques in the development of new products and/or services for their user community. By using these functions and thereby developing a marketing stance for support of hardware, software and services, User Services can become proactive on their campus. They will be able to take the lead in decisions concerning hardware selections, supported software packages and work with users to develop time tables as to when new services will be made available. For many the idea of “leading” rather than “following” may be something only dreamed of while on vacation. The functions that should be considered in the development or re-evaluation of services are:

a generic concept definition,
segmentation,
market research,
product development,
pricing (costing) decisions,
distribution,
and communication.

A critical look at the needs of most users, will disclose that those needs are not discipline-dependent. Rather they are a function of certain applications of relatively GENERIC CONCEPTS to a specific discipline. For example, a spreadsheet in an integrated software package may be appropriately used as an analysis tool for agricultural applications as it may be for business researchers or engineers. By approaching the assessment of user needs from the perspective of generic solutions to generic problems, a service can be provided with less associated costs to a much larger part of the user community.
The difference between providing quality instead of marginally adequate user support lies in the ability to differentiate the various market segments within the total user community. Those of us in User Services have long referred to the market segment as subgroups within our total user community. This SEGMENTATION requires that the limited resources available to the organization be focused upon those segments where need and responsiveness are likely to be the greatest, thus maximizing the service provided. We are in a unique position to match available products and services with those subgroups in the user community who have a potential need for such services. For example, evaluating a new integrated software package for the institution could potentially involve users from several subgroups across many disciplines. They may have use for one or more tools available in the product, and by evaluating the effectiveness of serving their needs, a better determination could be made about the viability of supporting such a product. The same rationale holds for hardware and hardware/software acquisition issues. The User Services staff is more able to act as facilitators for such matches than virtually any other organization within an institution. There is such a large void on most campuses in providing this leadership that if User Services were to step into the void they could provide almost campus wide direction.
To identify those market segments, traditional MARKETING RESEARCH (needs analysis) techniques can be used. These techniques allow User Services staff to define the problem and objectives, develop the information sources, collect and analyze the information, and present the findings. A part of the market research process may include the decision to demarket an existing product and/or service to meet the growing demand for new services and products. Market research also continues into the post-implementation phase to assess and review decisions, products and services to gain insight on how to better package future efforts. Too often, once the final implementation is complete, we fail to go back and critically review the task, especially from the standpoint of the user, to figure out what could be done better the next time. We get too busy solving the next crisis to adequately assess the post-implementation attitudes of the users. We often rely on the one-to-one channels of communication rather than the formal ones within the organization to get an overall feedback. Also, politics of the organization may counter any realistic analysis as well.
After the generic need has been defined, PRODUCT DEVELOPMENT can be established. For every product there needs to be a “bridge” provided with either documentation, training or support. The “bridge” that User Services provides may be large or small depending upon what vendors provide. This “bridge” compliments what the vendor provides to supply a complete support system to allow the user to function, as our goal always has been, more independently. The “bridge” can be documentation in the form of an “instant” or “mini” guide, an introductory training seminar, or any other technique to get the user functioning with the resources provided by the vendor. We all prepare and deliver “bridges”. In some cases, we redevelop ones available at other institutions. Documentation, training, support, and staffing issues must be solved and in place before the product is announced to the user community. This planning, implementation and support is critical to the successful adoption of the product by the users.
The PLACE and level of service provided by the staff must be addressed. Many institutions are grappling with maintaining a balance of centralized and/or decentralized support. Concurrently, many departments or units are hiring their own support staff with whom we are expected to compliment support efforts and training. Maintaining a constant level of quality support in such situations is challenging at best. Part of the solution may be to develop the role of a facilitator for User Services within a department to provide discipline specific support for the department. For example, an accountant faculty member is better able to demonstrate how a spreadsheet can be incorporated into a basic accounting class to another faculty member.
Whether or not User Services groups charge for their products or services, PRICING DECISIONS need to be a part of the planning process. What are the costs to User Services? What are the costs to the user community? Both real and implied costs must be included. Too often only the real or obvious costs are looked at, not what the trade-offs or hidden costs are going to be. Also, to be considered is the cost of saying “NO” or not providing the product, hardware or service. After all the costs have been determined and weighted, the decision can be made whether or not to provide the product, hardware or service. These cost determinations are usually never considered by User Services when the group is “reactive” or “following” in nature. They are the “tail” being wagged by the campus “dog”. In most cases the pricing or cost decisions have been made by some user subgroup, not the whole user community, so for one subgroup the entire user community “pays” by the rearranging of priorities of User Services staff. The goal must be to match the hardware, software, and service provided to solve the user's needs in the most cost effective manner for all concerned.
If product development continues, the DISTRIBUTION mechanisms must be considered next. A target population could be selected to participate in a pilot project. This allows the testing of the various elements of the product by users who can commit to testing and help refine the product offering before introducing it to the total user community. If all goes well, the participants in the pilot project will then in turn market the product through word of mouth within the user community. With or without a pilot project, formalization of the mechanisms for distributing training and documentation must be established, and a formal plan to promote the product and services needs to be implemented. Part of the distribution mechanism might include the decentralized support staff or knowledgeable users in the different departments.
How to disseminate information, as well as what is to be provided to whom, can be delineated to the user community through PROMOTION. A proactive effort is needed to effectively and efficiently determine what to say, how to say it, who to say it to, and why. This involves defining the services and making sure the user community knows what they are, where they can get them and at what cost. Not only advertising training sessions, documentation and support levels, but getting involved around the campus and posing the new product as a solution to perceived needs; inserting it into the user community not just letting the user come to you out of curiosity.
Funnelling our efforts into assessment of user behavior and subsequent evaluation of post-support attitudes allows us to be proactive in our user support, and provide a healthy marketing/business approach to the services provided. Such an effort will ensure that User Services staffs will continue to provide products and services which are supported and needed by the user community. As such we will be one team, our users and us. With these marketing tools you have another means of pulling it all together, providing information to consider the new roles, new services, new products, and new strategies for providing User Services growth for the 80's and beyond.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318743&ftid=15794&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:03>},
}

@article{Gray:1998:MLM:274946.274957,
  author =	 {Gray, David N. and Hotchkiss, John and LaForge, Seth
                  and Shalit, Andrew and Weinberg, Toby},
  title =	 {Modern Languages and Microsoft's Component Object
                  Model},
  journal =	 {Commun. ACM},
  issue_date =	 {May 1998},
  volume =	 41,
  number =	 5,
  month =	 may,
  year =	 1998,
  issn =	 {0001-0782},
  pages =	 {55--65},
  numpages =	 11,
  url =		 {http://doi.acm.org/10.1145/274946.274957},
  doi =		 {10.1145/274946.274957},
  acmid =	 274957,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=274957&ftid=39795&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:10>},
}

@article{Behrens:1998:PLA:269012.269017,
  author =	 {Behrens, Brian C. and Levary, Reuven R.},
  title =	 {Practical Legal Aspects of Software Reverse
                  Engineering},
  journal =	 {Commun. ACM},
  issue_date =	 {Feb. 1998},
  volume =	 41,
  number =	 2,
  month =	 feb,
  year =	 1998,
  issn =	 {0001-0782},
  pages =	 {27--29},
  numpages =	 3,
  url =		 {http://doi.acm.org/10.1145/269012.269017},
  doi =		 {10.1145/269012.269017},
  acmid =	 269017,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=269017&ftid=40907&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:19>},
}

@article{MacKnight:1989:ETM:67933.67940,
  author =	 {MacKnight, Carol B. and Balagopalan, Santosh},
  title =	 {An Evaluation Tool for Measuring Authoring System
                  Performance},
  journal =	 {Commun. ACM},
  issue_date =	 {Oct. 1989},
  volume =	 32,
  number =	 10,
  month =	 oct,
  year =	 1989,
  issn =	 {0001-0782},
  pages =	 {1231--1236},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/67933.67940},
  doi =		 {10.1145/67933.67940},
  acmid =	 67940,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {A model for producing objective and precise measurements of the power and performance of authoring systems is described. An animation task is given as an example of the model's potential as a tool for evaluating authoring systems along the dimensions of functionality, flexibility, and productivity.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=67940&ftid=5269&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:24>},
}

@inproceedings{Harold:1988:TCC:57216.57243,
  author =	 {Harold, F. G.},
  title =	 {The Two Cultures in Computing},
  booktitle =	 {Proceedings of the ACM SIGCPR Conference on
                  Management of Information Systems Personnel},
  series =	 {SIGCPR '88},
  year =	 1988,
  isbn =	 {0-89791-262-4},
  location =	 {College park, Maryland, USA},
  pages =	 {188--191},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/57216.57243},
  doi =		 {10.1145/57216.57243},
  acmid =	 57243,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In 1956 the distinguished British scientist, novelist, essayist, and statesman C. P. Snow published a three-page observation titled “The Two Cultures” [Snow 1956], describing the distressing lack of communication between two of society's most gifted groups: scientific and literary intellectuals. This brief essay stimulated considerable comment, which led Snow to publish subsequent discussions of the same general theme [Snow 1959; Snow 1963].
The computing industry was barely established in 1956; in the ensuing thirty years it has become a major force in society. It has, in fact, generated many commentaries on the unique nature of the professionals engaged in its many dimensions. Specialties within computing today are as diverse as those in the medical profession.
Despite the many varieties of concentration within computing, two are most commonly represented in academic curricula (and in the ranks of practitioners as well): computer scientists and information systems specialists. Whether these professionals are designated systems programmers and systems analysts or software engineers and applications programmers, there is a significant distinction between their backgrounds, outlooks, and temperaments. In some instances the separation between these two groups is minimal; in others, it is considerable, and perhaps growing. There is justification (with apologies to the late Lord Snow (1905-1980) for adopting and somewhat modifying his model) for suggesting that two cultures exist even within the circumscribed arena of computing, and that the differing orientations of these two groups cause real problems for the larger profession.
The establishment of a profession requires, among other things, the acceptance of a common body of knowledge. This exists, although in fledgling fashion, in computer science (CS) today. The Computing Sciences Accreditation Board (CSAB) is in place, and as of June 1987 had accredited 48 university curricula in the U.S. Draft standards for the accreditation of information systems (IS) curricula have been developed. Leading professional societies, including ACM, DPMA, and the IEEE Computer Society, have participated in the recommendation of criteria for academic programs in one or both of these areas. CS emphasis is placed upon theoretical and mathematical foundations of computing, while IS concentration focuses on pragmatic applications and business uses of computers. Each of these sub-disciplines has little use for the other. Computer scientists denigrate the inelegant nature of the typical COBOL or spreadsheet business application, while information systems specialists decry the inability of the computer scientist to communicate effective1y with users. The polarization between these two groups varies, but each typically views the other with suspicion and distrust.
This paper discusses the differing characteristics of these two groups, highlights the research which has identified these traits, and proposes a model for reintegration of their concerns under the heading of software engineering. C. P. Snow's work elaborating on his initial description of the Two Cultures is used as a framework for the discussion. The paper concludes with guidelines for the management of these two groups of professionals.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=57243&ftid=9186&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:55>},
}

@article{Scheifler:1986:XWS:22949.24053,
  author =	 {Scheifler, Robert W. and Gettys, Jim},
  title =	 {The X Window System},
  journal =	 {ACM Trans. Graph.},
  issue_date =	 {April 1986},
  volume =	 5,
  number =	 2,
  month =	 apr,
  year =	 1986,
  issn =	 {0730-0301},
  pages =	 {79--109},
  numpages =	 31,
  url =		 {http://doi.acm.org/10.1145/22949.24053},
  doi =		 {10.1145/22949.24053},
  acmid =	 24053,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An overview of the X Window System is presented, focusing on the system substrate and the low-level facilities provided to build applications and to manage the desktop. The system provides high-performance, high-level, device-independent graphics. A hierarchy of resizable, overlapping windows allows a wide variety of application and user interfaces to be built easily. Network-transparent access to the display provides an important degree of functional separation, without significantly affecting performance, which is crucial to building applications for a distributed environment. To a reasonable extent, desktop management can be custom-tailored to individual environments, without modifying the base system and typically without affecting applications.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=24053&ftid=41741&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:11:59>},
}

@proceedings{Mattern:2013:2493432,
  title =	 {UbiComp '13: Proceedings of the 2013 ACM
                  International Joint Conference on Pervasive and
                  Ubiquitous Computing},
  year =	 2013,
  isbn =	 {978-1-4503-1770-2},
  location =	 {Zurich, Switzerland},
  note =	 608139,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 14:12:00>},
}

@article{Minsky:2011:OM:2018396.2018413,
  author =	 {Minsky, Yaron},
  title =	 {OCaml for the Masses},
  journal =	 {Commun. ACM},
  issue_date =	 {November 2011},
  volume =	 54,
  number =	 11,
  month =	 nov,
  year =	 2011,
  issn =	 {0001-0782},
  pages =	 {53--58},
  numpages =	 6,
  url =		 {http://doi.acm.org/10.1145/2018396.2018413},
  doi =		 {10.1145/2018396.2018413},
  acmid =	 2018413,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Why the next language you learn should be functional.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=2018413&ftid=1047643&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:03>},
}

@inproceedings{Westmoreland:1985:MF:318741.318757,
  author =	 {Westmoreland, James H.},
  title =	 {Microcomputers for Faculty},
  booktitle =	 {Proceedings of the 13th Annual ACM SIGUCCS
                  Conference on User Services: Pulling It All
                  Together},
  series =	 {SIGUCCS '85},
  year =	 1985,
  isbn =	 {0-89791-167-9},
  location =	 {Toledo, Ohio, USA},
  pages =	 {97--101},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/318741.318757},
  doi =		 {10.1145/318741.318757},
  acmid =	 318757,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In August 1983, President Arliss L. Roaden of Tennessee Technological University appointed a task force to explore ways and means of making personal computers available to members of the faculty. The task force was not constrained in any way. It had to keep in mind the limitations of regulations but was not bound by financial constraints since it was exploring all possibilities.
There were several items taken into consideration. At the time that Tennessee Tech began to consider acquiring microcomputers for faculty, the faculty consisted of several distinct groups of computer users. There were those who used the VAX computers in teaching and research, there were some who used a microcomputer, there were some who were not users, and of those there were some who did not want to be computer users. Another consideration was the common applications of computers that might be made by the faculty. All faculty do some type of word processing and all keep a grade book. Some faculty are involved in other activities that might make use of a microcomputer, such as grant budgeting and data collection and analysis for research.
Another consideration was that of compatibility. The university computer center had two Digital Equipment Corporation VAX 11/780 computer systems installed for administration, academic and research applications. This fact had to be of concern when considering file transfer between the main facility and the microcomputers that the faculty might have.
Of course, a major concern was that of cost. It did not matter to the task force how the funding was to be handled. It felt that cost had to be held as low as possible and still get the type machine that would be a good system for the academic environment. So the task force felt that we had to have vendor participation in the project to get as good a discount as possible. Several methods of funding were considered, including a joint purchase by the faculty member and the university. Ownership was a major issue since Tennessee Tech is a state agency.
For proper utilization, it was felt that a good training program must be provided and that each person receiving a microcomputer must participate in the training. Even those who are computer users may not know anything about microcomputers, so they should go through the training also.
Maintenance was of concern, not only for the warranty period, but for the future. A long warranty period, a year, if possible, was important and the university would take over the maintenance responsibility after the warranty period.
The need to exchange files among the faculty, the access to letter quality printers, a common training program, maintenance support, and the need to present a unified front to the vendor, presented a need for standardization across the campus. There were approximately forty microcomputers of various brands scattered across the campus already. There is a need to have a specific machine for a specific use, but the general use systems should be standardized.
The task force felt that the faculty would need continued support after the initial training period. Their needs will expand as they become more knowledgeable users. They will also want to expand their own applications and the incorporation of the microcomputers into the curriculum is expected. The university will benefit in many ways by providing the faculty with a microcomputer and providing training and support in its use. The total campus could become more productive, the computer knowledge base would be expanded, and the faculty would be better prepared to introduce the computer and its applications into the classroom.
The task force recommended that:

The university provide microcomputers for faculty use
A training program be provided
Some machines be made available for faculty and staff to purchase at cost
Vendors be contacted to explore their interest in participating in the program by providing the machines at a minimum cost to the university.

A plan was developed “to provide a computer to each faculty member who wishes to have one and who can make effective use of the equipment.” Faculty members submitted a request to their department chairpersons. The deans and the provost established the priority list of faculty to receive a machine. The computer center had the responsibility of ordering the hardware and software, developing a training course, teaching the course, distributing the systems, providing continuing support, and providing hardware maintenance after the warranty period.
The Computer Resources Committee, which is responsible for the monitoring of computing needs at the university and planning for and recommending the implementation of changes in computing activities necessary to meet the needs of the university, endorsed the recommended plan. It felt that with the adoption of such a plan, that any department wishing to purchase equipment outside the plan would have to show justification for that deviation. The Tennessee State Board of Regents, Tennessee Tech's controlling body, approved the plan.
An agreement was reached with Digital Equipment Corporation for the purchase of 300 or more Rainbow 100 microcomputer systems. The computer center and DEC held two three-hour sessions for the faculty where information about the project and the systems was provided and the Rainbow 100 and the DECmate II were demonstrated running several application packages. Over 200 faculty attended these sessions.
The Rainbow 100 system with 256 Kbytes of memory, graphics option, LA50 printer, Multiplan, and WordStar was selected as the system to be purchased. The system has both the Zilog 8-bit Z80A and the Intel 16-bit 8088 processors and dual 400 Kbytes removable floppy disk storage. It has a serial printer port and an asynchronous RS232 communications port. The Rainbow will run both CP/M-86/80 and MS-DOS operating systems.
It is critical that training be done as effectively as possible when already busy faculty are involved. It becomes very important their encounter with a computer be pleasant because for some of the faculty it is their first experience with a computer of any kind. The stated purpose of the training was to “develop computing skills to be able to use the computer as a tool.” Ms. Charlotte Middlebrooks, Academic Support Manager, developed the course, wrote the tutorials, and taught the initial classes.
The course consists of 2 hours per day for 9 days. Initially faculty of equivalent backgrounds were grouped together. This worked fine for a few classes, but schedules made it necessary to take whoever was available at the time. Each person has a machine to use in class. In some cases it is the same computer that becomes theirs when the class is over. The instructor covers the major concepts and provides as much individual attention as possible. The course is completed hands-on with each faculty member working through a tutorial containing exercises and step by step instructions to complete the problems. Several students, who have been trained in microcomputer applications, assist with the classes and provide help with individual problems that occur in a hands-on class.
As expected, several faculty resisted the classes, but the President made class attendance a prerequisite for acquiring a microcomputer. After a couple of classes, the word got around the campus that the classes were well done and very useful. Soon we got requests to allow wives, husbands, and secretaries to attend the classes. An attempt is made to hold the class size to 15 and extra people are not allowed to attend. Classes for administrative staff and clerical staff are held periodically. Everyone who attends the class is requested to fill out an evaluation and send it back by campus mail and the responses are consistently very good. Even those who said that they were intimidated by computers have responded very positively and are very appreciative of the training.
One day of class is spent on hardware. On the first day, class participants assemble a machine. This means that they take it out of the boxes, put in all options, attach the cables, and turn it on. Even President Roaden attended the course and assembled his own machine. They also run diagnostics later in the course. The operating system, CP/M, is covered as part of the applications. MS-DOS is not covered in this initial training.
WordStar is covered in the first 3 days. It is easy to get started and early success is an important concept in the training. WordStar is taught as a tool for writing, creating, modifying, and merging documents. The primary features of Multiplan are covered in three days. Grade book and budget examples are used to demonstrate its usefulness. Many faculty did not know about electronic spreadsheets and did not see how they could use them until they worked the examples. The integration of the WordStar and Multiplan packages to produce reports is covered.
The VAX-Rainbow connection is discussed. Both Kermit and poly-Com by Polygon are used as example communication packages. One of our next big projects is to develop a local area network to connect all the Rainbows with the VAX systems.
It would be very unusual to undertake such a project without additional personnel and not have problems — and there were problems. Many faculty and administrators wanted to order additional options and/or wanted a slightly different configuration. DEC treats Tennessee Tech as one customer as you might expect, but funds were coming out of pockets from everywhere on campus. So the invoices had to be broken into pieces to charge each department appropriately. DEC is as one vendor, but they have several methods for filling orders. There were some misshipments and misbillings and these had to be handled.
The computer center did not have a training facility nor a space to establish such a facility. Since the facility had to be open during the day and the machines had to stay set up, dedicated room was necessary. A room was borrowed and that room is still in active use for teaching and working with microcomputers. Storage space for two hundred Rainbows was not available in the computer center. All the Rainbows with associated options came in approximately 6,000 boxes. The computer center had to receive, store, keep secure, issue, and account for each box.
Ownership of the equipment had to be accounted for and the university's established equipment tracking system had to be followed. Dealing with purchases for every department on campus and accounting for those purchases is more difficult than just dealing with your own department. Some of the equipment was purchased with departmental funds and some with university provided funds which were passed through the accounting system to account for the inventory of the equipment.
The computer center provides training on the Rainbow 100 as stated above. DEC provided training to the secretaries getting the DECmate II. The computer center continues to provide support through individual consultation or group sessions. We have hired a Microcomputer Specialist to provide this service and to teach the classes. We are taking on the responsibility of hardware maintenance with backup being provided by DEC.
The faculty and staff have responded in a very positive manner to this project. The faculty's morale has been very high. The computer center staff has trained almost 300 faculty and approximately 150 administrative and clerical staff. As of June 1, 1985, there are 388 Rainbow 100's, 35 DECmate II's, 2 DECmate III's, and 2 PRO350's on campus.
Two laboratory areas have been established outside the computer center for student use. The College of Business Administration has installed 15 Rainbows in a laboratory where 12 Apples were already being used. They have integrated the use of the Rainbow in almost every course offered in the college. Ten Rainbows have been installed in Library Media Center for student use.
The project of providing microcomputers to faculty has been very successful, with positive response from the participants. Additional computing has continued to be provided in the computer center at the same time with the addition of a VAX 11/785 and a VAX 11/750. A plan is being developed to provide a local area network with the VAX systems as the hub and the Rainbow 100's and Decmates as intelligent workstations which are located all over the campus. The continued integration of the computer into the curriculum is a must.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=318757&ftid=13575&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:07>},
}

@inproceedings{RuizLittle:1990:EGS:99186.99258,
  author =	 {Ruiz Little, Grace},
  title =	 {Establishing a Graphics Standard},
  booktitle =	 {Proceedings of the 18th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '90},
  year =	 1990,
  isbn =	 {0-89791-406-6},
  location =	 {Cincinnati, Ohio, USA},
  pages =	 {331--334},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/99186.99258},
  doi =		 {10.1145/99186.99258},
  acmid =	 99258,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {In 1987, Old Dominion University began its “Office Support” initiative. Though the crux of its efforts was to spread microcomputers and LANs throughout the administrative campus (student labs had already been taken care of), a vital component involved software. The realization that more access to equipment could lead to requested support for a wider variety of application software was frightening. Computing Services could not possibly support all the software available in the market and do it right. For this reason, the decision was made to establish standards and to rely upon the standards previously established for the public labs: WordPerfect, Lotus 123, and dBASE III+. Again, these were only standards; the customers could purchase any word processing, spreadsheet, or database package they wanted. And if they had problems Computer Services would try to help, but the degree of expertise would not be as high, nor would site licensing be sought, or short courses offered, on anything but the standard products. Standards could be changed of course, and application areas could be added.
By late 1988, our customers began to request graphics support. Computer Services decided to evaluate the market and establish a standard before people began to purchase their own preferences, and decided to concentrate on presentation graphics. There were other areas of interest, particularly CAD and animation, but these were more department specific. Presentation graphics could be used by any department.
A key element to the success of this project would be that the users be able to do the work in their own offices. This meant that our solution had to work on their current environment (the University is mostly DOS- based) and that it could not be cost prohibitive. The more costly aspects of graphics are the output devices. To meet this need, a centrally located Resource Center would be established. People whose departments could not justify the expense of a color printer, a film recorder, or a postscript (black and white) printer could use the equipment at the Central Facility with supplies being their only cost. Another requirement was that the product be compatible with the word processing/desktop publishing packages. Though Computer Services had not yet chosen a standard for desktop publishing, PageMaker, Ventura Publisher, and WordPerfect were all used widely enough to require consideration for graphic interface support.
Several of the industry-standard magazines and periodicals were reviewed and what seemed to be the top three software packages were chosen for evaluation: in the order in which they were rated by the NCGA shootout, these were Zenographics' Pixie, Ashton Tate's Draw Applause, and Software Publishing Corporation's Harvard Graphics. Harvard Graphics had been the number one choice for the previous two years, so the fact that it had dropped to third place aroused curiosity. Additional equipment is also needed for presentation graphics and a film recorder and a printer were suggested as a beginning. Also, since the final output is extremely important in this area, the project team (of two) agreed to do the work on low level computers (8088 and slow '286) so that the money could be used to buy the best output devices funding would allow. For the evaluation, funding for the three software packages, a film recorder, and a color printer was requested and received.
The film recorder purchased was the Matrix PCR. Without exception, every article we read rated it well over the others in quality. Though it was quite a bit more expensive than the others, it was considered a University resource instead of a departmental one, and deemed cost justified. The printer issue was more difficult. There was no clear- cut choice among the reviewers and there were no local vendors to visit for evaluation purposes. Graphics was not big in our area at that time; it still isn't. A few phone calls were made to the D.C. area to investigate what those heavily into graphics were using. The choice was narrowed down to the Tektronix 4693D and the CalComp Plotmaster. Though the quality of the Tektronix was preferred, the Plotmaster was chosen. The output was good, and the price, at a 40\% educational discount if purchased directly from Calcomp, was the deciding factor.
Once the installation was over, the PCR was a dream. The colors and resolution were great, and, once set up, the program which allowed batch use of the system was easy to use. Since the PCR was consistently the top-rated film recorder, any package that supports output to a film recorder seems to support the Matrix (PCR). Printed output was not as easy. Though the advertisements claimed that the Plotmaster worked with Harvard Graphics, Ashton Tate, and Zenographics products, it did not work with Draw Applause or Pixie, the new kids on the block. (The claim was not false; the Plotmaster was supported by other products in the Zenographics and Ashton Tate line of graphics. We had simply made an incorrect assumption.)
Evaluation of the software was more involved. The project team realized that the best way to evaluate the products was not by following the “training” section of the manuals, but by finding a “real, live application” for it. Not one, but three presentations were due within three weeks of the arrival of the equipment, so software evaluation commenced quickly. Pressed for time, Pixie was used almost exclusively after the first few days. It was found to be the easiest to learn and use. Draw Applause was used to get a few special effects slides such as rotating text.
After this project, the concern arose that perhaps the time element had had too much of an impact on the decision. After all, each package had its strengths - something the others could not do. The project of producing the University's “Statistical Profile” manual was then undertaken. Previously, this annual document had relied on graphic output from Lotus 123, so there was little concern about being able to improve it.
From this project the choice of Pixie as the University standard was confirmed. It was the easiest to use, and it would easily perform all the tasks required to do the project. Draw Applause, though great for special effects, was deemed too complicated for the average chart, and definitely for the average user. And Harvard Graphics was too frustrating. It sometimes seemed that it could do nothing right. It could do 3D pies, and explode a slice, but it could not do both; i.e., it could not explode a 3D slice. It supported the Plotmaster, but only 7 of the 264 colors. Labels were limited to 12 characters. To make them longer, one had to go into Draw/Annotate which is not the simplest of processes.
Further research showed that another plus for Pixie was the Zenographics family of products. Pixie files could be directly imported to Mirage, which is a highly-rated professional product widely used by graphic artists. Mirage has been called the “lear jet” of graphics packages and is often used in evaluating and comparing output devices. With Mirage to do the special effects, Draw Applause was no longer needed. Mirage was found to be heavily used in the D.C. area and meetings were set up. The meetings with World Bank, USGS (U.S. Geological Services), and the Department of Energy were very helpful. We visited the graphics departments and were surprised that they all used DOS machines and Zenographics software. We asked each “Why not Macs or mainframe?” and each responded the same: mainframe output devices were not as good, and the Macintosh did not yet have good color output support.
One of the Pixie/Mirage benefits was that customers could create relatively fancy slides themselves with Pixie, yet if they wanted something even fancier, they could take their files to the graphic arts department where the professionals could add artistic embellishments with Mirage. This would be of benefit to both parties; the users would be getting what they wanted, and the graphic artists would spend less time with the more “mundane” aspects of the design.
Finally, Zenographics Metafile, (since then upgraded and renamed ImPort) a program which converts a variety of graphic formats to a format that can be used in Mirage, was deemed essential. With this product, images from SAS, Harvard Graphics, and many other packages, (even from software in non-DOS environments) have been brought into Mirage. Thus, enhancements and output services can still be provided to users with software other than the chosen standard.
The next step was marketing. Of great help to this project and particularly in this area, was the Associate Vice President for Computing and Communication Services. Not only did he make a commitment to find funding for the project, but during his meetings with faculty, staff, and administrators, Mr. Hamage briefed them on the current research project and either brought them by, or encouraged them to give us a call. Most of the time, we spent approximately 15 minutes teaching them Pixie and then let them create their own charts. On a few occasions, we created the entire presentations for them - usually these were for presentation to the ODU Board of Visitors. Finally, the time came to announce the standard to the University. A special presentation was prepared which used four concurrent slide projectors synchronized with a programmer (graciously loaned to the University by Norfolk and Southern Corporation) and background music. This show was presented first to the Vice Presidents and later to the Deans. They were quite pleased with the capabilities they saw as well as with the offerings of the program (the site license price and output capabilities with supplies as their only cost). Next, we ran an article on Pixie in our monthly bulletin and another about the Zenographics grant and site license in the newsletter, both to publicize the availability of the product.
The research continues. Recently a GPIB board replaced the MVP Star board (which comes from Matrix) for output to the PCR. The color is much richer: though the PCR is capable of 16 million colors, the MVP Star board is limited to 256 colors per file. Though more than 256 colors per image might seem excessive, the need becomes clear when comparing shaded (gradated) backgrounds or using bitmapped images with fleshtones. Additional equipment has been purchased, a color scanner, a targa board, and a high resolution monitor. These have allowed us to include color scanned (bitmapped) images as part of our graphics. Output to a VCR through Mirage using the targa board is the current project.
In summary, our recommendation for developing a graphics standard is as follows. First, realize the need for a standard (or, if you are fortunate enough to have enough staff for adequate support, standards). Next, based on hearsay and magazine evaluations, choose your top three or four favorite software packages. Then, play with the packages following their “tutorials,” but realize that the purpose of this is more to get acquainted with using the package than for a true evaluation/comparison. The next step is the evaluation. Find a true need for graphics in your school, and volunteer to take on the assignment. This is when the true strength of the package comes out - it is not how many things a package can do, but how well it can do them. Remember to look at types of charts, black and white as well as color capabilities, fonts, ease of learning, ease of use, compatibility with other software (both for importing and exporting purposes), and output support. And finally, market your decision. Use newsletter articles, short seminars, meetings with individuals or departments, and presentations. And remember that from now on, whenever possible, your presentations should take advantage of graphics.},
  review = 	 {fbie: rejected <2016-01-15 14:12:12>},
}

@article{ComputerScienceandTechnologyBoard:1990:SUR:77481.77482,
  author =	 {Computer Science and Technology Board, CORPORATE},
  title =	 {Scaling Up: A Research Agenda for Software
                  Engineering},
  journal =	 {Commun. ACM},
  issue_date =	 {March 1990},
  volume =	 33,
  number =	 3,
  month =	 mar,
  year =	 1990,
  issn =	 {0001-0782},
  pages =	 {281--293},
  numpages =	 13,
  url =		 {http://doi.acm.org/10.1145/77481.77482},
  doi =		 {10.1145/77481.77482},
  acmid =	 77482,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {The following excerpts have been gleaned from a report by the Computer Science and Technology Board that summarizes the deliberations of a group of software engineers participating in a CSTB workshop that focused on setting research priorities.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=77482&ftid=19380&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:18>},
}

@book{Reiser:1991:OSU:102909,
  author =	 {Reiser, Martin},
  title =	 {The Oberon System: User Guide and Programmer's
                  Manual},
  year =	 1991,
  isbn =	 {0-201-54422-9},
  source =	 {ACM member price \$33.95, order number 706902},
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 14:12:20>},
}

@inproceedings{Gray:1987:VDS:29903.29905,
  author =	 {Gray, Jim},
  title =	 {A View of Database System Performance Measures},
  booktitle =	 {Proceedings of the 1987 ACM SIGMETRICS Conference on
                  Measurement and Modeling of Computer Systems},
  series =	 {SIGMETRICS '87},
  year =	 1987,
  isbn =	 {0-89791-225-X},
  location =	 {Banff, Alberta, Canada},
  pages =	 {3--4},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/29903.29905},
  doi =		 {10.1145/29903.29905},
  acmid =	 29905,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Database systems allow quick creation of performance problems. The goal of database systems is to allow the computer-illiterate to write complex and complete applications. It is the job of the system to translate a high-level description of data and procedures into efficient algorithms. The REAL performance metric of a system is how successfully it meets these goals.
Practitioners use a much narrower definition of system performance. They assume a standard workload and measure performance by peak throughput and by dollar cost per transaction.
Although many vendors have “private” performance measures, Bitton, Dewitt, and Turbyfill were the first to publish a measure of database system performance [Bitton]. Their measure, here called the Wisconsin benchmark, consists of a database design, a set of 32 retrieval and update statements, and a script for multi-user tests. They give two performance metrics: the elapsed time for each statement and the throughput of the system when running sixteen simultaneous scripts. No response time requirement or cost measure is included in the definition. The Wisconsin benchmark is the most widely used database benchmark.
Largely in response to the Wisconsin benchmark, an informal group including Bitton and Dewitt, defined a benchmark more representative of transaction processing applications [Anon]. Its workload is:

SCAN - A mini-batch operation to sequentially copy 1000 records
SORT - A batch operation to sort one million records.
DebitCredit - A short transaction with terminal input and output via X.25, presentation services, and a mix of five database accesses.

The DebitCredit transaction has rules for scaling the terminal network and database size as the transaction rate increases, and also rules for distributing transactions if the system is decentralized.
The performance metrics for this benchmark are:

Elapsed time for the SCAN and SORT.
Peak throughput for the DebitCredit transaction at 1 second response time for 95\% of the transactions. This gives a TPS (Transactions Per Second) rating.
Price per transaction where price is the 5-year cost of hardware, software and maintenance. This is sometimes called the vendors-view of price.

This benchmark has been adopted by several vendors to compare their performance and price performance from release to release and also to compare their performance to competitive products. MIPS, Whetstones and MegaFLOPs have served a similar role in the scientific community.
A system's TPS rating indicates not just processor speed, but also IO architecture, operating system, data communications and database software performance. Unfortunately, it does not capture ease-of-use.
Work continues on formalizing these benchmarks. At present they are written in English. Ultimately they should be defined by a file generator and a set of programs written in a standard database language such as COBOL-SQL.
When a vendor first measures his system against these benchmarks, the results are usually terrible. Both benchmarks are designed to expose generic performance bugs in frequently used transaction processing atoms. For example, the Wisconsin and SCAN benchmarks heavily penalize a system which is slow to read the next record in a file.
A system with poor performance on these benchmarks can be analyzed as follows: Most vendors have an “atomic” model of their system which represents each transaction as a collection of atoms. The atoms are the primitives of the system. For example, the SCAN benchmark is represented by most vendors as: SCAN: BEGIN TRANSACTION PERFORM 1000 TIMES READ SEQUENTIAL INSERT SEQUENTIAL COMMIT TRANSACTION
The atomic weights for, BEGIN, READ SEQUENTIAL, INSERT SEQUENTIAL, and COMMIT are measured for each release. The atomic weight usually consists of CPU instructions, message bytes, and disc IOs for a “typical” call to that operation. These weights can be converted to service times by knowing the speeds and utilizations of the devices (processors, discs, lines) used for the application. The molecular weight and service time of SCAN can then be computed as the sum of the atomic weights.
Defining and measuring a system's atoms is valuable. It produces a simple conceptual model of how the system is used. Atomic measurements also expose performance bugs. For example, based on the SCAN benchmark, most systems perform READ SEQUENTIAL in 1000 instructions and with .02 disc IO. If a system uses many more instructions or many more IO then it has a performance problem. Similarly, the DebitCredit transaction typically consumes about 2OOKi (thousand instructions) and five disc IO per transaction. One system is known to use 800Ki and 14 IO per transaction. The vendor could use atomic measurement to find the causes of such poor performance. When such problems are localized to an atom, solutions to the problem readily suggest themselves. So, atomic measurement is useful for performance assurance and performance improvement.
Atomic measurement also has a major role in system sizing and in capacity planning. If the customer can describe his application in terms of atoms, then a spreadsheet application can give him an estimate of the CPU, disc and line cost for the application. With substantially more effort (and assumptions) the system's response time can be predicted. With even more effort, a prototype system can be generated and benchmarked from the atomic transaction descriptions. Snapshot [Stewart] and Envision [Envison] are examples of systems which combine atomic modeling, queue modeling, and ultimately benchmarking of real systems generated from the atomic description of the application.},
  review = 	 {fbie: rejected <2016-01-15 14:12:26>},
}

@article{Gray:1987:VDS:29904.29905,
  author =	 {Gray, Jim},
  title =	 {A View of Database System Performance Measures},
  journal =	 {SIGMETRICS Perform. Eval. Rev.},
  issue_date =	 {May 1987},
  volume =	 15,
  number =	 1,
  month =	 may,
  year =	 1987,
  issn =	 {0163-5999},
  pages =	 {3--4},
  numpages =	 2,
  url =		 {http://doi.acm.org/10.1145/29904.29905},
  doi =		 {10.1145/29904.29905},
  acmid =	 29905,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Database systems allow quick creation of performance problems. The goal of database systems is to allow the computer-illiterate to write complex and complete applications. It is the job of the system to translate a high-level description of data and procedures into efficient algorithms. The REAL performance metric of a system is how successfully it meets these goals.
Practitioners use a much narrower definition of system performance. They assume a standard workload and measure performance by peak throughput and by dollar cost per transaction.
Although many vendors have “private” performance measures, Bitton, Dewitt, and Turbyfill were the first to publish a measure of database system performance [Bitton]. Their measure, here called the Wisconsin benchmark, consists of a database design, a set of 32 retrieval and update statements, and a script for multi-user tests. They give two performance metrics: the elapsed time for each statement and the throughput of the system when running sixteen simultaneous scripts. No response time requirement or cost measure is included in the definition. The Wisconsin benchmark is the most widely used database benchmark.
Largely in response to the Wisconsin benchmark, an informal group including Bitton and Dewitt, defined a benchmark more representative of transaction processing applications [Anon]. Its workload is:

SCAN - A mini-batch operation to sequentially copy 1000 records
SORT - A batch operation to sort one million records.
DebitCredit - A short transaction with terminal input and output via X.25, presentation services, and a mix of five database accesses.

The DebitCredit transaction has rules for scaling the terminal network and database size as the transaction rate increases, and also rules for distributing transactions if the system is decentralized.
The performance metrics for this benchmark are:

Elapsed time for the SCAN and SORT.
Peak throughput for the DebitCredit transaction at 1 second response time for 95\% of the transactions. This gives a TPS (Transactions Per Second) rating.
Price per transaction where price is the 5-year cost of hardware, software and maintenance. This is sometimes called the vendors-view of price.

This benchmark has been adopted by several vendors to compare their performance and price performance from release to release and also to compare their performance to competitive products. MIPS, Whetstones and MegaFLOPs have served a similar role in the scientific community.
A system's TPS rating indicates not just processor speed, but also IO architecture, operating system, data communications and database software performance. Unfortunately, it does not capture ease-of-use.
Work continues on formalizing these benchmarks. At present they are written in English. Ultimately they should be defined by a file generator and a set of programs written in a standard database language such as COBOL-SQL.
When a vendor first measures his system against these benchmarks, the results are usually terrible. Both benchmarks are designed to expose generic performance bugs in frequently used transaction processing atoms. For example, the Wisconsin and SCAN benchmarks heavily penalize a system which is slow to read the next record in a file.
A system with poor performance on these benchmarks can be analyzed as follows: Most vendors have an “atomic” model of their system which represents each transaction as a collection of atoms. The atoms are the primitives of the system. For example, the SCAN benchmark is represented by most vendors as: SCAN: BEGIN TRANSACTION PERFORM 1000 TIMES READ SEQUENTIAL INSERT SEQUENTIAL COMMIT TRANSACTION
The atomic weights for, BEGIN, READ SEQUENTIAL, INSERT SEQUENTIAL, and COMMIT are measured for each release. The atomic weight usually consists of CPU instructions, message bytes, and disc IOs for a “typical” call to that operation. These weights can be converted to service times by knowing the speeds and utilizations of the devices (processors, discs, lines) used for the application. The molecular weight and service time of SCAN can then be computed as the sum of the atomic weights.
Defining and measuring a system's atoms is valuable. It produces a simple conceptual model of how the system is used. Atomic measurements also expose performance bugs. For example, based on the SCAN benchmark, most systems perform READ SEQUENTIAL in 1000 instructions and with .02 disc IO. If a system uses many more instructions or many more IO then it has a performance problem. Similarly, the DebitCredit transaction typically consumes about 2OOKi (thousand instructions) and five disc IO per transaction. One system is known to use 800Ki and 14 IO per transaction. The vendor could use atomic measurement to find the causes of such poor performance. When such problems are localized to an atom, solutions to the problem readily suggest themselves. So, atomic measurement is useful for performance assurance and performance improvement.
Atomic measurement also has a major role in system sizing and in capacity planning. If the customer can describe his application in terms of atoms, then a spreadsheet application can give him an estimate of the CPU, disc and line cost for the application. With substantially more effort (and assumptions) the system's response time can be predicted. With even more effort, a prototype system can be generated and benchmarked from the atomic transaction descriptions. Snapshot [Stewart] and Envision [Envison] are examples of systems which combine atomic modeling, queue modeling, and ultimately benchmarking of real systems generated from the atomic description of the application.},
  review = 	 {fbie: rejected <2016-01-15 14:12:29>},
}

@article{Myrna:1985:UAV:255315.255657,
  author =	 {Myrna, John W. and DiChellis, Peter G.},
  title =	 {The Use of APL Versus Other Languages\&Mdash;a Six
                  Year Trend Analysis},
  journal =	 {SIGAPL APL Quote Quad},
  issue_date =	 {May 12, 1985},
  volume =	 15,
  number =	 4,
  month =	 may,
  year =	 1985,
  issn =	 {0163-6006},
  pages =	 {195--198},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/255315.255657},
  doi =		 {10.1145/255315.255657},
  acmid =	 255657,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Like everyone in the APL community, we've heard that all-too-familiar chorus: APL is a very small piece of the language market — just 1\% and declining. According to this school of thought, APL never got off the ground and probably never will. It's considered something of a “poor cousin” to well-known, successful languages like BASIC, FORTRAN, and COBOL.
Well, we've monitored the use of APL for some time now by reviewing the results of an unbiased, independent tracking survey on language usage, and we'd like to share some results that may surprise you. Results that show, for example, that the use of APL is not declining at all, and is even growing among one of the most important user segments in the market — the “casual programmer.” Within this segment — in a mainframe environment — APL enjoys ten times that pessimistic 1\% share and is running neck-and-neck with BASIC.
Admittedly, our data doesn't cover the entire data processing universe. It covers “primary use” in a particular high-quality mainframe environment (more on that in a minute). Still, we feel the data gives us an important look at where APL has been and where we, at least, think it's going.
The data we're using has been collected as part of an annual membership survey by the GUIDE organization. GUIDE is an independent group whose members are organizations using IBM mainframes, usually “small” machines such as the 4341. GUIDE's annual membership polls are very large, generally about 1500 installations.
The data presented in this paper is based on responses to the following question for the years 1978 through 1983: “A full-time programmer is one who earns his/her livelihood by programming. A casual programmer is one who does not earn his/her livelihood primarily by programming, but whose job does require some programming occasionally. Indicate the primary (most frequently used) language for (Check one language only per column). ” [I.e., one for full-time and one for casual].
So let's look at the numbers, beginning with full-time programmers. As Exhibit 1 shows, the use of APL as a primary language among full-time programmers has indeed hovered around 1\% to 2\% over the past 6 years. But those aren't the only numbers in the research, and we'd like to make a couple of points about what we think this data is really trying to tell us.
First, the data simply does not lend any credence to the premise that the use of APL is declining. APL use is at least holding steady and perhaps increasing, although the size of the increase in the survey is not really large enough statistically to say that usage is increasing.
Secondly, BASIC — one of the all-time “big three” — does no better than APL, and hasn't for the past six years (which is as far back as we have data). Another world-beater — FORTRAN — has been piddling around at about 4\% ever since we've been tracking. That's not much of a margin over APL's 1\% to 2\% when you consider that FORTRAN is apt to be available in more of these installations than APL.
In Exhibit 2, the data does show very clearly that COBOL is the dominant language among these full-time programmers, and we won't argue that point. But let's scrap once and for all the idea that APL can't hold it's own against languages like BASIC and FORTRAN among professional programmers.
Now let's look at casual programmers — people who don't earn their livelihood by programming, but whose jobs do require some programming, Exhibit 3 shows that the use of APL as a primary language among this group has doubled over the past 6 years, climbing steadily to 10\%.
As was also true among full-time programmers, the data shows that APL is equally as popular among these casual programmers as BASIC. The difference with casual programmers, of course, is that use of APL has grown rather impressively over the years, while BASIC has stagnated. Meanwhile, FORTRAN's popularity seems to be declining at about the same rate that APL is climbing. Exhibit 3 shows FORTRAN declining 6 percentage points over the past 6 years to its 1983 level of 18\% primary usage. Maybe we'll catch them, too.
Exhibit 3 also shows that COBOL is again the dominant language, though by nowhere near the margin it holds among full-time programmers. Margin of leadership is commonly used by business analysts to calculate a ratio called “relative share.” The idea is that 15\%, for example, is top-notch if the market leader only has 16\%. Anyway, it seems to us that APL's relative share of over one-third (10.1 / 27.7) among casual programmers is pretty respectable when you consider some of the popular assumptions about the size of the APL niche. Exhibit 4 tracks APL's relative share among casual programmers since 1978.
So what does it all mean?
First of all, we feel the data shows APL in a pretty favorable light. Our conclusion is that if a quality APL is available (as is true in the segment of the universe represented by this data), users will adopt it and stick with it. The six years of data we've reviewed here bears that out. Because of this, we firmly believe that quality APL products should be ported to a variety of new environments.
Secondly, we think the positive implication of APL's growth among “casual programmers” is fairly obvious considering the spread of computer literacy in the burgeoning white collar labor force. The current industry phrase — “knowledge workers” — says it all about this segment. They aren't computer jocks, but they get their jobs done by using a computer to convert a variety of data into usable knowledge. These are the users who are really driving the microcomputer explosion, and we're waiting to see what effect IBM's banner-year PC shipments will have on our 1984 and 1985 data.
However, based on the casual-user data we've seen, we believe that with quality APL systems now available on the current generation of 16-and 32- bit microcomputers, we will see more APL usage among the growing base of casual microcomputer programmers, and 10\% APL penetration as the primary language of these users is a benchmark against which we should measure ourselves. The challenge in this segment will be competing with the spreadsheets, DBMS, and other slick front-end software that is setting new standards in user interface and expectations. We think the casual programmer will demand more of these types of interfaces and features. To continue to succeed, APL systems will have to evolve along these lines.
Tables of the raw survey data are included in the appendix, incidentally, so you're free to do your own analysis in addition to ours.
The authors would like to express their thanks to Tom Gull, who compiled the GUIDE data used in this paper.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=255657&ftid=11876&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:33>},
}

@inproceedings{Myrna:1985:UAV:17701.255657,
  author =	 {Myrna, John W. and DiChellis, Peter G.},
  title =	 {The Use of APL Versus Other Languages\&Mdash;a Six
                  Year Trend Analysis},
  booktitle =	 {Proceedings of the International Conference on APL:
                  APL and the Future},
  series =	 {APL '85},
  year =	 1985,
  isbn =	 {0-897-91157-1},
  location =	 {Seattle, Washington, USA},
  pages =	 {195--198},
  numpages =	 4,
  url =		 {http://doi.acm.org/10.1145/17701.255657},
  doi =		 {10.1145/17701.255657},
  acmid =	 255657,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Like everyone in the APL community, we've heard that all-too-familiar chorus: APL is a very small piece of the language market — just 1\% and declining. According to this school of thought, APL never got off the ground and probably never will. It's considered something of a “poor cousin” to well-known, successful languages like BASIC, FORTRAN, and COBOL.
Well, we've monitored the use of APL for some time now by reviewing the results of an unbiased, independent tracking survey on language usage, and we'd like to share some results that may surprise you. Results that show, for example, that the use of APL is not declining at all, and is even growing among one of the most important user segments in the market — the “casual programmer.” Within this segment — in a mainframe environment — APL enjoys ten times that pessimistic 1\% share and is running neck-and-neck with BASIC.
Admittedly, our data doesn't cover the entire data processing universe. It covers “primary use” in a particular high-quality mainframe environment (more on that in a minute). Still, we feel the data gives us an important look at where APL has been and where we, at least, think it's going.
The data we're using has been collected as part of an annual membership survey by the GUIDE organization. GUIDE is an independent group whose members are organizations using IBM mainframes, usually “small” machines such as the 4341. GUIDE's annual membership polls are very large, generally about 1500 installations.
The data presented in this paper is based on responses to the following question for the years 1978 through 1983: “A full-time programmer is one who earns his/her livelihood by programming. A casual programmer is one who does not earn his/her livelihood primarily by programming, but whose job does require some programming occasionally. Indicate the primary (most frequently used) language for (Check one language only per column). ” [I.e., one for full-time and one for casual].
So let's look at the numbers, beginning with full-time programmers. As Exhibit 1 shows, the use of APL as a primary language among full-time programmers has indeed hovered around 1\% to 2\% over the past 6 years. But those aren't the only numbers in the research, and we'd like to make a couple of points about what we think this data is really trying to tell us.
First, the data simply does not lend any credence to the premise that the use of APL is declining. APL use is at least holding steady and perhaps increasing, although the size of the increase in the survey is not really large enough statistically to say that usage is increasing.
Secondly, BASIC — one of the all-time “big three” — does no better than APL, and hasn't for the past six years (which is as far back as we have data). Another world-beater — FORTRAN — has been piddling around at about 4\% ever since we've been tracking. That's not much of a margin over APL's 1\% to 2\% when you consider that FORTRAN is apt to be available in more of these installations than APL.
In Exhibit 2, the data does show very clearly that COBOL is the dominant language among these full-time programmers, and we won't argue that point. But let's scrap once and for all the idea that APL can't hold it's own against languages like BASIC and FORTRAN among professional programmers.
Now let's look at casual programmers — people who don't earn their livelihood by programming, but whose jobs do require some programming, Exhibit 3 shows that the use of APL as a primary language among this group has doubled over the past 6 years, climbing steadily to 10\%.
As was also true among full-time programmers, the data shows that APL is equally as popular among these casual programmers as BASIC. The difference with casual programmers, of course, is that use of APL has grown rather impressively over the years, while BASIC has stagnated. Meanwhile, FORTRAN's popularity seems to be declining at about the same rate that APL is climbing. Exhibit 3 shows FORTRAN declining 6 percentage points over the past 6 years to its 1983 level of 18\% primary usage. Maybe we'll catch them, too.
Exhibit 3 also shows that COBOL is again the dominant language, though by nowhere near the margin it holds among full-time programmers. Margin of leadership is commonly used by business analysts to calculate a ratio called “relative share.” The idea is that 15\%, for example, is top-notch if the market leader only has 16\%. Anyway, it seems to us that APL's relative share of over one-third (10.1 / 27.7) among casual programmers is pretty respectable when you consider some of the popular assumptions about the size of the APL niche. Exhibit 4 tracks APL's relative share among casual programmers since 1978.
So what does it all mean?
First of all, we feel the data shows APL in a pretty favorable light. Our conclusion is that if a quality APL is available (as is true in the segment of the universe represented by this data), users will adopt it and stick with it. The six years of data we've reviewed here bears that out. Because of this, we firmly believe that quality APL products should be ported to a variety of new environments.
Secondly, we think the positive implication of APL's growth among “casual programmers” is fairly obvious considering the spread of computer literacy in the burgeoning white collar labor force. The current industry phrase — “knowledge workers” — says it all about this segment. They aren't computer jocks, but they get their jobs done by using a computer to convert a variety of data into usable knowledge. These are the users who are really driving the microcomputer explosion, and we're waiting to see what effect IBM's banner-year PC shipments will have on our 1984 and 1985 data.
However, based on the casual-user data we've seen, we believe that with quality APL systems now available on the current generation of 16-and 32- bit microcomputers, we will see more APL usage among the growing base of casual microcomputer programmers, and 10\% APL penetration as the primary language of these users is a benchmark against which we should measure ourselves. The challenge in this segment will be competing with the spreadsheets, DBMS, and other slick front-end software that is setting new standards in user interface and expectations. We think the casual programmer will demand more of these types of interfaces and features. To continue to succeed, APL systems will have to evolve along these lines.
Tables of the raw survey data are included in the appendix, incidentally, so you're free to do your own analysis in addition to ours.
The authors would like to express their thanks to Tom Gull, who compiled the GUIDE data used in this paper.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=255657&ftid=11876&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:35>},
}

@inproceedings{Evenson:1988:RIC:62548.62553,
  author =	 {Evenson, Kristin M.},
  title =	 {Reference Interviews and the Computing Center Help
                  Desk},
  booktitle =	 {Proceedings of the 16th Annual ACM SIGUCCS
                  Conference on User Services},
  series =	 {SIGUCCS '88},
  year =	 1988,
  isbn =	 {0-89791-286-1},
  location =	 {Long Beach, California, USA},
  pages =	 {7--11},
  numpages =	 5,
  url =		 {http://doi.acm.org/10.1145/62548.62553},
  doi =		 {10.1145/62548.62553},
  acmid =	 62553,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {How often does the help desk forward a call to you, the spreadsheet expert, when they should have sent it to the database expert? Has anyone ever replied to one of your brilliant problem resolutions with “but that isn't what I wanted!”? All consultants know the frustration of talking to someone at length, discovering only after several minutes that they've been answering the wrong question.
Still, much of the training for computing center user support focuses on technical knowledge. Consultants often view the interchange between user and consultant as more of an art than a science. Consultants devote their limited training time to learning new systems; they count users to measure their success.
However, computer consultants can train themselves to interact more efficiently with users and can find new ways to evaluate their work. Users will benefit from better-focused consulting. Consultants will spend less time thrashing through misunderstandings, enjoying more time to work on actual problems. We can begin by using reference librarians as a model.
You might wonder what computing consultants can learn from librarians. After all, the library is an long-established institution, familiar and friendly. The computing center, now—there's the cutting edge, unknown and frightening. However, novice users need expert guides to the information resources in both environments.
Both computing center and library users become anxious when they must search out specific information. They don't know how to ask for help; they don't know what information they should provide in order to get the best assistance. Computing center users seem to sidle up to their main question. For example, a secretary asks about features of the LaserJet II when she wants to know how to get landscape printing on their old LaserJet. Similarly, library users approach the reference librarian with questions only obliquely related to their real aim. An anxious student asks for gardening books when his report on pesticides is due tomorrow.
Neither reference librarians nor computing center consultants can train users to ask better questions. However, reference librarians have developed a set of techniques which they use to discover their users' actual information needs. Librarians use the term “reference interview” to refer to the transaction between the person seeking information and the person providing information. After the initial contact, the librarian controls the interview, asking questions designed to discover the user's real question. The length of the reference interview depends on the complexity of the problem and the ability of the user to define the question.
Computing center consultants can easily apply reference interview techniques to their interactions with users. Listen to this quote from a reference service textbook:

“Many people are not aware that information of interest or of use to them is generally available in libraries.”
“As a reference librarian, one has accepted the responsibility of answering questions pleasantly, speedily, accurately, and, as nearly as possible, to the satisfaction of the inquirer.” (Thomas, p.95)

Change “library” to “computing center” and change “reference librarian” to “user consultant” and you have a goal statement suitable to any computing center help desk. A computing center help desk is very like a library reference desk. Both computing consultants and reference librarians answer users' questions. Both may use encounters with users to teach them how to use library or computing center resources. Both struggle with similar problems of inarticulate users, inadequate resources, and burned-out staff.
Several factors exacerbate the communication difficulties. Novice computer users don't know the jargon. They are scared of computers, or angry because they don't like feeling ignorant. They don't want to become computer experts; they just want to do their work. Often they feel pressured by deadlines. They don't have time to become acquainted with their system; they need to produce work now.
Librarians face similar difficulties. Library users don't understand the classification systems. They don't want to become librarians. They just want information and resent having to ask for help. Just as novice computer users don't want to admit ignorance, library users don't want to admit that they don't know how to use the library. Often they suffer the same time pressures; their paper is due tomorrow and they need information right now.
Computing center consultants can adopt most reference interview techniques unchanged, using reference librarians' work as a model to train and evaluate help desk staff. However, there are some obstacles to effortless use of the reference interview. Some consultants may feel that the differences between reference librarians and computer user consultants outweigh the similarities. Others would argue that we cannot define the reference interview clearly enough to apply these techniques in any structured way. Finally, reference interview training and evaluation will demand time.
These objections are valid. Computing centers are different from libraries; computing center consultants will not use reference interview techniques in exactly the same way as reference librarians. The reference interview does sometimes seem to be used as no more than a catch phrase for a grab bag of communication tips. We cannot effectively teach reference interview techniques if we have no more than a list of tips. Even if we can define the reference interview well enough to teach its use, we must add this training to consultants' already overbooked schedules. Evaluating consultants' use of reference interview techniques will require close observation of consultants' work and new methods of evaluation. However, none of these objections outweigh the benefits of the reference interview.
People do come to the library help desk for different reasons than they come to the computer center help desk. Library users usually have “what” questions; they want specific pieces of information. Computer users usually have “how” questions; they want instructions on how to accomplish some task. Library users want facts; journal citations, articles, and books on a particular subject. Computer users want instruction, problem fixes, disaster recovery, and help with diagnosing problems.
However, even when “typical” computing center users ask different question than “typical” library users, consultants can use the same reference interview techniques that librarians use. Reference interview techniques help the consultant control the interview in order to more easily discover the specific nature of each user's question. These techniques apply equally well whether users want quantitative or procedural information.
The amorphous nature of the reference interview is a more serious obstacle to training and evaluation. The “reference interview” can degenerate to nothing more than a label for a bunch of communication buzzwords. Computing center staff cannot apply reference interview techniques with measurable success unless they work from a clear definition.
The essence of the reference interview is that the information provider controls the interaction in order to best meet the needs of the person who needs the information. I divide the reference interview into three parts: approach, dialogue, and closure.
During approach, users decide who to approach and how to state their question. Consultants can control the environment to make it easy for the user to find help, again taking suggestions from library research. Signs should identify the help desk. Both student assistants and full-time consultants may wear name tags or badges. Help desk staff should appear “interruptable”—neither completely idle nor completely immersed in some project.
Reference interview articles often focus on the many communication techniques used in the second phase of dialogue between the user and the information provider. At the University of Iowa Personal Computing Support Center, we emphasize three techniques with our student workers: attending to the user, prompting for more information, and checking for mutual understanding.
During the dialogue, consultants depend on their general knowledge to recognize common problems and make connections which the novice user cannot. If unchecked by careful use of the reference interview, this ability to jump to the correct conclusion betrays both the consultant and the users. Dazzled users think that consultants magically solve their problems with almost no information. Consultants may jump too fast, giving users the right answers to the wrong questions. Careful attention to the user and checking for mutual understanding minimizes these problems.
The consultant must close the interview so that both the consultant and the user have the same understanding. During closure, the consultant makes sure that the user understands the answer and that both have the same expectations of any follow-up. In an ideal world, every reference interview ends with a satisfied user. In our imperfect reality, some users will not accept our answers. Consultants can borrow techniques from reference librarians to work with problem users.
The last and most serious obstacle to using reference interview techniques is the need for new methods of training and evaluation. Somehow consultants must find time to develop training, schedule training sessions, and evaluate their use of these techniques. With new software and hardware, consultants can accomplish much on their own if they are just given machine, manual, and disks. Reference interview techniques require more structured training. Again, we can draw upon the experience of reference librarians and use a variety of methods to train consultants to use reference interview techniques. Combinations of case studies and role-playing work well for many, especially if combined with videotaping. Concentrating on one technique at a time seems to work better than trying to teach every possible skill; this also allows shorter sessions which you can more easily fit into busy schedules.
Applying reference interview techniques will help consultants improve their work with users. Consultants must also devise new methods of evaluating their work in order to prove to themselves and to their management that the time spent on reference interview techniques is worthwhile.
In most computing centers, consultants religiously record each contact with a user. Their managers want to see numbers — preferably increasing numbers. Bigger numbers indicate that the consultants have accomplished more and thus deserve a bigger share of the budget. The consultants know that other departments within the computing center supply statistics to the administration, and that the consultants had better supply statistics that are just as good.
Thus consultants keep logs to mark each time they talk to a user. They break down contacts into telephone and walk-in; they code each for the subject of the question and categorize each by status of user. Consultants may decide to record not just each person, but each question asked by each person. After all, just one person may ask about using footnotes in Word, transferring Macintosh files to a DOS diskette, and recovering erased files. Shouldn't that count as three? They also note the start and stop time of each contact.
Each quarter the consultants transform their tickmarks into glowing reports of the multitudes who have benefited from the computing center help desk. However, these reports to the managers don't do that much for the consultants. The quantity of work may not impress the managers. Some managers who find the statistics impressive may keep their impression to themselves, giving no reward to the consultants. Those managers who do reward the consultants often give them rewards that increase the workload. They find money in the budget for more student workers — who must be trained. They provide a local area network — which must be installed and maintained. They give everyone new software — which the consultants must somehow find time to learn and then use their learning as the basis for more consulting and classes.
Even when these quarterly stacks of statistics do bring rewards, they do not help the consultants or the managers truly evaluate their work. Numbers of users seen does not invariably correlate with numbers of problems solved. Measuring numbers alone tells the computing center much about increasing demand and peak usage times, but it tells nothing about the quality of computing center services. Consultants must devise new methods to evaluate their work, educate their managers to use these new evaluation methods, and generate their own rewards for effective work.
In order to develop adequate measures, consultants must decide why they consult and exactly what they do when they consult. They should know how their private purposes fit the computing center's official statement of purpose. Many computing centers set forth the goal of greater productivity through computing and their consultants spread the gospel across campus. Many consultants encourage users to become self-sufficient — either to see the fledglings fly away from the nest or to shoo away the pests. Some encourage dependency, protecting each tender novice from the awful complexities of computing. Some consult only because they happened to find this job and they don't want to search for another right now.
As they consider their reasons for consulting, the consultants should observe their daily work. Consulting services vary widely; within one computing center the individual consultants provide different services, which should be evaluated differently. One consultant may teach no classes but spend twenty hours per week visiting departments to provide on-site assistance. Each consultant should list his or her activities — writing articles, teaching seminars, help desk services, etc.
Once they have developed a statement of purpose and a list of activities, the consultants can devise methods to evaluate their work. Each activity calls for a different tool of evaluation. Each tool should be chosen to answer two questions: “Does x (a particular technique) accomplish y (my reason for consulting)? How well does it accomplish it?” For example, consultants may use feedback questionnaires and tests to answer these questions about their seminars.
Obviously, the simple recording of numbers takes less time than this meditation on purpose, listing of activities, and then evaluation of activities according to how well they accomplish the purpose. Consultants often feel they have barely enough time to note one user contact before the next approaches. Few managers encourage overworked consultants to take time for detailed evaluation.
However, consultants can develop meaningful evaluations of their work a little at a time. While they continue to supply their managers with numbers, they can also select one activity to evaluate for a set time. The results of these evaluations, added to the usual statistics, will show their concern with quality as well as quantity. The consultants should demonstrate that these evaluations help the computing center accomplish its formally stated goals. This will encourage their managers both to see the value of evaluation and to appropriately reward the consultants.
The evaluations point out where consultants need to improve their work and where they should receive rewards. Part of the consultants' reward will lie in knowing that they have reached users. Few consultants derive much pleasure from knowing that they talked to thirty users per day this quarter compared to twenty-two per day last quarter. Most want to know they make a difference to at least some of those users. Merely recording the number of users who came to the help desk does not tell the consultants whether any of those users left the help desk happier than they came to it. Evaluation provides proof that the consultants actually do help users — proof that will provide much-needed satisfaction to the consultants.
Beyond the intangible reward of personal satisfaction, those consultants who can demonstrate progress toward stated goals are best equipped to suggest suitable rewards to the management. If the consultants can link these rewards to future progress — the three-day seminar in Boston that will even further improve their consulting, for example — so much the better.
As we hustle to keep track of continuous updates and the constant traffic of users, we can lose sight of our goals. Finding new ways to work with users and new ways to evaluate our work will help us find new enthusiasm for our work.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=62553&ftid=47583&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:49>},
}

@book{Winograd:1996:BDS:229868,
  editor =	 {Winograd, Terry},
  title =	 {Bringing Design to Software},
  year =	 1996,
  isbn =	 {0-201-85491-0},
  source =	 {ACM member price \$26.95, order no. 704960},
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  review = 	 {fbie: rejected <2016-01-15 14:12:50>},
}

@article{Svobodova:1984:FSN:3872.3873,
  author =	 {Svobodova, Liba},
  title =	 {File Servers for Network-based Distributed Systems},
  journal =	 {ACM Comput. Surv.},
  issue_date =	 {Dec. 1984},
  volume =	 16,
  number =	 4,
  month =	 dec,
  year =	 1984,
  issn =	 {0360-0300},
  pages =	 {353--398},
  numpages =	 46,
  url =		 {http://doi.acm.org/10.1145/3872.3873},
  doi =		 {10.1145/3872.3873},
  acmid =	 3873,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {An abstract is not available.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=3873&ftid=267096&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:12:55>},
}

@inproceedings{Mayer:1989:EAS:76619.76644,
  author =	 {Mayer, P. J.},
  title =	 {Entering the Ada Systems Design and Coding Market},
  booktitle =	 {Proceedings of the Conference on TRI-Ada '88},
  series =	 {TRI-Ada '88},
  year =	 1988,
  isbn =	 {0-89791-285-3},
  location =	 {Charleston, West Virginia, USA},
  pages =	 {567--580},
  numpages =	 14,
  url =		 {http://doi.acm.org/10.1145/76619.76644},
  doi =		 {10.1145/76619.76644},
  acmid =	 76644,
  publisher =	 {ACM},
  address =	 {New York, NY, USA},
  abstract = 	 {Advice is cheap, and we all know that you get what you pay for. There are many books, courses, and seminars on how to start a business. They have been written or are presented by professionals usually with far greater experience than I. While my general management background has been invaluable, the thing that best qualifies me to address this subject is the fact that we at Strictly Business Computer Systems have recently established an Ada programming shop.
I'll share with you our experiences, from inception to the present. I must preface my remarks with the comment that they represent only our single effort in this area. I was fortunate in that my primary associates had successfully established and were operating a profitable business in the computer field, and it was their proven philosophy of adding value that became the keynote of our Ada effort.
Additionally, we had the good fortune to make some valuable acquaintances early on in the process — relationships which enabled us to avoid some potentially costly pitfalls. Perhaps we can do the same for some of you.
Now, to the subject at hand.
What would seem to be the obvious first step in establishing any business is worth stating and that is the conscious act of making a commitment to the project. In our experience, the commitment was initially made about three years ago — two full years before the project was actually initiated. The delay occurred because the computer system integration business in which Strictly Business was totally immersed was growing at a pace that precluded devoting the time required to explore the Ada market.
Then, a file less than a year ago, I joined Strictly Business with the sole responsibility of researching the Ada shop possibilities, and then managing the shop if the research was positive — which it obviously was. The fact that Strictly Business was willing to add me to the staff, as pure overhead from the business standpoint, clearly demonstrates that a true commitment existed. That commitment is really three-fold because undertaking such a project requires a dedication of, and money. Beyond that, you must assume the posture that characterizes the entrepreneur, and that is a total immersion in the business. You must identify with it and make it the focus of all that you do.
If you and your organization are unwilling to pledge a full-fledged effort, your chances of success substantially diminish.
Secondly, since the first phase of this project should be a marketing study, you must select an underlying theme that will provide a framework and give specific direction to your research. From the outset, we were convinced that within the Ada market a definite need existed for additional systems design and coding capacity. The corollary is that this appeared to provide a significant business opportunity. Our research was active — not passive or neutral. We saw an opportunity, and our purpose was to objectively and concretely confirm our perceptions.
At each step in the process we were looking at what value was being added by the person, business or agency that we were exploring. Strictly Business was founded and has flourished on two basic concepts — namely, adding value through our involvement in each transaction and providing quality products and service to our clients. We scrupulously avoid being hardware and software “brokers” collecting fees for merely placing products with customers. We consider ourselves as partners with our clients and work to enhance their businesses with the products and services we provide.
Having made the commitment and articulated your role and objectives, you must now begin the real work. This part of my message may be preaching to the choir. The fact that you are involved in the Ada community indicates that you have or are beginning to acquire a knowledge of the Ada marketplace. That's essential.
Gather as much information as possible about every aspect of Ada. If you know the language, great. If not, that should not deter you from learning as much as you can exclusive of Ada per se. No one in our organization knew Ada before we began hiring our staff, yet several of us became knowledgeable and conversant enough to find our way around Ada circles — and in the Ada community, that's essential.
Regardless of how much you learn in your explorations, the input of people active in Ada is indispensable. One of the most gratifying things our research revealed was the generosity and willingness of Ada experts to share their knowledge. We knocked on a lot of doors and did not find one that was not opened wide for us.
Let me share with you some of the avenues we explored in trying to determine whet her or not a real Ada opportunity existed. We first had the advantage of coming from West Virginia whose senior U.S. Senator is Robert C. Byrd who has seen the potential of Ada and has for some years been one of its strongest advocates. With the assistance of two of his staff members, we were directed to the Software Valley Corporation which has been very much involved in bringing the advantages of Ada and Ada-related ventures to our Mountain State.
Bob Verhotz, the Executive Director of Software Valley Corporation, in addition to other helpful suggestions, recommended that we contact Mr. Ralph Crafts. Bob had worked with Ralph on a number of occasions and spoke highly of his credentials and performance. We have not been disappointed.
Ralph knows his way around the Ada community as well as anyone, and better than most. Almost a year ago, we employed Ralph as our consultant to define the state of the Ada market and give initial direction to our study. During intensive meetings with him, we received a great deal of background information and recommendations of additional areas into which we should extend our Ada network.
These three initial contacts — Ralph, Software Valley, and Senator Byrd — confirmed that quality-conscious and professional systems developers could definitely find a place in the Ada market.
At this point I think you can begin to see two things. The more obvious is the snowball effect of Ada contacts. Your first contact leads to two others which each lead to two or three more, and so on. The second thing is that we were strongly encouraged by each of these contacts, and our perceptions that excellent opportunities existed in Ada were reinforced. If anything, the potential began to look even greater than we had at first anticipated.
Our tentacles, at that point, began to extend into additional areas of the Ada community. We have come to share Ralph's belief that the more people you know in this still relatively small group, the better off you are.
We traveled to Washington to visit again with Senator Byrd's office. While there, with an introduction from the senator's staff, we also met with a number of people at the Ada Joint Programming Office, including the then-Air Force Deputy Director Major Al Kopp. More support and encouragement. On the same trip we cultivated an acquaintance at the Ada Information Clearinghouse. More support, encouragement, and a wealth of published information. We also briefly visited the STARS office and met with someone who was encouraging and informative about that extensive Ada project. Each of these organizations and individuals had a specific mission designed to enhance and increase the value of the Ada contribution.
At that point we had begun to look at equipment and it was here that we found one of our more valuable allies and associates. From our initial contact with the personnel at RATIONAL we found them to be most helpful and open. Our sales representative made it possible for us to meet with two large firms handling major project work in Ada for the Defense Department.
I don't need to tell you how valuable it can be to speak with someone who is engaged in the type of work you are contemplating and who has no ax to grind or hidden agendas as far as discussing things with you. Other vendors may have been equally helpful, but I doubt that any could have been more so. We met people doing actual project work in Ada for the government, extending our network and also making some contacts we would later pursue as we sought to put together our Ada staff.
In March of this year, we attended the SlGAda conference in Phoenix where we researched a number of vendors, but more importantly, met others in the Ada community — on the commercial as well as the governmental side. We, admittedly, understood very little of the technical content of the meeting, but our purpose in attending was not technical in nature. We were networking, and our network was rapidly expanding.
This might be a good point at which to remind you of the three-fold commitment required in this undertaking — time, energy, and money. By March our exploratory had gotten into its fifth month and had occupied practically all of my time and a substantial portion of the time of two of my colleagues at Strictly Business. Our travels had included a couple of trips to Washington and the trip to Phoenix as well as visits to Morgantown, WV (where the Software Valley Corporation is located) and Pittsburgh where we met with an active Ada development firm and some folks at the Software Engineering Institute of Carnegie-Mellon University. For a small firm such as ours, the budget for this venture was becoming substantial, but we were making valuable progress toward our objective.
Speaking of budgets, probably the largest single start-up expenditure will be the development system you select. Spend sufficient time in making this decision. In equipment, you have a myriad of choices. With the recent validation of a large number of compilers, Ada development can be done, in one form or another, on anything from PC's to the much more sophisticated full-blown systems requiring major financial expenditures — and cost, at least in our case, was a significant consideration. But cost was only one factor.
We also were concerned with other areas. Our initial plans called for a system to support ten (10) developers designing systems and/or writing code. Most hardware suppliers could accommodate that in one way or another. With our lack of experience in Ada, we were also looking for ease of familiarization and operation. And we were very much concerned with the level of support a supplier could provide. Who seemed most qualified and willing to “hold our hand,” as it were, until we gained some experience?
The last major consideration was credibility. We knew that as a start-up operation gaining entree and establishing our credentials with potential contractors was critical. Our development system could say a lot about our commitment and dedication. Technical capabilities being a given, we were willing to pay some premium to project the most professional image. Bottom Line: find the system that will best enable us to efficiently and effectively develop software — to give our future clients value for their programming expenditures.
We investigated three major suppliers — DEC and DG, both of whom seemed quite capable; and RATIONAL, whose development environment was written in and expressly for Ada.
Weighing all the factors — system capabilities, support, ease of integration and use, reputation, cost, efficiency, etc. — we came down on the side of RATIONAL, and later decided that we would supplement them with SUN Microsystems work stations.
We're happy with our decision and believe, as I said at the outset about the cost of advice, that you get what you pay for. At this time, we are confident that our system configuration will satisfy our objectives and meet our expectations. Something similar mayor may not be right for you. Your situation and needs, not our experience, should dictate your direction on equipment selection. We can only recommend that you thoroughly explore the alternatives.
So where were we? We had done a lot of reading and travelling; met a lot of people with whom we'd like to be professionally associated: gotten a tremendous amount of encouragement that had been tempered with some pragmatic cautions; and made some preliminary system selections. Now we were getting down to the nitty-gritty — putting our plans and a proposal down on paper so that we could launch a sales effort to put together the financing needed to make it go.
In formalizing your proposal or business plan, be prepared to spend a lot of hours at a desk with all of your background notes, a dictionary, a thesaurus, calculator, plenty of paper and pencils with generous erasers. With access to a word processor and a good spreadsheet program, you are facing a formidable task; without these two tools, it will seem, and may actually be, virtually “undoable.”
Your proposal or business plan can take any of several forms, and no one is necessarily more or less appropriate or effective than any other. The plan should reflect your corporate style and philosophy. But regardless of the form, there are some elements which are indispensable.
Your presentation must inspire confidence in a potential investor, assuming that you, like we, have to seek outside capital to launch your effort. The plan must clearly demonstrate that you have done your homework and thoroughly researched the subject and the market. It should deal with the principal players in your scenario, their credentials, and what they can contribute to the success of the venture — what value can each add? If yours is to be an extension of an existing business, the proposal must provide business and financial history in a realistic light, yet do so as favorably as possible. Finally, the plan must provide business forecasts in the form of projected financial statements and balance sheets. Have your accountant or someone with a strong financial background assist with the financials if that is not an area in which you have experience and confidence.
Ultimately, the plan must convince its readers that you have (a) identified a need in the market and (b) that you are prepared and positioned to meet it. Experienced business pros will be reviewing the plan, so make the effort, and do it right. In preparing all of this information, keep in mind that an investor who decides to participate based on the plan will view it as your commitment. He very likely will measure your success, or lack of it, by using the plan as his yardstick. So, be conservative or at least realistic. Don't put anything into your plan that you might regret. if it were referenced some time later.
One of our new acquaintances offered to review our proposal. He was doing Ada work so he could evaluate the presentation from that perspective. He was also very much involved with a managing board composed of experienced venture capitalists, so he could also take a look from that viewpoint. He gave us sound advice.
My point is that you should have some disinterested parties whose opinions you value and respect, and who can freely and dispassionately critique your work, review it before you run with it. And, believe me, unless you are superhuman, you will go through several drafts and revisions before you submit the plan for outsider review. Our final plan was the sixth major revision, excluding the many internal changes and edits. Preparing an acceptable and effective plan is a humbling experience that will teach you the value of patience.
One final note regarding your proposal — don't overlook its appearance. A copy of the plan and an introductory letter may be your only exposure as you try to get personal appointments to market your idea. Prepare them with care and attention to detail. Ensure that they reflect the high degree of professionalism that went into their re-search and preparation and which will characterize your business efforts. The content of the plan may not even be considered if the plan itself is not attractively presented.
Now that you have what you believe is a good marketing piece, where do you go with it?
Our objective was to secure local financing (within our community or at least within the state of West Virginia). We drew on personal contacts, a list of local venture capitalists that we obtained from the chamber of commerce, and suggestions offered by the CEO of one of the banks with whom we had an on-going personal and business relationship.
We thoroughly explored various loan, grant, and incentive programs offered by municipal, county and state governments to attract business. If you have a university near you, they may have an office that assists with business start-ups. They may be very helpful if you choose to apply for loans or grants since this is an art form in itself. Don't overlook these potentially attractive sources of advice or capital; they could make the difference.
Be prepared to make phone calls, personal visits and send written correspondence in cultivating potential investors. And be sure to have your ducks in line because most of these people did not accumulate their wealth or acquire their positions because they are fiscally naive or stupid. They are, by and large, very good business people who ask direct and probing questions and expect direct, succinct, supportable answers — and a wrong answer can quickly kill an opportunity.
If local capital is not available, you will have to look farther afield. That's an area in which we can't offer much advice as we did not have to pursue it. We anticipated that if we had had to look elsewhere we would have to be even more on our toes, since we would give up the advantage of common ground. We would be negotiating on their turf rather than being from the same community as the people we were soliciting.
One of the biggest difficulties we encountered was in selling something intangible. As sophisticated as many lenders and investors are, some are still uncomfortable with the computer field, and especially software, as an area of opportunity.
Unless high tech businesses are already an established and accepted investment arena in your area, lenders may have difficulty grasping the concept of investing in intellectual property. Loans or investments for plant and equipment are a piece of cake — you can survey, touch, walk around or kick the tires of the collateral. In dealing with software, you lose that advantage, and many people are still wary of getting financially involved with something they can't see, touch, taste, or smell.
Anticipate some initial skepticism and prepare to overcome it. BEGIN NOW. This is one area where you can't start sowing seeds and nurturing them too soon. Look for or create occasions to discuss with the financial powers in your community the role and advantages and success stories and opportunities in software development. When you come across a good article — one that's not too technical — that supports your point, send copies to appropriate people. Most will be read, and you'll be strengthening your case and laying a foundation you can build on later.
Aside from the “intangibility factor,” we found that the key concern of potential investors is the make-up of your staff. If you have on board people with strong credentials and proven track records in Ada, your job will be much easier. We didn't. In fact, we had the chicken-and-egg situation of having financiers citing staff as a prerequisite on the one hand; and our inability to recruit and hire a staff until we had secured financing on the other. It was one of the most frustrating aspects of the whole process.
We leaned heavily on the proven track records of those of us who were organizing the venture, even though they included no Ada experience. Special expertise has to be addressed, but good basic management skills and experience are highly regarded, well-respected, and carry a lot of weight. We also capitalized on the credentials of our consultant with whom we had reached an agreement for his continuing services after our start-up, making him a legitimate member of our team. It was true that we had considerable background in computer sales, and had on our staff experienced programmers doing custom work for clients, though not in Ada. Many people perceive experience in one area of the computer field as qualification to perform in what we knew to be largely unrelated areas. Since it worked to our advantage, we did not discourage that perception.
While we were putting together our financing, we did some preliminary recruiting. We secured resumes and expressions of interest from programmers by contacting the colleges and universities that were graduating students from computer science programs in our area. From the outset, our objective had been to get our programmers locally, if possible. We believe that local residents, particularly in an area like ours, are more easily attracted to job opportunities near home and are more likely to remain with us because of their ties to the area.
We recognized, however, that it was critical for us to attract at least one highly experienced Ada professional to direct the programming effort. We drew on the contacts we had made and also secured the services of two firms specializing in Ada placements. Use every tool you can muster, because this is a difficult area with the explosive growth that Ada is enjoying. Experienced people are hard to find, and you must be prepared for a difficult search and the possibility that you may not have adequately budgeted for this position. This person is key, however, and if you find the right one: the time, effort, and money expended in the search will have been well worth it.
Look into training, particularly if you do as we did and recruit most of your staff with little or no practical Ada experience. Budget the time and money to allow for proper training of your people and recognize that they will be unproductive for some period of time after they come on board. We completed the hiring of our staff in early Fall. Theirs is a ten-week-long training program. We anticipate beginning work on our first contract no earlier than the first of the year. Our staff will have been on the payroll for more than three months before they take their first steps toward providing a return on the investment in them.
So things have finally come together. With financing secured, you have ordered and scheduled installation of your system; hired and are training your staff; and are ready to undertake some work!
Getting that first contract may be a challenge. Use every means at your disposal. If you can hire a professional who can bring contracts with him, so to speak, great! If the contacts you have made in your investigations can't help open doors for you, then you haven't been contacting the right people. If you have a Senator Byrd to lend support, bravo! Get all the help you can. Don't be bashful — most people are more than willing to lend as much help as they're able. Don't leave any stone unturned. And don't wait too late to begin looking.
If, somehow, you can get a contract before you configure your shop it will certainly make it easier to attract financing. We were unable to do that. Few people will let a contract to a non-existent shop. We began to actively seek a contract as soon as we had our financing in place and our hiring underway.
Use every advantage to secure that first contract, but recognize that future work will be contingent on your performance and the reputation for quality that you establish. Personal relationships will become much less a factor. Don't bite off more than you can chew on that first contract. Find something manageable that will give you some experience, allow you to establish some credibility, and is small enough to be completed in a reasonable length of time. And go all out to deliver the best product possible on or ahead of schedule. Then you're on our own, and relying on your performance record — and that's as it should be. The ball will be in your court and how you handle it will determine the flow of the game for the future.
I've covered a lot of ground, and again I emphasize that this has been a review of our experience - a case study in which the last chapters are just now being written - and not a “how to” course, per se. In retrospect, I don't believe that there is much that we would do differently if we were to do it again. We approached the project as a marketing problem and treated it accordingly, drawing on the expertise of others in technical and financial areas. Some of the things we learned would enable us to compress the timeframe to establish a new venture if we were to do it again, but we are relatively well satisfied with how things went.
Let me close by just saying that you can become discouraged if you allow it to happen. If you are like we were, the potential of the opportunity is so enormous and so obvious that you won't be able to easily accept the reluctance and skepticism of others. Why can't they see what's as plain as day to us? Why are things taking so long? Be patient and persist. If you're committed, do your homework, lay the groundwork, and do a good selling job, things will ultimately work out. Don't lose your sense of urgency; don't allow your interest to flag; and be patient…be patient…be patient.
If we have been able to give you any ideas, then we've accomplished our objective. We wish you well. Thank you.},
  fullTextUrl =  {http://dl.acm.org/ft_gateway.cfm?id=76644&ftid=8518&dwn=1&CFID=575549397&CFTOKEN=15758644},
  review = 	 {fbie: rejected <2016-01-15 14:13:02>},
}
